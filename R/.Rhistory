cbind(model = "NN1_MAE", sample = sample, simulation_results_list[[realization_no]]$NN1_MAE[[sample]]$loss_stats),
cbind(model = "NN2_MSE", sample = sample, simulation_results_list[[realization_no]]$NN2_MSE[[sample]]$loss_stats),
cbind(model = "NN2_MAE", sample = sample, simulation_results_list[[realization_no]]$NN2_MAE[[sample]]$loss_stats),
cbind(model = "NN3_MSE", sample = sample, simulation_results_list[[realization_no]]$NN3_MSE[[sample]]$loss_stats),
cbind(model = "NN3_MAE", sample = sample, simulation_results_list[[realization_no]]$NN3_MAE[[sample]]$loss_stats),
cbind(model = "NN4_MSE", sample = sample, simulation_results_list[[realization_no]]$NN4_MSE[[sample]]$loss_stats),
cbind(model = "NN4_MAE", sample = sample, simulation_results_list[[realization_no]]$NN4_MAE[[sample]]$loss_stats),
cbind(model = "NN5_MSE", sample = sample, simulation_results_list[[realization_no]]$NN5_MSE[[sample]]$loss_stats),
cbind(model = "NN5_MAE", sample = sample, simulation_results_list[[realization_no]]$NN5_MAE[[sample]]$loss_stats),
#################################################################################################
cbind(model = "LSTM_MSE", sample = sample, simulation_results_list[[realization_no]]$LSTM_MSE[[sample]]$loss_stats),
cbind(model = "LSTM_MAE", sample = sample, simulation_results_list[[realization_no]]$LSTM_MAE[[sample]]$loss_stats),
#################################################################################################
cbind(model = "FFORMA_MSE", sample = sample, simulation_results_list[[realization_no]]$FFORMA_MSE[[sample]]$loss_stats),
cbind(model = "FFORMA_MAE", sample = sample, simulation_results_list[[realization_no]]$FFORMA_MAE[[sample]]$loss_stats)
)
}
cbind(realization_no = realization_no, dgp_spec = dgp_spec, SV = SV, cross_corr = cross_corr, df)
}
# Function to iterate over all realizations
all_realize_loss_df <- function(simulation_results_list, dgp_spec, SV, cross_corr) {
foreach(realization_no = (1:5), .combine = "rbind") %do% {
gen_tidy_loss_df(simulation_results_list, realization_no, dgp_spec, SV, cross_corr)
}
}
all_loss_df <- rbind(
all_realize_loss_df(g1_A1_nosv_0_results_all, dgp_spec = "g1", SV = 0, cross_corr = 0),
all_realize_loss_df(g2_A1_nosv_0_results_all, dgp_spec = "g2", SV = 0, cross_corr = 0),
all_realize_loss_df(g3_A1_nosv_0_results_all, dgp_spec = "g3", SV = 0, cross_corr = 0),
all_realize_loss_df(g1_A1_sv_0.01_results_all, dgp_spec = "g1", SV = 1, cross_corr = 0.01),
all_realize_loss_df(g2_A1_sv_0.01_results_all, dgp_spec = "g2", SV = 1, cross_corr = 0.01),
all_realize_loss_df(g3_A1_sv_0.01_results_all, dgp_spec = "g3", SV = 1, cross_corr = 0.01),
all_realize_loss_df(g1_A1_sv_0.1_results_all, dgp_spec = "g1", SV = 1, cross_corr = 0.1),
all_realize_loss_df(g2_A1_sv_0.1_results_all, dgp_spec = "g2", SV = 1, cross_corr = 0.1),
all_realize_loss_df(g3_A1_sv_0.1_results_all, dgp_spec = "g3", SV = 1, cross_corr = 0.1),
all_realize_loss_df(g1_A1_sv_1_results_all, dgp_spec = "g1", SV = 1, cross_corr = 1),
all_realize_loss_df(g2_A1_sv_1_results_all, dgp_spec = "g2", SV = 1, cross_corr = 1),
all_realize_loss_df(g3_A1_sv_1_results_all, dgp_spec = "g3", SV = 1, cross_corr = 1)
)
all_loss_df_averaged <- all_loss_df %>%
data.frame() %>%
group_by(model, dgp_spec, sample, SV, cross_corr) %>%
summarise(validation_MAE = mean(validation_MAE), validation_MSE = mean(validation_MSE),
validation_RMSE = mean(validation_RMSE), validation_RSquare = mean(validation_RSquare),
test_MAE = mean(test_MAE), test_MSE = mean(test_MSE),
test_RMSE = mean(test_RMSE), test_RSquare = mean(test_RSquare)
)
## Save to csv
write.csv(all_loss_df_averaged, file = "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/Results/simulation_loss_averaged.csv")
write.csv(all_loss_df, file = "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/Results/simulation_loss.csv")
#############################################################################
# Function to collate variable importance
normalize_variable_importance <- function(variable_importance_df) {
variable_importance_df %>%
# Add a very very tiny value so that division by zero does not occur
mutate(importance = importance + 1e-100) %>%
mutate(importance = importance + abs(min(importance))) %>%
mutate(importance = importance/sum(importance))
}
gen_tidy_vi <- function(simulation_results_list, realization_no, dgp_spec, SV, cross_corr) {
df <- foreach(sample = 1:3, .combine = "rbind") %do% {
rbind(
cbind(model = "LM_MSE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$LM_MSE[[sample]]$variable_importance)),
cbind(model = "LM_MAE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$LM_MAE[[sample]]$variable_importance)),
################################################################################################
cbind(model = "ELN_MSE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$ELN_MSE[[sample]]$variable_importance)),
cbind(model = "ELN_MAE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$ELN_MAE[[sample]]$variable_importance)),
################################################################################################
cbind(model = "RF_MSE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$RF_MSE[[sample]]$variable_importance)),
cbind(model = "RF_MAE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$RF_MAE[[sample]]$variable_importance)),
################################################################################################
cbind(model = "NN1_MSE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$NN1_MSE[[sample]]$variable_importance)),
cbind(model = "NN1_MAE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$NN1_MAE[[sample]]$variable_importance)),
cbind(model = "NN2_MSE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$NN2_MSE[[sample]]$variable_importance)),
cbind(model = "NN2_MAE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$NN2_MAE[[sample]]$variable_importance)),
cbind(model = "NN3_MSE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$NN3_MSE[[sample]]$variable_importance)),
cbind(model = "NN3_MAE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$NN3_MAE[[sample]]$variable_importance)),
cbind(model = "NN4_MSE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$NN4_MSE[[sample]]$variable_importance)),
cbind(model = "NN4_MAE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$NN4_MAE[[sample]]$variable_importance)),
cbind(model = "NN5_MSE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$NN5_MSE[[sample]]$variable_importance)),
cbind(model = "NN5_MAE", sample = sample,
normalize_variable_importance(simulation_results_list[[realization_no]]$NN5_MAE[[sample]]$variable_importance))
)
}
cbind(realization_no = realization_no, dgp_spec = dgp_spec, SV = SV, cross_corr = cross_corr, df)
}
# Iterate over all realizations
all_realize_vi <- function(simulation_results_list, dgp_spec, SV, cross_corr) {
foreach(realization_no = (1:10), .combine = "rbind") %do% {
gen_tidy_vi(simulation_results_list, realization_no, dgp_spec, SV, cross_corr)
}
}
all_vi_df <- rbind(
all_realize_vi(g1_A1_nosv_0_results_all, dgp_spec = "g1", SV = 0, cross_corr = 0),
all_realize_vi(g2_A1_nosv_0_results_all, dgp_spec = "g2", SV = 0, cross_corr = 0),
all_realize_vi(g3_A1_nosv_0_results_all, dgp_spec = "g3", SV = 0, cross_corr = 0),
all_realize_vi(g1_A1_sv_0.01_results_all, dgp_spec = "g1", SV = 1, cross_corr = 0.01),
all_realize_vi(g2_A1_sv_0.01_results_all, dgp_spec = "g2", SV = 1, cross_corr = 0.01),
all_realize_vi(g3_A1_sv_0.01_results_all, dgp_spec = "g3", SV = 1, cross_corr = 0.01),
all_realize_vi(g1_A1_sv_0.1_results_all, dgp_spec = "g1", SV = 1, cross_corr = 0.1),
all_realize_vi(g2_A1_sv_0.1_results_all, dgp_spec = "g2", SV = 1, cross_corr = 0.1),
all_realize_vi(g3_A1_sv_0.1_results_all, dgp_spec = "g3", SV = 1, cross_corr = 0.1),
all_realize_vi(g1_A1_sv_1_results_all, dgp_spec = "g1", SV = 1, cross_corr = 1),
all_realize_vi(g2_A1_sv_1_results_all, dgp_spec = "g2", SV = 1, cross_corr = 1),
all_realize_vi(g3_A1_sv_1_results_all, dgp_spec = "g3", SV = 1, cross_corr = 1)
)
all_vi_df_averaged <- all_vi_df %>%
group_by(model, dgp_spec, sample, SV, cross_corr, variable) %>%
summarise(importance = mean(importance))
a4_aspect_ratio <- 1.5
## Plots showing that quantile loss is better
all_loss_df_averaged %>%
ungroup() %>%
mutate(sample = as.factor(sample)) %>%
ggplot() +
geom_bar(aes(x = model, y = test_MAE, fill = sample), stat = "identity", position = position_dodge()) +
scale_x_discrete(label = labels, breaks = breaks) +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_brewer(palette = "Paired") +
facet_grid(rows = vars(cross_corr), cols = vars(dgp_spec))
breaks <- levels(all_loss_df_averaged$model)
labels <- as.expression(breaks)
labels[[2]] <- bquote(bold(.(labels[[2]])))
labels[[4]] <- bquote(bold(.(labels[[4]])))
labels[[6]] <- bquote(bold(.(labels[[6]])))
labels[[16]] <- bquote(bold(.(labels[[16]])))
## Plots showing that quantile loss is better
all_loss_df_averaged %>%
ungroup() %>%
mutate(sample = as.factor(sample)) %>%
ggplot() +
geom_bar(aes(x = model, y = test_MAE, fill = sample), stat = "identity", position = position_dodge()) +
scale_x_discrete(label = labels, breaks = breaks) +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_brewer(palette = "Paired") +
facet_grid(rows = vars(cross_corr), cols = vars(dgp_spec))
ggsave(filename = "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/Results/simulation_test_mae.pdf",
width = 15 * a4_aspect_ratio, height = 15, units = "cm")
all_loss_df_averaged %>%
ungroup() %>%
mutate(sample = as.factor(sample)) %>%
ggplot() +
geom_bar(aes(x = model, y = test_RMSE, fill = sample), stat = "identity", position = position_dodge()) +
scale_x_discrete(label = labels, breaks = breaks) +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_brewer(palette = "Paired") +
facet_grid(rows = vars(cross_corr), cols = vars(dgp_spec))
ggsave(filename = "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/Results/simulation_test_rmse.pdf",
width = 15 * a4_aspect_ratio, height = 15, units = "cm")
all_loss_df_averaged %>%
ungroup() %>%
mutate(sample = as.factor(sample)) %>%
ggplot() +
geom_bar(aes(x = model, y = test_RSquare, fill = sample), stat = "identity", position = position_dodge()) +
scale_x_discrete(label = labels, breaks = breaks) +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_brewer(palette = "Paired") +
facet_grid(rows = vars(cross_corr), cols = vars(dgp_spec))
ggsave(filename = "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/Results/simulation_test_rsquare.pdf",
width = 15 * a4_aspect_ratio, height = 15, units = "cm")
library(tidyverse)
library(jsonlite)
library(Metrics)
library(caret)
library(lubridate)
## Multicore Setup
library(foreach)
library(doFuture)
#Registering
registerDoFuture()
plan(multisession)
tidy_to_json <- function(data, start) {
stock_id <- data$stock %>%
unique()
# Number of cross sectional units
cross_units <- length(stock_id)
## JUst setting the beginning time to something arbitrary for now, change if needed
pooled_panel_json <- data.frame(start = rep(start, cross_units),
target = c(1:cross_units),
dynamic_feat = c(1:cross_units))
pooled_panel_json <- foreach(i = 1:cross_units, .combine = "rbind") %dopar% {
pooled_panel_filter <- data %>%
filter(stock == stock_id[i])
pooled_panel_filter_feature <- pooled_panel_filter %>%
select(-time, -rt, -stock) %>%
unname() %>%
as.matrix() %>%
# Transpose it to get the right format of one feature series per row
t()
data.frame(start = start, target = list(pooled_panep_filter$rt), dynamic_feat = list(pooled_panel_filter_feature))
}
pooled_panel_json
}
pooled_panel %>% tidy_to_json(start = "2000-01-01")
tidy_to_json <- function(data, start) {
stock_id <- data$stock %>%
unique()
# Number of cross sectional units
cross_units <- length(stock_id)
## JUst setting the beginning time to something arbitrary for now, change if needed
pooled_panel_json <- data.frame(start = rep(start, cross_units),
target = c(1:cross_units),
dynamic_feat = c(1:cross_units))
pooled_panel_json <- foreach(i = 1:cross_units, .combine = "rbind") %dopar% {
pooled_panel_filter <- data %>%
filter(stock == stock_id[i])
pooled_panel_filter_feature <- pooled_panel_filter %>%
select(-time, -rt, -stock) %>%
unname() %>%
as.matrix() %>%
# Transpose it to get the right format of one feature series per row
t()
data.frame(start = start, target = list(pooled_panel_filter$rt), dynamic_feat = list(pooled_panel_filter_feature))
}
pooled_panel_json
}
pooled_panel %>% tidy_to_json(start = "2000-01-01")
tidy_to_json <- function(data, start) {
stock_id <- data$stock %>%
unique()
# Number of cross sectional units
cross_units <- length(stock_id)
## JUst setting the beginning time to something arbitrary for now, change if needed
pooled_panel_json <- data.frame(start = rep(start, cross_units),
target = c(1:cross_units),
dynamic_feat = c(1:cross_units))
pooled_panel_json <- foreach(i = 1:cross_units, .combine = "rbind") %dopar% {
pooled_panel_filter <- data %>%
filter(stock == stock_id[i])
pooled_panel_filer_rt <- pooled_panel_filter$rt %>% list()
pooled_panel_filter_feature <- pooled_panel_filter %>%
select(-time, -rt, -stock) %>%
unname() %>%
as.matrix() %>%
# Transpose it to get the right format of one feature series per row
t() %>%
list()
data.frame(start = start, target = pooled_panel_filter_rt, dynamic_feat = pooled_filter_feature)
}
pooled_panel_json
}
pooled_panel_train <- pooled_panel %>%
filter(time %in% timeSlices[[1]]$train) %>%
tidy_to_json(start = "2000-01-01")
tidy_to_json <- function(data, start) {
stock_id <- data$stock %>%
unique()
# Number of cross sectional units
cross_units <- length(stock_id)
## JUst setting the beginning time to something arbitrary for now, change if needed
pooled_panel_json <- data.frame(start = rep(start, cross_units),
target = c(1:cross_units),
dynamic_feat = c(1:cross_units))
pooled_panel_json <- foreach(i = 1:cross_units, .combine = "rbind") %dopar% {
pooled_panel_filter <- data %>%
filter(stock == stock_id[i])
pooled_panel_filter_rt <- pooled_panel_filter$rt %>% list()
pooled_panel_filter_feature <- pooled_panel_filter %>%
select(-time, -rt, -stock) %>%
unname() %>%
as.matrix() %>%
# Transpose it to get the right format of one feature series per row
t() %>%
list()
data.frame(start = start, target = pooled_panel_filter_rt, dynamic_feat = pooled_filter_feature)
}
pooled_panel_json
}
pooled_panel_train <- pooled_panel %>%
filter(time %in% timeSlices[[1]]$train) %>%
tidy_to_json(start = "2000-01-01")
tidy_to_json <- function(data, start) {
stock_id <- data$stock %>%
unique()
# Number of cross sectional units
cross_units <- length(stock_id)
## JUst setting the beginning time to something arbitrary for now, change if needed
pooled_panel_json <- data.frame(start = rep(start, cross_units),
target = c(1:cross_units),
dynamic_feat = c(1:cross_units))
pooled_panel_json <- foreach(i = 1:cross_units, .combine = "rbind") %dopar% {
pooled_panel_filter <- data %>%
filter(stock == stock_id[i])
pooled_panel_filter_rt <- pooled_panel_filter$rt %>% list()
pooled_panel_filter_feature <- pooled_panel_filter %>%
select(-time, -rt, -stock) %>%
unname() %>%
as.matrix() %>%
# Transpose it to get the right format of one feature series per row
t() %>%
list()
data.frame(start = start, target = pooled_panel_filter_rt, dynamic_feat = pooled_panel_filter_feature)
}
pooled_panel_json
}
pooled_panel_train <- pooled_panel %>%
filter(time %in% timeSlices[[1]]$train) %>%
tidy_to_json(start = "2000-01-01")
tidy_to_json <- function(data, start) {
stock_id <- data$stock %>%
unique()
# Number of cross sectional units
cross_units <- length(stock_id)
## JUst setting the beginning time to something arbitrary for now, change if needed
pooled_panel_json <- data.frame(start = rep(start, cross_units),
target = c(1:cross_units),
dynamic_feat = c(1:cross_units))
pooled_panel_json <- foreach(i = 1:cross_units, .combine = "rbind") %dopar% {
df <- data.frame(start = 0, target = 0, dynamic_feat = 0)
pooled_panel_filter <- data %>%
filter(stock == stock_id[i])
pooled_panel_filter_rt <- pooled_panel_filter$rt %>% list()
pooled_panel_filter_feature <- pooled_panel_filter %>%
select(-time, -rt, -stock) %>%
unname() %>%
as.matrix() %>%
# Transpose it to get the right format of one feature series per row
t() %>%
list()
df$start <- start
df$target <- pooled_panel_filter_rt
df$dynamic_feat <- pooled_panel_filter_feature
df
}
pooled_panel_json
}
pooled_panel_train <- pooled_panel %>%
filter(time %in% timeSlices[[1]]$train) %>%
tidy_to_json(start = "2000-01-01")
View(pooled_panel_train)
?enframe
test_list <- rep(list(0), 10)
for (i in 1:10) {
test_list[[i]] <- matrix(rnorm(100, 0, 1), 10, 10)
}
View(test_list)
enframe(test_list)
enframe(test_list)$value
rbind(test_list[[1]], test_list[[2]])
do.call(test_list, rbind())
?do.call
do.call(rbind, test_list)
?map
test_list[[1]]
test_list[1]
a <- test_list[1]
a[1]
a[[1]]
foreach(i = 1:length(test_list), .combine = "rbind") %do% {
test_list[[i]]
}
library(foreach)
foreach(i = 1:length(test_list), .combine = "cbind") %do% {
test_list[[i]]
}
foreach(i = 1:length(test_list), .combine = "rbind") %do% {
test_list[[i]] <- test_list[[i]]^2
test_list[[i]]
}
knitr::opts_chunk$set(echo = TRUE)
################
##Load Libraries
################
library(tidyverse)
library(keras)
library(quantreg)
library(ggplot2)
library(forecast)
library(rlist)
library(Metrics)
library(ranger)
library(caret)
library(forcats)
library(xtable)
library(randomForestSRC)
library(xts)
library(uwot)
library(rugarch)
#Parallel Computing
library(foreach)
library(doFuture)
#Registering
registerDoFuture()
plan(multisession)
set.seed(27935248)
g3_A1_nosv_0 <- readRDS("~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Simulated_dataset/g3_A1_nosv_0.RDS")
#######
g1_A1_sv_0.01 <- readRDS("~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Simulated_dataset/g1_A1_sv_0.01.RDS")
batch_process_range <- c(6:10)
g3_A1_nosv_0_LSTM_results_610 <- fit_all_models_lstm(g3_A1_nosv_0, batch_process_range)
saveRDS(g3_A1_nosv_0_LSTM_results_610, "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Model_results/g3_A1_nosv_0_LSTM_results_610.rds")
g1_A1_sv_0.01_LSTM_results_610 <- fit_all_models_lstm(g1_A1_sv_0.01, batch_process_range)
saveRDS(g1_A1_sv_0.01_LSTM_results_610, "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Model_results/g1_A1_sv_0.01_LSTM_results_610.rds")
knitr::opts_chunk$set(echo = TRUE)
################
##Load Libraries
################
library(tidyverse)
library(keras)
library(quantreg)
library(ggplot2)
library(forecast)
library(rlist)
library(Metrics)
library(ranger)
library(caret)
library(forcats)
library(xtable)
library(randomForestSRC)
library(xts)
library(uwot)
library(rugarch)
#Parallel Computing
library(foreach)
library(doFuture)
#Registering
registerDoFuture()
plan(multisession)
set.seed(27935248)
g2_A1_sv_0.01 <- readRDS("~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Simulated_dataset/g2_A1_sv_0.01.RDS")
g3_A1_sv_0.01 <- readRDS("~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Simulated_dataset/g3_A1_sv_0.01.RDS")
batch_process_range <- c(6:10)
g2_A1_sv_0.01_LSTM_results_610 <- fit_all_models_lstm(g2_A1_sv_0.01, batch_process_range)
saveRDS(g2_A1_sv_0.01_LSTM_results_610, "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Model_results/g2_A1_sv_0.01_LSTM_results_610.rds")
g3_A1_sv_0.01_LSTM_results_610 <- fit_all_models_lstm(g3_A1_sv_0.01, batch_process_range)
saveRDS(g3_A1_sv_0.01_LSTM_results_610, "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Model_results/g3_A1_sv_0.01_LSTM_results_610.rds")
knitr::opts_chunk$set(echo = TRUE)
################
##Load Libraries
################
library(tidyverse)
library(keras)
library(quantreg)
library(ggplot2)
library(forecast)
library(rlist)
library(Metrics)
library(ranger)
library(caret)
library(forcats)
library(xtable)
library(randomForestSRC)
library(xts)
library(uwot)
library(rugarch)
#Parallel Computing
library(foreach)
library(doFuture)
#Registering
registerDoFuture()
plan(multisession)
set.seed(27935248)
g1_A1_sv_0.1 <- readRDS("~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Simulated_dataset/g1_A1_sv_0.1.RDS")
g2_A1_sv_0.1 <- readRDS("~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Simulated_dataset/g2_A1_sv_0.1.RDS")
g1_A1_sv_0.1_LSTM_results_610 <- fit_all_models_lstm(g1_A1_sv_0.1, batch_process_range)
saveRDS(g1_A1_sv_0.1_LSTM_results_610, "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Model_results/g1_A1_sv_0.1_LSTM_results_610.rds")
g2_A1_sv_0.1_LSTM_results_610 <- fit_all_models_lstm(g2_A1_sv_0.1, batch_process_range)
saveRDS(g2_A1_sv_0.1_LSTM_results_610, "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Model_results/g2_A1_sv_0.1_LSTM_results_610.rds")
knitr::opts_chunk$set(echo = TRUE)
################
##Load Libraries
################
library(tidyverse)
library(keras)
library(quantreg)
library(ggplot2)
library(forecast)
library(rlist)
library(Metrics)
library(ranger)
library(caret)
library(forcats)
library(xtable)
library(randomForestSRC)
library(xts)
library(uwot)
library(rugarch)
#Parallel Computing
library(foreach)
library(doFuture)
#Registering
registerDoFuture()
plan(multisession)
set.seed(27935248)
g3_A1_sv_0.1 <- readRDS("~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Simulated_dataset/g3_A1_sv_0.1.RDS")
#######
g1_A1_sv_1 <- readRDS("~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Simulated_dataset/g1_A1_sv_1.RDS")
g3_A1_sv_0.1_LSTM_results_610 <- fit_all_models_lstm(g3_A1_sv_0.1, batch_process_range)
saveRDS(g3_A1_sv_0.1_LSTM_results_610, "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Model_results/g3_A1_sv_0.1_LSTM_results_610.rds")
g1_A1_sv_1_LSTM_results_610 <- fit_all_models_lstm(g1_A1_sv_1, batch_process_range)
saveRDS(g1_A1_sv_1_LSTM_results_610, "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Model_results/g1_A1_sv_1_LSTM_results_610.rds")
g2_A1_sv_0.01_DEEPAR_results <- readRDS("~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Model_results/g2_A1_sv_0.01_DEEPAR_results.RDS")
g2_A1_sv_0.01_DEEPAR_results[[1]]$DEEPAR_MSE
