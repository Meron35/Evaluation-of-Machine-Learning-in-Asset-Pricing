X_array[1, 1, ] <- pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
array(dim = c(1, 1, 80000))
X_array <- array(data = 0, dim = c(train_length, 1, 80000))
X_array[1, 1, ] <- pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
array(dim = c(1, 1, 80000))
pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
array(dim = c(1, 1, 80000))
pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
as.numeric(  )
pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock)
pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
as.vector()
pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
as.vector() %>%
dim()
X_array[1, 1, ] <- pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
as.vector()
pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
length()
pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
as.matrix()
pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
as.matrix() %>%
as.vector()
pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
as.matrix() %>%
as.vector() %>%
length()
X_array[1, 1, ] <- pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
as.matrix() %>%
as.vector()
X_array[1, , ] <- pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
as.matrix() %>%
as.vector()
X_array <- array(data = 0, dim = c(train_length, 1, 80000))
X_array[1, 1, ] <- pooled_panel %>%
filter(time == 2) %>%
dplyr::select(-rt, -time, -stock) %>%
as.matrix() %>%
as.vector()
object.size(pooled_panel)
X_array[[1]]
X_array[1, 1, ]
for(t in 1:train_length) {
X_array[t, 1, ] <- pooled_panel %>%
filter(time == t+1) %>%
dplyr::select(-rt, -time, -stock) %>%
as.matrix() %>%
as.vector()
}
for(t in 1:train_length) {
Y_array[t, ] <- pooled_panel %>%
filter(time == t+1) %>%
dplyr::select(rt)
}
Y_array[t, ] <- pooled_panel %>%
filter(time == t+1) %>%
dplyr::select(rt) %>%
as.matrix()
Y_array[t, ] <- pooled_panel %>%
filter(time == t+1) %>%
dplyr::select(rt) %>%
as.matrix() %>%
as.vector()
Y_array <- array(data = 0, dim = c(train_length, 200))
for(t in 1:train_length) {
Y_array[t, ] <- pooled_panel %>%
filter(time == t+1) %>%
dplyr::select(rt) %>%
as.matrix() %>%
as.vector()
}
View(Y_array)
?layer_lstm
lstm_model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(1, dim(X_array)[3])) %>%
layer_activation("tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
layer_dense(units = 128) %>%
layer_activation("tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
layer_dense(units = 200) %>%
layer_activation("linear")
lstm_model %>% compile(loss = "mse",
optimizer = optimizer_adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999),
metrics = list("mae", "mse"))
lstm_model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(1, dim(X_array)[3])) %>%
layer_activation("tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
layer_dense(units = 128) %>%
layer_activation("tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
layer_dense(units = 200) %>%
layer_activation("linear")
l1_penalty <- 0.01
lstm_model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(1, dim(X_array)[3])) %>%
layer_activation("tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
layer_dense(units = 128) %>%
layer_activation("tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
layer_dense(units = 200) %>%
layer_activation("linear")
dim(X_array)[3]
lstm_model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(1, dim(X_array)[3])) %>%
layer_activation("tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
layer_dense(units = 128) %>%
layer_activation("tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
layer_dense(units = 200) %>%
layer_activation("linear")
stock_1 <- pooled_panel %>%
filter(stock == "stock_1")
View(stock_1)
?ugarch_spec
?ugarchspec
stock_1 <- pooled_panel %>%
filter(stock == "stock_1") %>%
as.xts()
library(xts)
stock_1 <- pooled_panel %>%
filter(stock == "stock_1") %>%
as.xts()
?as.xts
data(sample_matrix)
View(sample_matrix)
pooled_panel %>%
filter(stock == "stock_1") %>%
as.xts()
pooled_panel %>%
filter(stock == "stock_1")
pooled_panel %>%
filter(stock == "stock_1") %>%
xts()
sample.xts <- as.xts(sample_matrix)
View(sample.xts)
dimnames(sample_matrix)
dimnames(stock_1)
stock_1[-1:3]
stock_1[-1:3,]
stock_1[-(1:3),]
stock_1[,-(1:3)]
ugarch_spec <- ugarchspec(variance.model = list(model = "gjrGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = stock_1[,-(1:3)],
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(0, 0),
include.mean = TRUE,
external.regressors = NULL,
start.pars = list(),
fixed.pars = list()),
distribution.model = "std")
AR1_GARCH_1_1_t_model <- ugarchfit(spec = ugarch_spec,
data = stock_1$rt,
solver.control = list(trace=0))
show(AR1_GARCH_1_1_t_model)
ugarch_spec <- ugarchspec(variance.model = list(model = "gjrGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(0, 0),
include.mean = TRUE,
external.regressors = stock_1[,-(1:3)],
start.pars = list(),
fixed.pars = list()),
distribution.model = "std")
AR1_GARCH_1_1_t_model <- ugarchfit(spec = ugarch_spec,
data = stock_1$rt,
solver.control = list(trace=0))
show(AR1_GARCH_1_1_t_model)
stock_1_xts <- as.xts(stock_1[,-(1:3)])
stock_1_xts <- as.xts(stock_1[,-(1:3)], order.by = index(x))
stock_1_xts <- as.xts(stock_1[,-(1:3)], order.by = index(stock_1))
stock_1_xts <- as.xts(stock_1[,-(1:3)], order.by = as.Date(stock_1$time))
as.Date(stock_1$time)
ugarch_spec <- ugarchspec(variance.model = list(model = "gjrGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(0, 0),
include.mean = TRUE,
external.regressors = stock_1_xts,
start.pars = list(),
fixed.pars = list()),
distribution.model = "std")
AR1_GARCH_1_1_t_model <- ugarchfit(spec = ugarch_spec,
data = stock_1$rt,
solver.control = list(trace=0))
show(AR1_GARCH_1_1_t_model)
View(stock_1_xts)
stock_1_xts <- as.xts(stock_1[,4:103], order.by = as.Date(stock_1$time))
ugarch_spec <- ugarchspec(variance.model = list(model = "gjrGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(0, 0),
include.mean = TRUE,
external.regressors = stock_1_xts,
start.pars = list(),
fixed.pars = list()),
distribution.model = "std")
AR1_GARCH_1_1_t_model <- ugarchfit(spec = ugarch_spec,
data = stock_1$rt,
solver.control = list(trace=0))
show(AR1_GARCH_1_1_t_model)
ugarch_spec <- ugarchspec(variance.model = list(model = "GARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(0, 0),
include.mean = TRUE,
external.regressors = stock_1_xts,
start.pars = list(),
fixed.pars = list()),
distribution.model = "std")
ugarch_spec <- ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(0, 0),
include.mean = TRUE,
external.regressors = stock_1_xts,
start.pars = list(),
fixed.pars = list()),
distribution.model = "std")
AR1_GARCH_1_1_t_model <- ugarchfit(spec = ugarch_spec,
data = stock_1$rt,
solver.control = list(trace=0))
ugarch_spec <- ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(0, 0),
include.mean = TRUE,
external.regressors = stock_1_xts),
distribution.model = "std")
# Trimming down the number of factors makes it so that convergence is possible, but the fit is awful
stock_1_xts <- as.xts(stock_1[,4:103], order.by = as.Date(stock_1$time))
AR1_GARCH_1_1_t_model <- ugarchfit(spec = ugarch_spec,
data = stock_1$rt,
solver.control = list(trace=0))
show(AR1_GARCH_1_1_t_model)
ugarch_spec <- ugarchspec(variance.model = list(model = "gjrGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(0, 0),
include.mean = TRUE,
external.regressors = stock_1_xts),
distribution.model = "std")
AR1_GARCH_1_1_t_model <- ugarchfit(spec = ugarch_spec,
data = stock_1$rt,
solver.control = list(trace=0))
show(AR1_GARCH_1_1_t_model)
AIC(AR1_GARCH_1_1_t_model)
?ugarchfit
infocriteria(AR1_GARCH_1_1_t_model)
# rugarch
ugarch_spec <- ugarchspec(variance.model = list(model = "gjrGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(0, 0),
include.mean = TRUE,
external.regressors = NULL),
distribution.model = "std")
AR1_GARCH_1_1_t_model <- ugarchfit(spec = ugarch_spec,
data = stock_1$rt,
solver.control = list(trace=0))
show(AR1_GARCH_1_1_t_model)
library(tsfeatures)
install.packages("tsfeatures")
library(tfeatures)
library(tsfeatures)
devtools::install_github("robjhyndman/M4metalearning")
install_github("robjhyndman/M4metalearning")
tsfeatures(stock_1$rt,
features = c("acf"))
## THA_features function from Meta4learning dev package
THA_features <-
function(dataset, n.cores=1) {
list_process_fun <- lapply
cl = -1
require(tsfeatures)
if (n.cores > 1) {
cl <- parallel::makeCluster(n.cores)
#parallel::clusterExport(cl, varlist="dataset", envir=environment())
parallel::clusterExport(cl, varlist=ls(), envir=environment())
parallel::clusterExport(cl, varlist=ls(envir=environment(THA_features)),
envir = environment(THA_features))
parallel::clusterCall(cl, function() library(tsfeatures)) #required to find functions within tsfeatures
list_process_fun <- function(my_list, ...) {
parallel::parLapplyLB(cl, my_list, ...)
}
}
dataset_feat <- list_process_fun(dataset,
function (serdat) {
tryCatch({
#additional features from Talagala, Hyndman, Athanasopoulos 2018
featrow <-
tsfeatures::tsfeatures(
serdat$x,
features = c(
"acf_features",
"arch_stat",
"crossing_points",
"entropy",
"flat_spots",
"heterogeneity_tsfeat_workaround",
"holt_parameters",
"hurst",
"lumpiness",
"nonlinearity",
"pacf_features",
"stl_features",
"stability",
"hw_parameters_tsfeat_workaround",
"unitroot_kpss",
"unitroot_pp"
)
)
#additional features
series_length <- length(serdat$x)
featrow <- tibble::add_column(
featrow,
"series_length" = series_length)
featrow[is.na(featrow)] <-
0 #SET NAs TO 0 ?
#adding dummy variables for non seasonal series
#that are not output by tsfeatures
if (length(featrow) == 37) {
featrow <- tibble::add_column(featrow, "seas_acf1" = 0, .before = 7)
featrow <- tibble::add_column(featrow, "seas_pacf" =
0, .before = 24)
featrow = tibble::add_column(
featrow,
"seasonal_strength" = 0,
"peak" = 0,
"trough" = 0,
.before=33)
}
serdat$features <- featrow
serdat
}, error = function(e) {
print(e)
return(e)
})
})
if (n.cores > 1) {
parallel::stopCluster(cl)
}
dataset_feat
}
THA_features(stock$rt)
THA_features(stock_1$rt)
## THA_features function from Meta4learning dev package
THA_features <-
function(dataset, n.cores=1) {
list_process_fun <- lapply
cl = -1
require(tsfeatures)
if (n.cores > 1) {
cl <- parallel::makeCluster(n.cores)
#parallel::clusterExport(cl, varlist="dataset", envir=environment())
parallel::clusterExport(cl, varlist=ls(), envir=environment())
parallel::clusterExport(cl, varlist=ls(envir=environment(THA_features)),
envir = environment(THA_features))
parallel::clusterCall(cl, function() library(tsfeatures)) #required to find functions within tsfeatures
list_process_fun <- function(my_list, ...) {
parallel::parLapplyLB(cl, my_list, ...)
}
}
dataset_feat <- list_process_fun(dataset,
function (serdat) {
tryCatch({
#additional features from Talagala, Hyndman, Athanasopoulos 2018
featrow <-
tsfeatures::tsfeatures(
serdat,
features = c(
"acf_features",
"arch_stat",
"crossing_points",
"entropy",
"flat_spots",
"heterogeneity_tsfeat_workaround",
"holt_parameters",
"hurst",
"lumpiness",
"nonlinearity",
"pacf_features",
"stl_features",
"stability",
"hw_parameters_tsfeat_workaround",
"unitroot_kpss",
"unitroot_pp"
)
)
#additional features
series_length <- length(serdat$x)
featrow <- tibble::add_column(
featrow,
"series_length" = series_length)
featrow[is.na(featrow)] <-
0 #SET NAs TO 0 ?
#adding dummy variables for non seasonal series
#that are not output by tsfeatures
if (length(featrow) == 37) {
featrow <- tibble::add_column(featrow, "seas_acf1" = 0, .before = 7)
featrow <- tibble::add_column(featrow, "seas_pacf" =
0, .before = 24)
featrow = tibble::add_column(
featrow,
"seasonal_strength" = 0,
"peak" = 0,
"trough" = 0,
.before=33)
}
serdat$features <- featrow
serdat
}, error = function(e) {
print(e)
return(e)
})
})
if (n.cores > 1) {
parallel::stopCluster(cl)
}
dataset_feat
}
THA_features(stock_1$rt)
heterogeneity_tsfeat_workaround <- function(x) {
output <- c(arch_acf =0, garch_acf=0, arch_r2=0, garch_r2=0)
try( output <- tsfeatures::heterogeneity(x) )
output
}
#' @export
hw_parameters_tsfeat_workaround <- function(x) {
hw_fit <- NULL
hw_fit$par <- c(NA, NA, NA)
try(hw_fit <- forecast::ets(x, model=c("AAA")), silent=TRUE)
names(hw_fit$par) <- c("hw_alpha", "hw_beta" , "hw_gamma")
hw_fit$par[1:3]
}
THA_features(stock_1$rt)
THA_features(as.ts(stock_1$rt))
tsfeatures(stock_1$rt,
features = c("acf_features",
"arch_stat",
"crossing_points",
"entropy",
"flat_spots",
"heterogeneity_tsfeat_workaround",
"holt_parameters",
"hurst",
"lumpiness",
"nonlinearity",
"pacf_features",
"stl_features",
"stability",
"hw_parameters_tsfeat_workaround",
"unitroot_kpss",
"unitroot_pp"))
