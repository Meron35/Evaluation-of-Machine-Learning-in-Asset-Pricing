#Initialize List
RF_model_grid <- rep(list(0), nrow(RF_grid))
for (i in 1:nrow(RF_grid)) {
RF_model_grid[[i]] <- list(RF_grid = 0, model = 0)
#MSE Case
if (loss_function == "mse") {
RF <- rfsrc(f, train,
#Hyperparameters
ntree = RF_grid$ntree[i],
mtry = RF_grid$mtry[i],
nodesize = RF_grid$nodesize[i],
splitrule = "mse"
)
#RF_model_grid[[i]]$model <- RF
RF_model_grid[[i]]$RF_grid <- cbind(RF_grid[i, ],
#Train Loss
train_loss = mse(train$rt, predict(RF)$predicted),
#Validation Loss
validation_loss = mse(validation$rt, predict(RF, newdata = validation)$predicted)
)
} else {
#MAE Case
RF <- rfsrc(f, train,
#Hyperparameters
ntree = RF_grid$ntree[i],
mtry = RF_grid$mtry[i],
nodesize = RF_grid$nodesize[i],
splitrule = "quantile.regr",
prob = 0.5
)
#RF_model_grid[[i]]$model <- RF
RF_model_grid[[i]]$RF_grid <- cbind(RF_grid[i, ],
#Train Loss
train_loss = mae(train$rt, predict(RF)$predicted),
#Validation Loss
validation_loss = mae(validation$rt, predict(RF, newdata = validation)$predicted)
)
}
}
return(RF_model_grid)
}
#Returns the dataframe row containing the "best" hyperparameters
get_RF_best_tune <- function(RF_model_grid) {
RF_tune_grid <- RF_model_grid[[1]]$RF_grid
for (i in 2:length(RF_model_grid)) {
RF_tune_grid <- rbind(RF_tune_grid, RF_model_grid[[i]]$RF_grid)
}
return(RF_tune_grid[which.min(RF_tune_grid$validation_loss), ])
}
RF_fit_stats <- function(pooled_panel, RF_grid, timeSlices, loss_function) {
#Initialize
RF_stats <- rep(list(0), 3)
f <- panel_formula(pooled_panel)
#Load training, validation and test sets
for (set in 1:3) {
RF_stats[[set]] <- list(loss_stats = data.frame(train_MAE = 0, train_MSE = 0, train_RMSE = 0, train_RSquare = 0,
validation_MAE = 0, validation_MSE = 0, validation_RMSE = 0, validation_RSquare = 0,
test_MAE = 0, test_MSE = 0, test_RMSE = 0, test_RSquare = 0),
#Other useful things
forecast_resids = 0,
model = 0,
hyperparameters = 0,
variable_importance = 0)
train <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$train)
validation <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$validation)
test <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$test)
#Fit on training Set over grid of hyperparameters
model_grid <- RF_fit_model_grid(f, train, validation, RF_grid, loss_function)
#Get the best hyperparameters
best_model_params <- get_RF_best_tune(model_grid)
RF_stats[[set]]$hyperparameters <- best_model_params
#Compute the optimal model
if (loss_function == "mse") {
model <- rfsrc(f, train,
#Hyperparameters
ntree = best_model_params$ntree,
mtry = best_model_params$mtry,
nodesize = best_model_params$nodesize,
splitrule = "mse",
bootstrap = "by.root", samptype = "swr"
)
} else {
model <- rfsrc(f, train,
#Hyperparameters
ntree = best_model_params$ntree,
mtry = best_model_params$mtry,
nodesize = best_model_params$nodesize,
splitrule = "quantile.regr",
prob = 0.5,
bootstrap = "by.root", samptype = "swr"
)
}
RF_stats[[set]]$model <- model
#Train
train_predict <- predict(model, train)$predicted
RF_stats[[set]]$loss_stats$train_MAE <- mae(train$rt, train_predict)
RF_stats[[set]]$loss_stats$train_MSE <- mse(train$rt, train_predict)
RF_stats[[set]]$loss_stats$train_RMSE <- rmse(train$rt, train_predict)
RF_stats[[set]]$loss_stats$train_RSquare <- (1 - sse(train$rt, train_predict) / sum((train$rt - mean(train$rt))^2))
#Validation
valid_predict <- predict(model, newdata = validation)$predicted
RF_stats[[set]]$loss_stats$validation_MAE <- mae(validation$rt, valid_predict)
RF_stats[[set]]$loss_stats$validation_MSE <- mse(validation$rt, valid_predict)
RF_stats[[set]]$loss_stats$validation_RMSE <- rmse(validation$rt, valid_predict)
RF_stats[[set]]$loss_stats$validation_RSquare <- (1 - sse(validation$rt, valid_predict) / sum((validation$rt - mean(validation$rt))^2))
#Test
test_predict <- predict(model, newdata = test)$predicted
RF_stats[[set]]$loss_stats$test_MAE <- mae(test$rt, test_predict)
RF_stats[[set]]$loss_stats$test_MSE <- mse(test$rt, test_predict)
RF_stats[[set]]$loss_stats$test_RMSE <- rmse(test$rt, test_predict)
RF_stats[[set]]$loss_stats$test_RSquare <- (1 - sse(test$rt, test_predict) / sum((test$rt - mean(test$rt))^2))
#Forecast residuals
RF_stats[[set]]$forecast_resids <- rf_ave_forecast_resids(rf_model = model, test = test)
#Variable Importance
RF_stats[[set]]$variable_importance <- RF_variable_importance(test, model)
}
return(RF_stats)
}
# Neural Networks
set.seed(27935248)
#Build neural networks with neuron numbers according to geometric pyramid rule, and ReLU activation function for all layers
# IE Input layer > 32 neurons > 16 neurons > 8 neurons > 4 neurons > 2 neurons > output
##Neural Network generalized
NNet_fit_stats <- function(pooled_panel, timeSlices, hidden_layers, loss_function, batch_size, patience) {
#Initialize
NNet_stats <- rep(list(0), 3)
for (set in 1:3) {
NNet_stats[[set]] <- list(loss_stats = data.frame(train_MAE = 0, train_MSE = 0, train_RMSE = 0, train_RSquare = 0,
validation_MAE = 0, validation_MSE = 0, validation_RMSE = 0, validation_RSquare = 0,
test_MAE = 0, test_MSE = 0, test_RMSE = 0, test_RSquare = 0),
#Other useful things
# Keep forecasts here in for nnet objects to make sure they aren't doing something stupid
forecasts = 0,
forecast_resids = 0,
model = 0,
variable_importance = 0)
#Load Training, validation and test sets
train <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$train)
validation <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$validation)
test<- pooled_panel %>%
filter(time %in% timeSlices[[set]]$test)
train_x <- train[4:ncol(train)]
train_y <- train$rt
validation_x <- validation[4:ncol(validation)]
validation_y <- validation$rt
test_x <- test[4:ncol(test)]
test_y <- test$rt
# Fit the model
# The patience parameter is the amount of epochs to check for improvement.
# Gu et al don't say what their early stopping parameter p is
early_stop <- callback_early_stopping(monitor = "val_loss", patience = patience, restore_best_weights = TRUE)
print_dot_callback <- callback_lambda(
on_epoch_end = function(epoch, logs) {
if (epoch %% 50 == 0) cat("\n")
cat(".")
}
)
l1_penalty <- 0.1
build_NN <- function(hidden_layers, loss_function) {
if (hidden_layers == 1) {
model <- keras_model_sequential() %>%
# Layer 1
layer_dense(units = 32, input_shape = ncol(train_x)) %>%
layer_batch_normalization() %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
# Output Layer
layer_dense(units = 1, activation = "linear")
} else if (hidden_layers == 2) {
model <- keras_model_sequential() %>%
# Layer 1
layer_dense(units = 32, input_shape = ncol(train_x)) %>%
layer_batch_normalization() %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
# Layer 2
layer_dense(units = 16) %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
# Output Layer
layer_dense(units = 1, activation = "linear")
} else if (hidden_layers == 3) {
model <- keras_model_sequential() %>%
# Layer 1
layer_dense(units = 32, input_shape = ncol(train_x)) %>%
layer_batch_normalization() %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
# Layer 2
layer_dense(units = 16) %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
#Layer 3
layer_dense(units = 8) %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
# Output Layer
layer_dense(units = 1, activation = "linear")
} else if (hidden_layers == 4) {
model <- keras_model_sequential() %>%
# Layer 1
layer_dense(units = 32, input_shape = ncol(train_x)) %>%
layer_batch_normalization() %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
# Layer 2
layer_dense(units = 16) %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
#Layer 3
layer_dense(units = 8) %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
#Layer 4
layer_dense(units = 4) %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
# Output Layer
layer_dense(units = 1, activation = "linear")
} else {
model <- keras_model_sequential() %>%
# Layer 1
layer_dense(units = 32, input_shape = ncol(train_x)) %>%
layer_batch_normalization() %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
# Layer 2
layer_dense(units = 16) %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
#Layer 3
layer_dense(units = 8) %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
#Layer 4
layer_dense(units = 4) %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
#Layer 5
layer_dense(units = 2) %>%
layer_activation("relu") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
# Output Layer
layer_dense(units = 1, activation = "linear")
}
model %>% compile(
loss = loss_function,
optimizer = "adam",
metrics = list("mae", "mse")
)
model
}
neural_network <- build_NN(hidden_layers, loss_function)
# Other options used throughout the neural network fitting process are specified here
# Namely, batch size
# In general, larger batch sizes result in faster progress in training, but don't always converge as fast. Smaller batch sizes train slower, but can converge faster.
# Default batch size is 32
neural_network %>% fit(as.matrix(train_x), as.matrix(train_y),
batch_size = batch_size, epochs = 500, verbose = 1,
validation_data = list(as.matrix(validation_x), as.matrix(validation_y)),
callbacks = list(early_stop, print_dot_callback))
#Model
NNet_stats[[set]]$model <- neural_network
#Train
train_predict <- neural_network %>% predict(as.matrix(train_x))
NNet_stats[[set]]$loss_stats$train_MAE <- mae(train$rt, train_predict)
NNet_stats[[set]]$loss_stats$train_MSE <- mse(train$rt, train_predict)
NNet_stats[[set]]$loss_stats$train_RMSE <- rmse(train$rt, train_predict)
NNet_stats[[set]]$loss_stats$train_RSquare <- R2(train_predict, train$rt, form = "traditional")
#Validation
validation_predict <- neural_network %>% predict(as.matrix(validation_x))
NNet_stats[[set]]$loss_stats$validation_MAE <- mae(validation$rt, validation_predict)
NNet_stats[[set]]$loss_stats$validation_MSE <- mse(validation$rt, validation_predict)
NNet_stats[[set]]$loss_stats$validation_RMSE <- rmse(validation$rt, validation_predict)
NNet_stats[[set]]$loss_stats$validation_RSquare <- R2(validation_predict, validation$rt, form = "traditional")
#Test
test_predict <- neural_network %>% predict(as.matrix(test_x))
NNet_stats[[set]]$loss_stats$test_MAE <- mae(test$rt, test_predict)
NNet_stats[[set]]$loss_stats$test_MSE <- mse(test$rt, test_predict)
NNet_stats[[set]]$loss_stats$test_RMSE <- rmse(test$rt, test_predict)
NNet_stats[[set]]$loss_stats$test_RSquare <- R2(test_predict, test$rt, form = "traditional")
#Forecasts
NNet_stats[[set]]$forecasts <- test_predict
#Forecast residuals
NNet_stats[[set]]$forecast_resids <- nnet_ave_forecast_resids(nnet_model = neural_network, test = test)
#Variable Importance
NNet_stats[[set]]$variable_importance <- NNet_variable_importance(test, neural_network)
}
NNet_stats
}
pooled_panel <- g1_A1_panel[[1]]$panel
View(timeSlices)
LM_stats_mse <- LM_fit(pooled_panel, timeSlices, "mse")
LM_stats_mse <- LM_fit(pooled_panel, timeSlices, "mse", f)
f <- panel_formula(pooled_panel)
LM_stats_mse <- LM_fit(pooled_panel, timeSlices, "mse", f)
set <- 1
#Load Training, validation and test sets
train <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$train)
validation <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$validation)
test <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$test)
lm <- speedlm(f, data = train, model = FALSE, fitted = FALSE, y = FALSE)
#Statistics
#Training Set
train_predict <- predict(lm, newdata = train)
################################################
# Linear Model
LM_variable_importance <- function(test, lm_model) {
test_x <- test[4:ncol(test)]
# Specify .packages = "quantreg" here as it seems it isn't supported and therefore is missed by doFuture
variable_importance_df <- foreach(i = (1:ncol(test_x)), .combine = "rbind", .packages = c("speedglm", "quantreg")) %dopar% {
test_x_zero <- test_x
test_x_zero[, i] <- 0
original_R2 <- R2(predict(lm_model, newdata = test_x), test$rt, form = "traditional")
new_R2 <- R2(predict(lm_model, newdata = test_x_zero), test$rt, form = "traditional")
variable_importance <- data.frame(variable = colnames(test_x)[i], importance = (original_R2 - new_R2))
variable_importance
}
variable_importance_df
}
LM_stats_mse <- LM_fit(pooled_panel, timeSlices, "mse", f)
#
LM_stats_mse[[1]]$loss_stats
LM_stats_mse[[2]]$loss_stats
LM_stats_mse[[3]]$loss_stats
ELN_stats_mse <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mse")
?predict.hqreg
eln_ave_forecast_resids <- function(eln_model, test, alpha, lambda) {
time_periods <- unique(test$time)
# Set .combine to "c" to return a vector of results, which is what we want
ave_forecast_resids_vector <- foreach(t = 1:length(time_periods), .combine = "c") %do% {
test_cross_section <- test %>%
filter(time == time_periods[t])
test_cross_section_x <- as.matrix(test_cross_section[4:ncol(test_cross_section)])
residuals <- test_cross_section$rt - predict(eln_model, test_cross_section_x,
alpha = alpha, lambda = lambda)
mean(residuals)
}
ave_forecast_resids_vector
}
ELN_stats_mse <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mse")
?speedlm
ELN_stats_mse[[1]]$loss_stats
g1_A1_panel[[1]]$statistics
ELN_stats_mse[[1]]$model$alpha
ELN_stats_mse[[2]]$loss_stats
ELN_stats_mse[[2]]$model$alpha
ELN_stats_mse[[3]]$loss_stats
ELN_stats_mse[[3]]$model$alpha
ELN_stats_mse[[1]]$variable_importance %>% arrange(desc(importance))
ELN_stats_mse[[2]]$variable_importance %>% arrange(desc(importance))
ELN_stats_mse[[3]]$variable_importance %>% arrange(desc(importance))
pooled_panel <- g1_A1_panel[[1]]$panel
f <- panel_formula(pooled_panel)
ELN_stats_mae <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mae")
ELN_stats_mse <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mse")
ELN_stats_mae[[1]]$loss_stats
ELN_stats_mae[[1]]$model$alpha
ELN_stats_mae[[2]]$loss_stats
ELN_stats_mae[[2]]$model$alpha
ELN_stats_mae[[3]]$loss_stats
ELN_stats_mae[[3]]$model$alpha
ELN_stats_mae[[1]]$variable_importance %>% arrange(desc(importance))
ELN_stats_mae[[2]]$variable_importance %>% arrange(desc(importance))
ELN_stats_mae[[3]]$variable_importance %>% arrange(desc(importance))
gen_W <- function(){
#Generate Lambda Matrix first
# Change the sd parameter here to control the degree of cross sectional correlation
Lambda <- matrix(
data = rnorm(N*4, 0, 0.01),
nrow = N, ncol = 4
)
#Use Lambda to create B matrix
B <- (Lambda) %*% t(Lambda)
B <- B + 1/10*diag(nrow = nrow(B))
# B is now a positive semi definite matrix
# It is therefore a valid covariance matrix
#Decompose it via cholesky to give the lower triangle matrix
# R by default gives the upper triangle, therefore it needs to be transposed
W <- t(chol(B))
return(W)
}
g1_A1_panel <- sim_panel_data(simN,
char_rho_a = 0.5, char_rho_b = 1,
cross_corr = 1, A1, xt_multi = 1, g_function = "g1", theta = matrix(c(0.02, 0.02, 0.02), nrow = 1),
error_sv = 1, error_ep_sd = 1,
error_omega = -1.8, error_gamma = 0.95, error_w = 0.2, error_v_sd = 0.05,
predictor_format = "kronecker")
summary(sim_tune_statistics(g1_A1_panel))
pooled_panel <- g1_A1_panel[[1]]$panel
f <- panel_formula(pooled_panel)
LM_stats_mse <- LM_fit(pooled_panel, timeSlices, "mse", f)
#
LM_stats_mae <- LM_fit(pooled_panel, timeSlices, "mae", f)
#
LM_stats_mse[[1]]$loss_stats
LM_stats_mse[[2]]$loss_stats
LM_stats_mse[[3]]$loss_stats
#
LM_stats_mse[[1]]$variable_importance %>% arrange(desc(importance))
LM_stats_mse[[2]]$variable_importance %>% arrange(desc(importance))
LM_stats_mse[[3]]$variable_importance %>% arrange(desc(importance))
#
LM_stats_mae[[1]]$loss_stats
LM_stats_mae[[2]]$loss_stats
LM_stats_mae[[3]]$loss_stats
#
LM_stats_mae[[1]]$variable_importance %>% arrange(desc(importance))
LM_stats_mae[[2]]$variable_importance %>% arrange(desc(importance))
LM_stats_mae[[3]]$variable_importance %>% arrange(desc(importance))
ELN_stats_mae <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mae")
ELN_stats_mse <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mse")
ELN_stats_mse[[1]]$loss_stats
ELN_stats_mse[[1]]$model$alpha
ELN_stats_mse[[2]]$loss_stats
ELN_stats_mse[[2]]$loss_stats
ELN_stats_mse[[2]]$model$alpha
ELN_stats_mse[[3]]$loss_stats
ELN_stats_mse[[3]]$model$alpha
ELN_stats_mse[[1]]$variable_importance %>% arrange(desc(importance))
ELN_stats_mse[[2]]$variable_importance %>% arrange(desc(importance))
ELN_stats_mse[[3]]$variable_importance %>% arrange(desc(importance))
ELN_stats_mae[[1]]$loss_stats
ELN_stats_mae[[1]]$model$alpha
ELN_stats_mae[[2]]$loss_stats
ELN_stats_mae[[2]]$model$alpha
ELN_stats_mae[[3]]$loss_stats
ELN_stats_mae[[3]]$model$alpha
ELN_stats_mae[[1]]$variable_importance %>% arrange(desc(importance))
ELN_stats_mae[[2]]$variable_importance %>% arrange(desc(importance))
ELN_stats_mae[[2]]$variable_importance %>% arrange(desc(importance))
ELN_stats_mae[[3]]$variable_importance %>% arrange(desc(importance))
RF_grid <- expand.grid(
#ntree usually isn't tuned. Just set to max of computationally feasible
ntree = 100,
mtry = seq(10, round(ncol(pooled_panel[4:ncol(pooled_panel)])/3), 20)
# nodesize = seq(2, 14, 2)
# nodedepth recommended not to be changed
#nodedepth = 1
)
RF_MSE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mse")
rf_ave_forecast_resids <- function(rf_model, test) {
time_periods <- unique(test$time)
# Set .combine to "c" to return a vector of results, which is what we want
ave_forecast_resids_vector <- foreach(t = 1:length(time_periods), .combine = "c") %do% {
test_cross_section <- test %>%
filter(time == time_periods[t])
residuals <- test_cross_section$rt - predict(rf_model, newdata = test_cross_section)
mean(residuals)
}
ave_forecast_resids_vector
}
RF_MSE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mse")
rf_ave_forecast_resids <- function(rf_model, test) {
time_periods <- unique(test$time)
# Set .combine to "c" to return a vector of results, which is what we want
ave_forecast_resids_vector <- foreach(t = 1:length(time_periods), .combine = "c") %do% {
test_cross_section <- test %>%
filter(time == time_periods[t])
residuals <- test_cross_section$rt - predict(rf_model, newdata = test_cross_section)$predicted
mean(residuals)
}
ave_forecast_resids_vector
}
RF_MSE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mse")
RF_MSE[[1]]$loss_stats
RF_MSE[[2]]$loss_stats
RF_MSE[[3]]$loss_stats
RF_MSE[[1]]$variable_importance %>% arrange(desc(importance))
RF_grid <- expand.grid(
#ntree usually isn't tuned. Just set to max of computationally feasible
ntree = 100,
mtry = seq(20, round(ncol(pooled_panel[4:ncol(pooled_panel)])/3), 20)
# nodesize = seq(2, 14, 2)
# nodedepth recommended not to be changed
#nodedepth = 1
)
RF_MAE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mae")
RF_MAE[[1]]$loss_stats
RF_MAE[[2]]$loss_stats
RF_MAE[[3]]$loss_stats
RF_MAE[[2]]$loss_stats
RF_MAE[[1]]$loss_stats
RF_MAE[[2]]$loss_stats
RF_MAE[[3]]$loss_stats
RF_MAE[[1]]$variable_importance %>% arrange(desc(importance))
RF_MAE[[1]]$forecast_resids
?dm.test
dm.test(RF_MSE[[1]]$forecast_resids, RF_MAE[[1]]$forecast_resids)
