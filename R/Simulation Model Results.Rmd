---
title: "Simulation Model Results"
author: "Ze Yu Zhong"
date: "21/07/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
################
##Load Libraries
################

library(tidyverse)
library(keras)
library(quantreg)
library(ggplot2)
library(forecast)
library(rlist)
library(Metrics)
library(ranger)
library(caret)
library(forcats)

#Parallel Computing
library(foreach)
library(doFuture)
#Registering
registerDoFuture()
plan(multisession)

set.seed(27935248)
```

```{r}
# Load Datasets

# Set how many realizations of datasets you wish to process
# Going with 30 for now as this is the rule of thumb for a sufficiently large sample

#batch_process_range <- c(1:30)
batch_process_range <- c(1:10)

# Actual Function
# This function takes a dataset and:
# Runs all possible models across mse and mae loss functions, does NOT save the models (for memory efficiency), and saves the loss statistics, actual forecasts, forecast residuals, and variable importance metrics into a list object
# Fairly straightforward, as the model_fit functions from before do everything for you already
# Ie acts as a very big wrapper/for loop
# Note that a lot number of the models are not multithreaded

fit_all_models <- function(dataset_list, batch_process_range,
                           # Logical arguments specifying which models you want to fit
                           # This is useful if you don't want to fit some of the most intensive methods such as RF and Neural Networks
                           LM, ELN, RF, NNet) {
  # Initialize List
  simulation_results_list <- rep(list(0), length(batch_process_range))
  
  for (batch in (batch_process_range)) {
    
    simulation_results_list[[batch]] <- list(
      # Panel Statistics
      Dataset_stats = 0, 
      # Models
      LM_MSE = 0, LM_MAE = 0,
      ELN_MSE = 0, ELN_MAE = 0,
      RF_MSE = 0, RF_MAE = 0,
      # Neural Networks
      NN1_MSE = 0, NN1_MAE = 0,
      NN2_MSE = 0, NN2_MAE = 0,
      NN3_MSE = 0, NN3_MAE = 0,
      NN4_MSE = 0, NN4_MAE = 0,
      NN5_MSE = 0, NN5_MAE = 0
    )
    
    # Load Dataset
    pooled_panel <- dataset_list[[batch]]$panel
    simulation_results_list[[batch]]$Dataset_stats <- dataset_list[[batch]]$statistics
    simulation_results_list[[batch]]$returns <- pooled_panel$rt
    
    timeSlices <- customTimeSlices(start = 2, initialWindow = 84, horizon = 12, validation_size = 60, test_size = 12, set_no = 3)
    
    f <- panel_formula(pooled_panel)
    
    if (LM == 1) {
      # Linear Models
      simulation_results_list[[batch]]$LM_MSE <- LM_fit(pooled_panel, timeSlices, "mse", f)
      simulation_results_list[[batch]]$LM_MAE <- LM_fit(pooled_panel, timeSlices, "mae", f)
    }
    
    if (ELN == 1) {
      # Penalized Linear Models
    
      alpha_grid <- seq(0, 1, 0.01)
      
      simulation_results_list[[batch]]$ELN_MAE <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mae")
      simulation_results_list[[batch]]$ELN_MSE <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mse")
    }
    
    if (RF == 1) {
      # Random Forests
      RF_grid <- expand.grid(
      #ntree usually isn't tuned. Just set to max of computationally feasible
      ntree = 50,
      mtry = seq(10, ncol(pooled_panel[4:ncol(pooled_panel)])/4, 10)
      # nodesize = seq(2, 14, 2)
      # nodedepth recommended not to be changed
      #nodedepth = 1
      )
    
      simulation_results_list[[batch]]$RF_MSE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mse", f)
      simulation_results_list[[batch]]$RF_MAE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mae", f)
    }
      
    if (NNet == 1) {
      # Neural Networks
      # Commented for now because honours lab computers don't have keras/tensorflow
      
      batch_size <- 32
      patience <- 20
      
      simulation_results_list[[batch]]$NN1_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 1, "mse", batch_size = batch_size, patience = patience)
      simulation_results_list[[batch]]$NN1_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 1, "mae", batch_size = batch_size, patience = patience)
    
      simulation_results_list[[batch]]$NN2_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 2, "mse", batch_size = batch_size, patience = patience)
      simulation_results_list[[batch]]$NN2_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 2, "mae", batch_size = batch_size, patience = patience)
    
      simulation_results_list[[batch]]$NN3_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 3, "mse", batch_size = batch_size, patience = patience)
      simulation_results_list[[batch]]$NN3_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 3, "mae", batch_size = batch_size, patience = patience)
    
      simulation_results_list[[batch]]$NN4_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 4, "mse", batch_size = batch_size, patience = patience)
      simulation_results_list[[batch]]$NN4_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 4, "mae", batch_size = batch_size, patience = patience)
    
      simulation_results_list[[batch]]$NN5_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 5, "mse", batch_size = batch_size, patience = patience)
      simulation_results_list[[batch]]$NN5_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 5, "mae", batch_size = batch_size, patience = patience)
    }
  }
  simulation_results_list
}
```

```{r}
batch_process_range <- c(1:10)

# Random Forest is too intensive, just run the simpler models for now

g1_A1_nosv_0_results <- fit_all_models(g1_A1_nosv_0, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)
g2_A1_nosv_0_results <- fit_all_models(g2_A1_nosv_0, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)
g3_A1_nosv_0_results <- fit_all_models(g3_A1_nosv_0, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)

saveRDS(g1_A1_nosv_0_results, "g1_A1_nosv_0_results.rds")
saveRDS(g2_A1_nosv_0_results, "g2_A1_nosv_0_results.rds")
saveRDS(g3_A1_nosv_0_results, "g3_A1_nosv_0_results.rds")

g1_A1_sv_0.01_results <- fit_all_models(g1_A1_sv_0.01, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)
g2_A1_sv_0.01_results <- fit_all_models(g2_A1_sv_0.01, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)
g3_A1_sv_0.01_results <- fit_all_models(g3_A1_sv_0.01, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)

saveRDS(g1_A1_sv_0.01_results, "g1_A1_sv_0.01_results.rds")
saveRDS(g2_A1_sv_0.01_results, "g2_A1_sv_0.01_results.rds")
saveRDS(g3_A1_sv_0.01_results, "g3_A1_sv_0.01_results.rds")

g1_A1_sv_0.1_results <- fit_all_models(g1_A1_sv_0.1, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)
g2_A1_sv_0.1_results <- fit_all_models(g2_A1_sv_0.1, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)
g3_A1_sv_0.1_results <- fit_all_models(g3_A1_sv_0.1, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)

saveRDS(g1_A1_sv_0.1_results, "g1_A1_sv_0.1_results.rds")
saveRDS(g2_A1_sv_0.1_results, "g2_A1_sv_0.1_results.rds")
saveRDS(g3_A1_sv_0.1_results, "g3_A1_sv_0.1_results.rds")

g1_A1_sv_1_results <- fit_all_models(g1_A1_sv_1, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)
g2_A1_sv_1_results <- fit_all_models(g2_A1_sv_1, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)
g3_A1_sv_1_results <- fit_all_models(g3_A1_sv_1, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)

saveRDS(g1_A1_sv_1_results, "g1_A1_sv_1_results.rds")
saveRDS(g2_A1_sv_1_results, "g2_A1_sv_1_results.rds")
saveRDS(g3_A1_sv_1_results, "g3_A1_sv_1_results.rds")
```

```{r}
## Across the different realizations, compute the average statistics
g1_A1_sv_0.01_results_average <- list(
      # Panel Statistics
      Dataset_stats = 0, 
      # Models
      LM_MSE = 0, LM_MAE = 0,
      ELN_MSE = 0, ELN_MAE = 0,
      RF_MSE = 0, RF_MAE = 0,
      # Neural Networks
      NN1_MSE = 0, NN1_MAE = 0,
      NN2_MSE = 0, NN2_MAE = 0,
      NN3_MSE = 0, NN3_MAE = 0,
      NN4_MSE = 0, NN4_MAE = 0,
      NN5_MSE = 0, NN5_MAE = 0
    )

results_df <- foreach(1 = (1:length(simulation_results)), .combine = "rbind") %do% {
  cbind(realization_no = i)
  rbind(simulation_results[[]])
}

## Given the simulation results list, return a dataframe of loss statistics for a single realization and time slice

c_loss_df <- function(simulation_results, batch, sample) {
  cbind(realization_no = batch, sample = sample, 
      rbind(cbind(model = "LM_MSE", simulation_results[[batch]]$LM_MSE[[sample]]$loss_stats),
            cbind(model = "LM_MAE", simulation_results[[batch]]$LM_MSE[[sample]]$loss_stats),
            
            cbind(model = "ELN_MSE", simulation_results[[batch]]$ELN_MSE[[sample]]$loss_stats),
            cbind(model = "ELN_MAE", simulation_results[[batch]]$ELN_MAE[[sample]]$loss_stats),
            
            cbind(model = "RF_MSE", simulation_results[[batch]]$RF_MSE[[sample]]$loss_stats),
            cbind(model = "RF_MAE", simulation_results[[batch]]$RF_MAE[[sample]]$loss_stats)
            
            # cbind(model = "NN1_MSE", simulation_results[[batch]]$NN1_MSE[[sample]]$loss_stats),
            # cbind(model = "NN1_MAE", simulation_results[[batch]]$NN1_MAE[[sample]]$loss_stats),
            # 
            # cbind(model = "NN2_MSE", simulation_results[[batch]]$NN2_MSE[[sample]]$loss_stats),
            # cbind(model = "NN2_MAE", simulation_results[[batch]]$NN2_MAE[[sample]]$loss_stats),
            # 
            # cbind(model = "NN3_MSE", simulation_results[[batch]]$NN3_MSE[[sample]]$loss_stats),
            # cbind(model = "NN3_MAE", simulation_results[[batch]]$NN3_MAE[[sample]]$loss_stats),
            # 
            # cbind(model = "NN4_MSE", simulation_results[[batch]]$NN4_MSE[[sample]]$loss_stats),
            # cbind(model = "NN4_MAE", simulation_results[[batch]]$NN4_MAE[[sample]]$loss_stats),
            # 
            # cbind(model = "NN5_MSE", simulation_results[[batch]]$NN5_MSE[[sample]]$loss_stats),
            # cbind(model = "NN5_MAE", simulation_results[[batch]]$NN5_MAE[[sample]]$loss_stats)
            )
      )
}

## Function that uses above function to iterate over all samples

c_iterate_samples <- function(simulation_results, batch) {
  foreach(sample = 1:3, .combine = "rbind") %do% {
    c_loss_df(g1_A1_sv_0.01_results, batch, sample)
  }
}

## Function that returns everything in a big dataframe

c_all_results <- function(simulation_results) {
  foreach(batch = 1:10, .combine = "rbind") %do% {
    c_iterate_samples(simulation_results, batch)
  }
}

# Function that averages all statistics over all realizations

average_over_realizations <- function(simulation_results) {
  c_all_results(simulation_results) %>%
    group_by(sample, model) %>%
    summarise(train_MAE = mean(train_MAE), train_MSE = mean(train_MSE), 
              train_RMSE = mean(train_RMSE), train_RSquare = mean(train_RSquare),
              
              validation_MAE = mean(validation_MAE), validation_MSE = mean(validation_MSE), 
              validation_RMSE = mean(validation_RMSE), validation_RSquare = mean(validation_RSquare),
              
              test_MAE = mean(test_MAE), test_MSE = mean(test_MSE), 
              test_RMSE = mean(test_RMSE), test_RSquare = mean(test_RSquare)
              )
}

## Function that appends extra ID columns

append_id_columns <- function(SV, cross_corr, specification, simulation_results) {
  cbind(SV = rep(SV, nrow(average_over_realizations(simulation_results))), 
        cross_corr = rep(cross_corr, nrow(average_over_realizations(simulation_results))),
        dgp_spec = rep(specification, nrow(average_over_realizations(simulation_results))),
        average_over_realizations(simulation_results))
}

all_results_df <- rbind(
  append_id_columns(SV = 0, cross_corr = 0, specification = "g1", simulation_results = g1_A1_nosv_0_results),
  append_id_columns(SV = 0, cross_corr = 0, specification = "g2", simulation_results = g2_A1_nosv_0_results),
  append_id_columns(SV = 0, cross_corr = 0, specification = "g3", simulation_results = g3_A1_nosv_0_results),
  
  append_id_columns(SV = 1, cross_corr = 0.01, specification = "g1", simulation_results = g1_A1_sv_0.01_results),
  append_id_columns(SV = 1, cross_corr = 0.01, specification = "g2", simulation_results = g2_A1_sv_0.01_results),
  append_id_columns(SV = 1, cross_corr = 0.01, specification = "g3", simulation_results = g3_A1_sv_0.01_results),
  
  append_id_columns(SV = 1, cross_corr = 0.1, specification = "g1", simulation_results = g1_A1_sv_0.1_results),
  append_id_columns(SV = 1, cross_corr = 0.1, specification = "g2", simulation_results = g2_A1_sv_0.1_results),
  append_id_columns(SV = 1, cross_corr = 0.1, specification = "g3", simulation_results = g3_A1_sv_0.1_results)
)
  
```


```{r}
# Functions to process the raw loss statistics from earlier and create neat tables

# Functions to visualize variable importance metrics from earlier

combined_importance_list <- function(results_list) {
  combined_importance_list <- rep(list(0), length(results_list))
  
  for (batch in 1:length(results_list)) {
    combined_importance_list[[batch]] <- rep(list(0), 3)
    
    for (set in 1:3) {
      
      # Linear Models
      
      if (typeof(results_list[[batch]]$LM_MSE) == "list") {
        LM <- rbind(
          data.frame(cbind(results_list[[batch]]$LM_MSE[[set]]$variable_importance, model = "LM_MSE")),
          data.frame(cbind(results_list[[batch]]$LM_MAE[[set]]$variable_importance, model = "LM_MAE"))
        )
      } else {LM <- NULL}
      
      # Elastic Net
      
      if (typeof(results_list[[batch]]$ELN_MSE) == "list") {
        ELN <- rbind(
          data.frame(cbind(results_list[[batch]]$ELN_MSE[[set]]$variable_importance, model = "ELN_MSE")),
          data.frame(cbind(results_list[[batch]]$ELN_MAE[[set]]$variable_importance, model = "ELN_MAE"))
        )
      } else {ELN <- NULL}
      
      # Random Forest
      
      if (typeof(results_list[[batch]]$RF_MSE) == "list") {
        RF <- rbind(
          data.frame(cbind(results_list[[batch]]$RF_MSE[[set]]$variable_importance, model = "RF_MSE")),
          data.frame(cbind(results_list[[batch]]$RF_MAE[[set]]$variable_importance, model = "RF_MAE"))
        )
      } else {RF <- NULL}
      
      # Neural Networks
      
      if (typeof(results_list[[batch]]$NN1_MSE) == "list") {
        NN <- rbind(
          data.frame(cbind(results_list[[batch]]$NN1_MSE[[set]]$variable_importance, model = "NN1_MSE")),
          data.frame(cbind(results_list[[batch]]$NN1_MAE[[set]]$variable_importance, model = "NN1_MAE")),
          
          data.frame(cbind(results_list[[batch]]$NN2_MSE[[set]]$variable_importance, model = "NN2_MSE")),
          data.frame(cbind(results_list[[batch]]$NN2_MAE[[set]]$variable_importance, model = "NN2_MAE")),
          
          data.frame(cbind(results_list[[batch]]$NN3_MSE[[set]]$variable_importance, model = "NN3_MSE")),
          data.frame(cbind(results_list[[batch]]$NN3_MAE[[set]]$variable_importance, model = "NN3_MAE")),
          
          data.frame(cbind(results_list[[batch]]$NN4_MSE[[set]]$variable_importance, model = "NN4_MSE")),
          data.frame(cbind(results_list[[batch]]$NN4_MAE[[set]]$variable_importance, model = "NN4_MAE")),
          
          data.frame(cbind(results_list[[batch]]$NN5_MSE[[set]]$variable_importance, model = "NN5_MSE")),
          data.frame(cbind(results_list[[batch]]$NN5_MAE[[set]]$variable_importance, model = "NN5_MAE"))
        )
      } else {NN <- NULL}
      combined_importance_list[[batch]][[set]] <- rbind( LM, ELN, RF, NN)
    }
  }
  combined_importance_list
}

# Takes a combined importance list object as returned from previous function, and plots variable importance for a given batch and set
# Also take an importance threshold
combined_importance_plot <- function(combined_importance, batch_no, set_no, threshold) {
  df <- combined_importance[[batch_no]][[set_no]] %>%
    group_by(model) %>%
    mutate(importance = (importance + min(importance)/sum(importance + min(importance)))) %>%
    filter(importance > threshold)
  
  ggplot(df %>% mutate(variable = fct_reorder(variable, importance))) +
    geom_tile(aes(x = model, y = variable, alpha = importance))
}

g1_A1_results_importance <- combined_importance_list(g1_A1)

combined_importance_plot(g1_A1_results_importance, 1, 3, 0.005)

# Function that takes a results list object and returns a combined loss statistics data frame

combined_loss_stats <- function(results_list) {
  results_loss <- rep(list(0), length(results_list))
  for (batch in 1:length(results_list)) {
    results_loss[[batch]] <- rep(list(0), 3)
    for (set in 1:3) {
      # Linear Models
      
      if (typeof(results_list[[batch]]$LM_MSE) == "list") {
        LM <- rbind(
          data.frame(cbind(results_list[[batch]]$LM_MSE[[set]]$loss_stats, model = "LM_MSE")),
          data.frame(cbind(results_list[[batch]]$LM_MAE[[set]]$loss_stats, model = "LM_MAE"))
        )
      } else {LM <- NULL}
      
      # Elastic Net
      
      if (typeof(results_list[[batch]]$ELN_MSE) == "list") {
        ELN <- rbind(
          data.frame(cbind(results_list[[batch]]$ELN_MSE[[set]]$loss_stats, model = "ELN_MSE")),
          data.frame(cbind(results_list[[batch]]$ELN_MAE[[set]]$loss_stats, model = "ELN_MAE"))
        )
      } else {ELN <- NULL}
      
      # Random Forest
      
      if (typeof(results_list[[batch]]$RF_MSE) == "list") {
        RF <- rbind(
          data.frame(cbind(results_list[[batch]]$RF_MSE[[set]]$loss_stats, model = "RF_MSE")),
          data.frame(cbind(results_list[[batch]]$RF_MAE[[set]]$loss_stats, model = "RF_MAE"))
        )
      } else {RF <- NULL}
      
      # Neural Networks
      
      if (typeof(results_list[[batch]]$NN1_MSE) == "list") {
        NN <- rbind(
          data.frame(cbind(results_list[[batch]]$NN1_MSE[[set]]$loss_stats, model = "NN1_MSE")),
          data.frame(cbind(results_list[[batch]]$NN1_MAE[[set]]$loss_stats, model = "NN1_MAE")),
          
          data.frame(cbind(results_list[[batch]]$NN2_MSE[[set]]$loss_stats, model = "NN2_MSE")),
          data.frame(cbind(results_list[[batch]]$NN2_MAE[[set]]$loss_stats, model = "NN2_MAE")),
          
          data.frame(cbind(results_list[[batch]]$NN3_MSE[[set]]$loss_stats, model = "NN3_MSE")),
          data.frame(cbind(results_list[[batch]]$NN3_MAE[[set]]$loss_stats, model = "NN3_MAE")),
          
          data.frame(cbind(results_list[[batch]]$NN4_MSE[[set]]$loss_stats, model = "NN4_MSE")),
          data.frame(cbind(results_list[[batch]]$NN4_MAE[[set]]$loss_stats, model = "NN4_MAE")),
          
          data.frame(cbind(results_list[[batch]]$NN5_MSE[[set]]$loss_stats, model = "NN5_MSE")),
          data.frame(cbind(results_list[[batch]]$NN5_MAE[[set]]$loss_stats, model = "NN5_MAE"))
        )
      } else {NN <- NULL}
      results_loss[[batch]][[set]] <- rbind(LM, ELN, RF, NN)
    }
  }
  results_loss
}

g1_A1_loss <- combined_loss_stats(g1_A1)

g1_A1_loss[[1]][[1]]

gu_et_al_g2_loss[[1]][[1]]

```

