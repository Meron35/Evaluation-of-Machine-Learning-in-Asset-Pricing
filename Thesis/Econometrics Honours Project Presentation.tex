%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Preamble
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\PassOptionsToPackage{usenames, dvipsnames, table}{xcolor}

\documentclass[aspectratio=169]{beamer}
\usetheme{Boadilla}

%Make beamer number figures, because it doesn't by default
\setbeamertemplate{caption}[numbered]

\usepackage[english]{babel}
\usepackage[ruled, vlined]{algorithm2e}

\usepackage{amsfonts}
\usepackage{setspace, graphicx, epstopdf, amsmath}
%Do not use enumitem because this interferes with beamer drawing bullet points
\usepackage{marginnote, datetime, url, subfigure}

%Bibliography Stuff
%Use natbib even though it's old because it's compliant with journal styles
%Actual bibliography style etc are specified where you actually want it
\usepackage{natbib}


%Fluff
\linespread{1.3}

%Neural Network Packages
\usepackage{neuralnetwork}
\usepackage{xpatch}
\makeatletter
% \linklayers have \nn@lastnode instead of \lastnode,
% patch it to replace the former with the latter, and similar for thisnode
\xpatchcmd{\linklayers}{\nn@lastnode}{\lastnode}{}{}
\xpatchcmd{\linklayers}{\nn@thisnode}{\thisnode}{}{}
\makeatother

%Regression Tree
\usepackage{tikz,forest}
\usetikzlibrary{arrows.meta}

\forestset{
	.style={
		for tree={
			base=bottom,
			child anchor=north,
			align=center,
			s sep+=1cm,
			straight edge/.style={
				edge path={\noexpand\path[\forestoption{edge},thick,-{Latex}] 
					(!u.parent anchor) -- (.child anchor);}
			},
			if n children={0}
			{tier=word, draw, thick, rectangle}
			{draw, diamond, thick, aspect=2},
			if n=1{%
				edge path={\noexpand\path[\forestoption{edge},thick,-{Latex}] 
					(!u.parent anchor) -| (.child anchor) node[pos=.2, above] {Y};}
			}{
				edge path={\noexpand\path[\forestoption{edge},thick,-{Latex}] 
					(!u.parent anchor) -| (.child anchor) node[pos=.2, above] {N};}
			}
		}
	}
}

%%TODONOTE commands
\usepackage[colorinlistoftodos]{todonotes}
\newcommand{\smalltodo}[2][] {\todo[caption={#2}, size=\scriptsize,%
	fancyline,#1]{\begin{spacing}{.5}#2\end{spacing}}}
\newcommand{\rhs}[2][]{\smalltodo[color=green!30,#1]{{\bf RS:} #2}}
%%

%Graphs
\usepackage{tikz}
\usepackage{pgfplots}

\usepackage[export]{adjustbox}

%Coloured Tables


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%Title and other fluff, just before document start
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Hyperref apparently is a big package and causes a lot of issues, so it's recommended to load this last

\usepackage{hyperref}

%Gets rid of the neon green boxes around boxes

\usepackage[]{xcolor}

\graphicspath{{../Results/}}

\hypersetup{
	colorlinks,
	linkcolor = {red!50!black},
	citecolor = {blue!50!black},
	urlcolor = {blue!80!black}
}

\title{Evaluation of Machine Learning in Finance}

\author{Ze Yu Zhong 
	\\ Supervisor: David Frazier}

\institute{Monash University}

\date{}

\begin{document}
	
\begin{frame}[plain]
    \maketitle
\end{frame}

\begin{frame}
\frametitle{Overview}
\tableofcontents
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%Intereave literature review throughout this section
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Main Motivation}
To evaluate the application of machine learning to predicting financial asset returns, with specific regard to how they deal with the unique challenges present in financial data via simulation.
\end{frame}

\begin{frame}
\frametitle{Motivation}
Empirical finance is typically concerned with two main goals:
\begin{itemize}
	\item Prediction accuracy - want to predict future returns!
	\item Statistical causal inference - want to understand \textit{what} drives returns
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Motivation}
Recognise that these goals are very difficult, especially for traditional regression!

The underlying data generating process for financial data is unknown - returns are estimated by \textit{risk factors}, defined by \cite{harvey__2016} as a collection of regressors that can proxy for underlying risk factors

Factors are often unsuitable for regression:
\begin{itemize}
	\item Persistent
	\item Cross-sectionally correlated (multicollinearity)
	\item Non-stationary
	\item Pre-known, and therefore little time series variation
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Motivation}
Consequences when included in traditional regression well documented:
\begin{itemize}
	\item Biased t-stats
	\item High variance for coefficient estimates
	\item Unstable coefficient estimates
\end{itemize}
These can adversely affect statistical inference. 

The estimated coefficients, due to being imprecise, will also result in poor out of sample prediction, which are a function of coefficients. This is particularly so if the multicollinearity between regressors changes over time, which is likely in financial data
\end{frame}

\begin{frame}
\frametitle{Background - Dividend Ratio Example}
\begin{itemize}

\item Included due to good in sample performance in the 1990s \citep{goyal_predicting_2003}

\item \textit{Persistent} (\cite{goetzmann_testing_1993}, \cite{ang_stock_2006})

	\begin{itemize}
	\item Correlated with lagged dependent variables on the right hand side of the regression equation. 
	
	\item Violates assumptions of independent regressors of OLS: t stats are biased upwards due to autocorrelated errors
	
	\item GMM and NW errors corrections are also biased, \citep{goetzmann_testing_1993}
	\end{itemize}

\item Not robust and have poor out of sample performance since 2000s (\cite{goyal_predicting_2003}, \cite{lettau_consumption_2001}, \cite{schwert_anomalies_2003})
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Dividend Ratio Example}
\begin{itemize}
\item Factors such as dividend ratios, earnings price ratio, interest and inflation etc. were ``widely accepted" able to predict excess returns, \citep{lettau_consumption_2001}

\item \cite{welch_comprehensive_2008} conclude that not a single variable had any statistical forecasting power, and the significance values of some factors change with the choice of sample periods.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Background}
\begin{itemize}
\item More factors produced by literature: currently over 600 documented \citep{harvey_census_2019}
\begin{itemize}
	\item False discovery problem, \citep{harvey__2016}
	
	\item Factors are cross sectionally correlated - inefficient covariances, factors may be subsumed within others, \citep{feng_taming_2019}
	
	\item Number of factors may be more than sample size, making regression impossible
\end{itemize}
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Why apply Machine Learning in Finance?}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%
%Interweave Literature review throughout this section
%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Why apply Machine Learning in Finance?}

Machine learning methods have been used within the literature and appear to be well suited:
\begin{itemize}
	\item High dimensional - more flexible than traditional regression models, which make strong functional form assumptions and are sensitive to outliers, \citep{freyberger_dissecting_2017}
	\item Explicit ``regularization" methods for guarding against overfitting
	\item Methods to produce an optimal model from all possible at manageable computation cost
\end{itemize}
More able to manage the explosion in the number of factors suggested by the literature!
\end{frame}

\begin{frame}
\frametitle{Applications in the Literature}
Causal Analysis:
\begin{itemize}
	\item \cite{kozak_shrinking_2017}, \cite{rapach_forecasting_2013}, \cite{freyberger_dissecting_2017}, and others apply shrinkage and selection methods to identify important factors
\end{itemize}
Prediction Performance:
\begin{itemize}
	\item \cite{gu_empirical_2018}, \cite{feng_deep_2018}, construct machine learning portfolios that historically outperform traditional portfolios in terms of prediction error and predictive $R^2$
	\item Attribute their success to machine learning's ability to find non-linear interactions
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Motivations}
However, little work has been done on how machine learning actually recognises and deals with the challenges in financial data. 
\begin{itemize}
	\item \cite{feng_deep_2018} cross validates their training set, destroying temporal aspect of data, and only explore a handful of factors
	\item \cite{gu_empirical_2018} only use data up until the 1970s to produce predictions in the last 30 years
	\item \cite{gu_empirical_2018}'s models do not have consistent importance metrics - only their tree based methods recognise dividend yield as important
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Motivations}
Can machine learning deal with the challenges in financial data?
\begin{itemize}
	\item Persistent Regressors?
	\item Identify true factors from a high dimensional, cross sectionally correlated panel?
	\item Is regularization enough to handle non-robustness?
	\item Are their conclusions consistent?
	\item Do they perform better than traditional methods?
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Motivations}
We explored this via two studies, focusing on the prediction performance and factor selection performance of some common machine learning models:

Simulation study
\begin{itemize}
	\item 
\end{itemize}

Empirical study
\begin{itemize}
	\item 
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Model Specification}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Model Specification}
Returns are modelled as an additive error model
\begin{equation}
	r_{i, t+1} = E(r_{i, t+1} | \mathcal{F}_t) + \epsilon_{i, t+1}
\end{equation}
		
where 
\begin{equation}
	E(r_{i, t+1} | \mathcal{F}_t) = g^*(z_{i,t})
\end{equation}
		
Stocks are indexed as $i = 1, \dots, N$ and months by $t = 1, \dots, T$. 

$g^*(z_{i,t})$ represents the model approximation using the $P$ dimensional predictor set $z_{i,t}$. 
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methodology}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Overview}
Machine Learning Methodology consists of 3 overall components:
\begin{itemize}
	\item Sample Splitting
	\item Loss Function(s)
	\item Models/Algorithms considered
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Sample Splitting
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Sample Splitting - Expanding Window Scheme}
An expanding/growing window approach was used to
\begin{itemize}
	\item Allow models to incorporate more data over time
	\item Preserve temporal ordering of data (compared to cross-validation)
	\item Allows the model to use the most recent data, in some sense
\end{itemize}
The training/validation split was chosen such that the size of the training set was 1.5 times the length of the validation set to begin with, consistent with \cite{gu_empirical_2018}.
Split specification is ultimately subjective
\end{frame}

\begin{frame}
\frametitle{Sample Splitting}
\begin{figure}
	\begin{center}
		\begin{tabular}{|c|p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}|}
			\hline
			Set No. &&&&&&&&&&&&&&& \\
			\hline
			%%%%%%%%
			3 & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} &
			\cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & 	
			\cellcolor{olive} \\
			%%%%%%%%
			2 & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} &
			\cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & 	
			\cellcolor{olive} & NA  \\
			%%%%%%%%
			1 & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} &
			\cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & 	
			\cellcolor{olive} & NA & NA \\
			\hline
			Year & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15\\
			\hline
		\end{tabular}
		\medskip
		\begin{tabular}{|c|p{0.40cm}|}
			\hline
			Training & \cellcolor{cyan} \\
			\hline
			Validation & \cellcolor{pink} \\
			\hline
			Test & \cellcolor{olive} \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Sample Splitting Procedure}
	\label{sample_split_diag}
\end{figure}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Loss Functions
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Loss Functions}
Mean Absolute Error (MAE)

	\begin{equation}
	\text{MAE} = \frac{1}{n} \sum_{j = i}^{n} |y_j - \hat{y_j}|
	\end{equation}
	
Mean Squared Error (MSE)

	\begin{align}
	\text{MSE} &= \frac{1}{n} \sum_{j = i}^{n} \left( y_j - \hat{y_j}\right) ^2
	\end{align}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Linear Models
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Models}
We focus on 4 common machine learning models:
\begin{itemize}
	\item Linear Models
	\item Penalized Linear Models
	\item Random Forests
	\item Neural Networks
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Linear Models}
Linear Models assume that the underlying conditional expectation \( g^*(z_{i, t}) \) can be modelled as a linear function of the predictors and the parameter vector \( \theta \):
	\begin{equation}
	g(z_{i, t};\theta) = z_{i, t}' \theta
	\end{equation}
	
Optimizing $\theta$ w.r.t. MSE yields the Pooled OLS estimator
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Penalized Linear
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Penalized Linear Models}
Linear Models + Penalty term (Elastic Net by \cite{zou_regularization_2005} shown):
	\begin{align}
	\mathcal{L(\theta;.)} &= 
		\underset{\text{Loss Function}}{\underbrace{\mathcal{L(\theta)}}} + 
		\underset{\text{Penalty Term}}{\underbrace{\phi(\theta;.)}} \\
	\phi(\theta;\lambda,\rho) &= 
		\lambda(1-\rho) \sum_{j = 1}^{P}|\theta_j| +
		\frac{1}{2} \lambda \rho \sum_{j = 1}^{P}\theta_j^2
	\end{align}

Elastic Net penalty aims to produce efficient and parsimonious via shrinkage and selection
	
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Regression Trees and Random Forests
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Regression Trees \& Random Forests}
\begin{itemize}
	\item Fully non-parametric models that can capture complex multi-way interactions. 
	\item A tree "grows" in a series of iterations:
	\begin{enumerate}
		\item Make a split ("branch") along one predictor, such that it is the best split available at that stage with respect to minimizing the loss function
		\item Repeat until each observation is its own node, or until the stopping criterion is met
	\end{enumerate}
	\item Slices the predictor space into rectangular partitions, and predicts the unknown function $g^*(z_{i,t})$ with the ``average" value of the outcome variable in each partition to minimize the loss function
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Random Forests}
Trees have very low bias and high variance

They are very prone to overfitting and non-robust

Random Forests were proposed by \cite{breiman_random_2001} to address this
\begin{itemize}
	\item Create $B$ bootstrap samples
	\item Grow a highly overfit tree to each, but only using $m$ random subset of all predictors for each
	\item Average the output from all trees as an ensemble model
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Neural Networks
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Neural Networks - Overview}
Most complex model considered

Able to capture non-linearities systematically

In theory able to approximate any function - Universal Approximation Theorem
\end{frame}

\begin{frame}
\frametitle{Neural Network Specification}

\begin{itemize}
\item Neural networks with up to 5 hidden layers were considered. 

\item The number of neurons is each layer determined by geometric pyramid rule \citep{masters_practical_1993}

\item All units are fully connected
\end{itemize}

ReLU activation function was chosen for all hidden layers for computational speed, and hence popularity in literature:

\begin{equation}
\operatorname{ReLU}(x) = max(0, x)
\end{equation}
\end{frame}

\begin{frame}
\frametitle{Neural Network Tuning}
Neural Networks have the largest number of hyperparameters to tune - computationally infeasible to conduct comprehensive grid search. 

A conservative gridsearch was conducted, but it was observed that in general, default values provided the best performance.

Observed that neural networks are high sensitive to hyperparameters - not easy to tune!
\end{frame}

\begin{frame}
\frametitle{Hyperparameter Tuning}
Hyperparameters gridsearched:
\begin{itemize}
	\item Optimizer
	\item Learning Rate
	\item Batch Size
	\item l1 penalty
	\item Activation function
	\item Momentum
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Neural Network - Activation Function}
\cite{gu_empirical_2018} specified using the ReLU activation function for all layers

We found that this specification does not work due to the ``dying ReLU" problem"

Alternatives such as Leaky ReLU also did not give very good performance

A specification of the tanh activation function was observed to give the best results
\end{frame}

\begin{frame}
%Beamer hacks and uses # in a loop
%Therefore, we need to replace all # with ####
\begin{figure}
	\begin{neuralnetwork}
		%Options
		[nodespacing=9.5mm, layerspacing=18mm,
		maintitleheight=1em, layertitleheight=2em,
		height=7, toprow=false, nodesize=20pt, style={},
		title={}, titlestyle={}]
		\newcommand{\nodetextclear}[2]{}
		%use \ifnum to get different labels, such as x_n on the last neuron
		\newcommand{\nodetextx}[2]{\ifnum ####2=8 $x_n^{(0)}$ \else $x_####2^{(0)}$ \fi}
		\newcommand{\nodetexty}[2]{$y_####2$}
		%Hidden layer textcommands
		%32 neurons
		\newcommand{\nodetextxa}[2]{\ifnum ####2=7 $x_{32}^{(1)}$ \else $x_####2^{(1)}$ \fi}
		%16 neurons
		\newcommand{\nodetextxb}[2]{\ifnum ####2=6 $x_{16}^{(2)}$ \else $x_####2^{(2)}$ \fi}
		%8 neurons
		\newcommand{\nodetextxc}[2]{\ifnum ####2=5 $x_{8}^{(3)}$ \else $x_####2^{(3)}$ \fi}
		\newcommand{\nodetextxd}[2]{$x_####2^{(4)}$}
		\newcommand{\nodetextxe}[2]{$x_####2^{(5)}$}
		%Input Layer
		\inputlayer[count=8, bias=false, exclude = {7}, title=, text=\nodetextx]
		%Hidden Layer 1
		\hiddenlayer[count=7, bias=false, exclude = {6}, title=, text=\nodetextxa] 
		\linklayers[not from = {7}, not to = {6}]
		%Hidden Layer 2
		\hiddenlayer[count=6, bias=false, exclude = {5}, title=, text=\nodetextxb] 
		\linklayers[not from = {6}, not to = {5}]
		%Hidden Layer 3
		\hiddenlayer[count=5, bias=false, exclude = {4}, title=, text=\nodetextxc] 
		\linklayers[not from = {5}, not to = {4}]
		%Hidden Layer 4
		\hiddenlayer[count=4, bias=false, title=, text=\nodetextxd] 
		\linklayers[not from = {4}]
		%Hidden Layer 5
		\hiddenlayer[count=2, bias=false, title=, text=\nodetextxe] \linklayers
		%Final Layer
		\outputlayer[count=1, title=, text=\nodetexty] \linklayers
		% draw dots
		\path (L0-6) -- node{$\vdots$} (L0-8);
		\path (L1-5) -- node{$\vdots$} (L1-7);
		\path (L2-4) -- node{$\vdots$} (L2-6);
		\path (L3-3) -- node{$\vdots$} (L3-5);
	\end{neuralnetwork}
	\caption{Neural Network 5 (most complex considered)}
	\label{Neural_Network}
\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Loss Metrics}
	
	Overall predictive performance for individual excess stock returns were assessed using the following loss metrics:
	
	Mean Squared Error
	
	Mean Absolute Error
	
	Out of sample predictive R
	
\end{frame}
	
\begin{frame}
\frametitle{Out of Sample R squared}
		
An out of sample R squared metric was also reported, as is popular in the financial literature. There is no consensus as to how this metric is to be calculated, and we use the following formulation:
\begin{equation}
R^2_{OOS} = 
	1 - 
	\frac{\sum_{(i, t)\in\mathcal{T}_3}(r_{i, t+1} - \widehat{r}_{i, t+1})}
	{\sum_{(i, t)\in\mathcal{T}_3} \left( r_{i, t+1} - \bar{r}_{i, t+1} \right) ^2}
\end{equation}
		
where $\mathcal{T}_3$ indicates that the fits are only assessed on the test subsample
		
Interpretation of this is be cautioned, as R squared was originally designed for use in assessing in sample fit for linear models.
\end{frame}
	
\begin{frame}
\frametitle{Variable Importance}	
\begin{itemize}
	\item Defined as the reduction in predictive R-Squared from setting all values of predictor $j$ to 0, while holding the remaining model estimates fixed
	\item Note some minor transformations applied to this metric for numerical reasons
			
	\begin{equation}
	VI_{j, norm} = \frac{VI_j + \operatorname{min}(VI_j) + o}
	{\Sigma VI_j + \operatorname{min}(VI_j) + o} \quad ; \quad o = 10^{-100}
		\end{equation}
	\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Simulation Study}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Simulation Study}
Simulation study conducted see how well machine learning performs in a controlled environment which we understand, as opposed to empirical data which we do not understand
Characteristics of financial data to be captured
\begin{itemize}
	\item Stochastic volatility in errors
	\item Low signal to noise ratio
	\item Persistence across time in regressors
	\item Cross sectionally correlated (collinear) regressors
	\item High number of regressors
\end{itemize}
\end{frame}

\subsection{Simulation Design}
%% Gu et al design

\begin{frame}
\frametitle{\cite{gu_empirical_2018}'s Simulation Design}
We replicate \cite{gu_empirical_2018}'s simulation design as a starting point
%% Insert their specification here
Several Problems:
\begin{itemize}
	\item White noises, constant volatility specification
	\item No cross sectional correlation
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Proposed Simulation Design}
Latent factor model with stochastic volatility for excess return, $r_{t+1}$, for $t=1,\dots,T$:

\begin{flalign}
r_{i, t+1} &= 
g\left(z_{i, t}\right) + \beta_{i,t+1}v_{t+1} + e_{i, t+1}; \\
z_{i, t} &= \left(1, x_{t}\right)^{\prime} \otimes c_{i, t}; 
\quad \beta_{i, t}=\left(c_{i 1, t}, c_{i 2, t}, c_{i 3, t}\right); \\ 
e_{i, t+1} &= 
\exp\left( \frac{\sigma_{i, t+1}^2}{2} \right) \varepsilon_{i, t+1}; \\
\sigma^2_{i,t+1} &= 
\omega + \gamma_i\sigma^2_{t,i}+w_{i,t+1}
\end{flalign}

$v_{t+1}$ is a $3\times 1$ vector of errors, $w_{i,t+1},\varepsilon_{i,t+1}$ are scalar error terms. Variances tuned such that the R squared for each individual return series was 50\% and annualized volatility 30\%.

\end{frame}

\begin{frame}
\frametitle{Simulating Characteristics}

Matrix $C_t$ is an $N\times P_c$ vector of latent factors. 

$x_t$ is a $3 \times 1$ multivariate time series

$\varepsilon_{t+1}$ is a $N\times 1$ vector of idiosyncratic errors. 

Simulation mechanism for $C_t$ that gives correlation across the factors \& time

Draw normal random numbers for each $1\leq i\leq N$ and $1\leq j\leq P_{c}$, according to 

\begin{equation}
\overline{c}_{i j, t} = \rho_{j} \overline{c}_{i j, t-1}+\epsilon_{i j, t} ;
\quad \rho_{j} \sim \mathcal{U} \left( \frac{1}{2},1 \right) 
\end{equation}

\end{frame}

\begin{frame}
\frametitle{Simulating Characteristics}
Then, define the matrix 

\begin{equation}
B:=\Lambda\Lambda' + \frac{1}{10}\mathbb{I}_{n}, \quad
\Lambda_i = (\lambda_{i1},\dots,\lambda_{i4}), \quad
\lambda_{ik}\sim N(0,1), \; k=1,\dots,4
\end{equation}

Transform this into a correlation matrix $W$ via

\begin{equation}
W = \left( \operatorname{diag}(B) \right) ^{\frac{-1}{2}}
(B)
\left( \operatorname{diag}(B) \right) ^{\frac{-1}{2}}
\end{equation}

Use $W$ to build in cross sectional correlation for $N\times P_{c}$ matrix $\bar{C}_t$:

\begin{equation}
\widehat{C}_{t}=W\overline{C}_{t}
\end{equation}
\end{frame}

\begin{frame}
\frametitle{Simulating Characteristics}

Finally, the "observed" characteristics for each $1\leq i\leq N$ and for $j=1, \dots, P_{c}$ are constructed according to:

\begin{equation}
c_{i j, t} = \frac{2}{n+1} \operatorname{rank}\left(\hat{c}_{i j, t}\right) - 1.
\end{equation}

with the rank transformation normalizing all predictors to be within $[-1, 1]$ 
\end{frame}

\begin{frame}
\frametitle{Simulating Return Series}
We will consider four different functions $g(\cdot)$:
\begin{flalign*}
(1)\; & g_1 \left(z_{i, t}\right)=\left(c_{i 1, t}, c_{i 2, t}, c_{i 3, t} \times x_{3,t}'\right) \theta_{0} \\
(2)\; & g_2 \left(z_{i, t}\right)=\left(c_{i 1, t}^{2}, c_{i 1, t} \times c_{i 2, t}, \operatorname{sgn}\left(c_{i 3, t} \times  x_{3,t}'\right)\right) \theta_{0} \\
(3)\; & g_3 \left(z_{i, t}\right) = \left(1[c_{i3,t}>0],c_{i 2, t}^{3}, c_{i 1, t} \times c_{i 2, t}\times 1[c_{i3,t}>0], \text{logit}\left({c}_{i 3, t} \right)\right) \theta_{0}
\end{flalign*}

Tune $\theta^0$ s.t. cross sectional $R^2$ is 25\%, and predictive $R^2$ is 5\%. 

The simulation design results in $3 \times 4 = 12$ different simulation designs, with $N = 200$ stocks, $T = 180$ periods and $P_c = 100$ characteristics. Each design will be simulated 50 times to assess the robustness of machine learning algorithms.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SIMULATION STUDY RESULTS

\section{Simulation Study Results}

\subsection{Prediction Performance}

%% Quantile Loss is better

\begin{frame}
\begin{center}
	\begin{figure}
		\includegraphics[max size={\textwidth}{\textheight}]{simulation_test_mae_pre_all.pdf}
		\caption{Test MAE across all simulation designs}
	\end{figure}	
\end{center}
\end{frame}

\begin{frame}
\begin{center}
	\begin{figure}
	\includegraphics[max size={\textwidth}{\textheight}]{simulation_test_mse_pre_all.pdf}
	\caption{Test MAE across all simulation designs}
	\end{figure}	
\end{center}
\end{frame}

%% More data is worse for SV designs

%% Best Models are penalized Linear and random forests, random forests are only better on g2 specification (most non-linear)

\subsection{Variable Importance}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Empirical Study}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Data}

\begin{frame}
\frametitle{Data Source}
\cite{gu_empirical_2018}'s dataset of individual factors available from their website:
\begin{itemize}
	\item March 1957 - December 2016
	\item 61 annual factors
	\item 13 quarterly factors
	\item 20 monthly factors
	\item Industry dummy with 74 levels
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Data Cleaning Procedure}
Reducing dataset size:
\begin{itemize}
	\item Only include NASDAQ stocks
	\item Filter out penny stocks (microcaps)
	\item Keep only instruments with share code of 10, 11 (filtering out REITs, etc)
	\item Convert to a monthly format
	\item Industry dummy was dropped due to inaccuracy and high dimensionality
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Data Cleaning Procedure}
Missing Data
\begin{itemize}
	\item Significant increase in data quality and availability after 1993 Q3
	\item Factors with more than 20\% missing data were removed
	\item Remaining missing factors were imputed with cross sectional medians
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Macroeconomic Factors}
\begin{table}
	\caption{Macroeconomic Factors, (\cite{welch_comprehensive_2008})}
	\begin{center}
		\begin{tabular}{lccc} \hline
			No. & Acronym & Macroeconomic Factor \\ \hline
			1 & macro\_dp & Dividend Price Ratio \\
			2 & macro\_ep & Earnings Price Ratio \\
			3 & macro\_bm & Book to Market Ratio \\
			4 & macro\_ntis & Net Equity Expansion \\
			5 & macro\_tbl & Treasury Bill Rate \\
			6 & macro\_tms & Term Spread \\
			7 & macro\_dfy & Default Spread \\
			8 & macro\_svar & Stock Variance \\ \hline
		\end{tabular}
	\end{center}
\end{table}
\end{frame}

\begin{frame}
\frametitle{Cleaned Dataset}
Baseline set of covariates defined as:
\begin{equation}
	z_{i,t} - (1, x_t)' \otimes c_{i,t}
\end{equation}
where $c_{i,t}$ is a $P_c$ matrix of characteristics for each stock $i$, and $(1, x_t)'$ is a $P_x \times 1$ vector of macroeconomic predictors.

Number of covariates in this baseline set is $61 \times (8 + 1) = 549$. 
\end{frame}

%% CURRENTLY NOT WORKING, FIX ASAP

\begin{frame}
\frametitle{Sample Splitting}
\begin{figure}
	\begin{center}
		\begin{tabular}{|c|p{0.60cm}p{0.60cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}p{0.40cm}|}
			\hline
			Set &&&&&&&&&&&&&&&& \\
			\hline
			%%%%%%%%
			3 & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} &
			\cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{olive} \\
			%%%%%%%%
			2 & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} &
			\cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & 	
			\cellcolor{olive} & NA \\
			%%%%%%%%
			1 & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} &
			\cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{pink} & \cellcolor{olive} & NA & NA \\
			\hline
			Time & 93Q3 & 93Q4 & 94 & 95 & 96 & ... & 06 & 07 & 08 & ... & 11 & 12 & 13 & 14 & 15 & 16 \\
			\hline
		\end{tabular}
		\medskip
		\begin{tabular}{|c|p{0.60cm}|}
			\hline
			Training & \cellcolor{cyan} \\
			\hline
			Validation & \cellcolor{pink} \\
			\hline
			Test & \cellcolor{olive} \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Empirical Data Sample Splitting Procedure}
	\label{emp_sample_split_diag}
\end{figure}
\end{frame}

\subsection{Empirical Data Results}

\begin{frame}
\frametitle{Overview}

In general, results from the simulation study were repeated.

\begin{itemize}
	\item Suggest that simulation study was accurate to some degree
	\item Support for same conclusions to be made
\end{itemize}

Again see that results are different from \cite{gu_empirical_2018}. Neural networks do not vastly outperform other models!

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Prediction Accuracy - MSE}
\begin{figure}
\includegraphics{empirical_test_mse.pdf}
\caption{Empirical Data Test MSE Averaged Across all Samples}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Prediction Accuracy - MAE}
\begin{figure}
	\includegraphics{empirical_test_mae.pdf}
	\caption{Empirical Data Test MAE Averaged Across all Samples}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Prediction Accuracy - Neural Networks}
Similarly, some weak evidence that neurla networks with more hidden layers perform better

Neural Networks are still unstable
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Variable Importance - Individual Factors}
\includegraphics{empirical_sample_all_vi_ind.pdf}
\end{frame}

\begin{frame}
\frametitle{Variable Importance - Macroeconomic Factors}
\includegraphics{empirical_sample_all_vi_macro.pdf}
\end{frame}

\begin{frame}
\frametitle{Variable Importance}
Important factors in penalized linear models and random forests:
\begin{itemize}
\item 1 and 6 month momentum factors
\end{itemize}
Important factors in neural networks:
\begin{itemize}
\item Market Value (though inconsistent)
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Conclusion}
Machine learning offers tools to improve stock return prediction and identification of true underlying regressors. 

Penalized linear models, and to a lesser extent, random forests are the best performing models.

Feed-forward neural network architectures considered fail in the context of stock return prediction and variable importance analysis. The result is consistent across simulated data and empirical data. Importantly, this is in direct contradiction to previous literature, which concluded that neural networks vastly outperform. 

Top performing models - penalized linear and random forests, tend to agree and correctly identify causal regressors in simulated contexts, and same subset in empirical contexts. Neural networks only agree in simulated contexts. 

Penalized linear models are most consistent at correctly identify causal regressors, though this result is not always reliable, particularly when non-linearities are introduced.

Minimizing quantile loss yields better prediction performance.

Overall findings differ from sparse literature on similar topics. Performance of penalized linear models in both prediction and variable importance analysis is promising. 

Machine learning offers some tools which may aid in the problems of prediction and risk factor selection in the financial world.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{References}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%This is just here to get the citations working throughout the presentation, skip over this when presenting
\begin{frame}
\frametitle{References}
\bibliographystyle{jfe}
\bibliography{Bibliography}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Questions and Answers}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\begin{center}
\huge Questions and Answers
\end{center}
\end{frame}

\end{document}
