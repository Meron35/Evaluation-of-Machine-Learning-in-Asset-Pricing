mutate(Time = as.yearmon(as.character(DATE), "%Y%m%d"))
datashare$Time
datashare <- datashare_RAW %>%
mutate(Time = as.yearmon(as.character(DATE), "%Y%m%d")) %>%
select(-DATE)
summary(datashare)
datashare <- datashare_RAW %>%
mutate(Time = as.yearmon(as.character(DATE), "%Y%m%d")) #%>%
unique(datashare$permno)
length(unique(datashare$permno))
df_10006 <- datashare %>%
filter(permno == 10006)
View(df_10006)
# Load RAW Welch Goyal Data
PredictorData2017 <- read_excel("data/factors/PredictorData2017.xlsx",
na = "NaN")
# Load RAW Welch Goyal Data
PredictorData2017_RAW <- read_excel("data/factors/PredictorData2017.xlsx",
na = "NaN")
PredictorData2017 <- PredictorData2017_RAW %>%
mutate(Time = as.yearmon(as.character(yyyymm), "%Y%m"))
View(PredictorData2017)
PredictorData2017 <- PredictorData2017_RAW %>%
mutate(Time = as.yearmon(as.character(yyyymm), "%Y%m")) %>%
select(-yyyymm)
View(PredictorData2017)
object.size(datashare)
PredictorData2017 <- PredictorData2017_RAW %>%
mutate(Time = as.yearmon(as.character(yyyymm), "%Y%m")) %>%
select(-yyyymm) %>%
# Dividend price ratio is the difference between the log of dividends and the log of prices.
mutate(dp = log(D12) - log(Index)) %>%
# earnings price ratio is the difference between the log of earnings and the log of prices.
mutate(ep = log(E12) - log(Index)) %>%
# Term Spread is the difference between long term yield on gov bonds and treasury bills
mutate(tms = lty = tbl) %>%
PredictorData2017 <- PredictorData2017_RAW %>%
mutate(Time = as.yearmon(as.character(yyyymm), "%Y%m")) %>%
select(-yyyymm) %>%
# Dividend price ratio is the difference between the log of dividends and the log of prices.
mutate(dp = log(D12) - log(Index)) %>%
# earnings price ratio is the difference between the log of earnings and the log of prices.
mutate(ep = log(E12) - log(Index)) %>%
# Term Spread is the difference between long term yield on gov bonds and treasury bills
mutate(tms = lty - tbl) %>%
# Default spread is the difference betwen difference between BAA and AAA-rated corporate bond yields
mutate(dfy = BAA - AAA) %>%
# Rename b/m to bm
rename(bm = `b/m`)
View(PredictorData2017)
View(PredictorData2017)
PredictorData2017 <- PredictorData2017_RAW %>%
mutate(Time = as.yearmon(as.character(yyyymm), "%Y%m")) %>%
select(-yyyymm) %>%
# Dividend price ratio is the difference between the log of dividends and the log of prices.
mutate(dp = abs(log(D12) - log(Index))) %>%
# earnings price ratio is the difference between the log of earnings and the log of prices.
mutate(ep = abs(log(E12) - log(Index))) %>%
# Term Spread is the difference between long term yield on gov bonds and treasury bills
mutate(tms = lty - tbl) %>%
# Default spread is the difference betwen difference between BAA and AAA-rated corporate bond yields
mutate(dfy = abs(BAA - AAA)) %>%
# Rename b/m to bm
rename(bm = `b/m`)
macro_predictors <- PredictorData2017 %>%
select(Time, dp, ep, bm, ntis, tbl, tms, dfy, svar)
View(macro_predictors)
View(datashare_RAW)
knitr::opts_chunk$set(echo = TRUE)
################
##Load Libraries
################
library(tidyverse)
library(keras)
library(ggplot2)
library(forecast)
library(rlist)
library(Metrics)
library(ranger)
library(caret)
library(readr)
library(zoo)
library(readxl)
#Parallel Computing
library(foreach)
library(doFuture)
#Registering
registerDoFuture()
plan(multisession)
set.seed(27935248)
datashare_stock_ids <- unique(datashare$permno)
write.csv(datashare_stock_ids, file = "datashare_stock_ids.csv")
# It seems as though that data is only fully available for some stocks in the dataset
# Absolutely no clue how Gu et al dealt with missing data issues
df_10006 <- datashare %>%
filter(permno == 100014)
View(df_10006)
# It seems as though that data is only fully available for some stocks in the dataset
# Absolutely no clue how Gu et al dealt with missing data issues
df_10006 <- datashare %>%
filter(permno == 10006)
# It seems as though that data is only fully available for some stocks in the dataset
# Absolutely no clue how Gu et al dealt with missing data issues
df_10006 <- datashare %>%
filter(permno == 10014)
View(df_10006)
# It seems as though that data is only fully available for some stocks in the dataset
# Absolutely no clue how Gu et al dealt with missing data issues
df_10006 <- datashare %>%
filter(permno == 10006)
View(df_10006)
col(datashare)
colnames(datashare)
colnames(macro_predictors)
?rename_at
# Subset so that we have the predictors we actually care about
# Note that some of these by default have the same names as those in the individual factor set
# Therefore, prefix them with macro_ to make it clearer
macro_predictors <- PredictorData2017 %>%
select(Time, dp, ep, bm, ntis, tbl, tms, dfy, svar) %>%
rename_at(vars(-Time), "toupper")
View(macro_predictors)
# Subset so that we have the predictors we actually care about
# Note that some of these by default have the same names as those in the individual factor set
# Therefore, prefix them with macro_ to make it clearer
macro_predictors <- PredictorData2017 %>%
select(Time, dp, ep, bm, ntis, tbl, tms, dfy, svar) %>%
rename_at(vars(-Time), function(x) paste0("a", x))
View(macro_predictors)
# Subset so that we have the predictors we actually care about
# Note that some of these by default have the same names as those in the individual factor set
# Therefore, prefix them with macro_ to make it clearer
macro_predictors <- PredictorData2017 %>%
select(Time, dp, ep, bm, ntis, tbl, tms, dfy, svar) %>%
rename_at(vars(-Time), function(x) paste0("macro_", x))
min(datashare$Time)
# Subset so that we have the predictors we actually care about
# Note that some of these by default have the same names as those in the individual factor set
# Therefore, prefix them with macro_ to make it clearer
# Also filter out all the entries that precede the datashare dataset as they can't be used
macro_predictors <- PredictorData2017 %>%
select(Time, dp, ep, bm, ntis, tbl, tms, dfy, svar) %>%
rename_at(vars(-Time), function(x) paste0("macro_", x)) %>%
filter(Time >= min(datashare$Time))
max(macro_predictors$Time)
max(datashare$Time)
# Subset so that we have the predictors we actually care about
# Note that some of these by default have the same names as those in the individual factor set
# Therefore, prefix them with macro_ to make it clearer
# Also filter out all the entries that are not in the datashare dataset as they can't be used (Note that this also takes care of all missing values in this dataset)
macro_predictors <- PredictorData2017 %>%
select(Time, dp, ep, bm, ntis, tbl, tms, dfy, svar) %>%
rename_at(vars(-Time), function(x) paste0("macro_", x)) %>%
filter(Time >= min(datashare$Time) & <= max(datashare$Time))
?filter
# Subset so that we have the predictors we actually care about
# Note that some of these by default have the same names as those in the individual factor set
# Therefore, prefix them with macro_ to make it clearer
# Also filter out all the entries that are not in the datashare dataset as they can't be used (Note that this also takes care of all missing values in this dataset)
macro_predictors <- PredictorData2017 %>%
select(Time, dp, ep, bm, ntis, tbl, tms, dfy, svar) %>%
rename_at(vars(-Time), function(x) paste0("macro_", x)) %>%
filter(Time >= min(datashare$Time) & Time <= max(datashare$Time))
View(datashare)
colnames(datashare_RAW)
individual_factor_names <- colnames(datashare-RAW)
individual_factor_names <- colnames(datashareRAW)
individual_factor_names <- colnames(datashare_RAW)
individual_factor_names
individual_factor_names <- colnames(datashare_RAW)[3:96]
# Subset so that we have the predictors we actually care about
# Note that some of these by default have the same names as those in the individual factor set
# Therefore, prefix them with macro_ to make it clearer
# Also filter out all the entries that are not in the datashare dataset as they can't be used (Note that this also takes care of all missing values in this dataset)
macro_predictors <- PredictorData2017 %>%
select(Time, dp, ep, bm, ntis, tbl, tms, dfy, svar) %>%
rename_at(vars(-Time), function(x) paste0("macro_", x)) %>%
filter(Time >= min(datashare$Time) & Time <= max(datashare$Time)) %>%
# Add constant term so we can apply kronecker product later
mutate(constant = 1)
View(macro_predictors)
?mutate
# Subset so that we have the predictors we actually care about
# Note that some of these by default have the same names as those in the individual factor set
# Therefore, prefix them with macro_ to make it clearer
# Also filter out all the entries that are not in the datashare dataset as they can't be used (Note that this also takes care of all missing values in this dataset)
macro_predictors <- PredictorData2017 %>%
select(Time, dp, ep, bm, ntis, tbl, tms, dfy, svar) %>%
rename_at(vars(-Time), function(x) paste0("macro_", x)) %>%
filter(Time >= min(datashare$Time) & Time <= max(datashare$Time)) %>%
# Add constant term so we can apply kronecker product later
mutate(constant = 1) %>%
# Reorder
select(Time, constant, everything())
View(macro_predictors)
datashare <- datashare_RAW %>%
mutate(Time = as.yearmon(as.character(DATE), "%Y%m%d")) %>%
select(-DATE) %>%
# Reorder
select(Time, permno, everything())
datashare$sic2
sic2_codes <- datashare$sic2
sic2_codes <- datashare %>%
select(Time, permno, sic2)
View(sic2_codes)
sic2_codes <- datashare %>%
select(Time, permno, sic2) %>%
mutate(sic2 = as.factor(sic2))
View(sic2_codes)
summary(sic2_codes)
?model.matrix
unique(sic2_codes$sic2)
model.matrix(permno ~ sic2, data = sic2_codes)
model.matrix( ~ sic2, data = sic2_codes)
model.frame( ~ sic2, data = sic2_codes)
sic2_frame <- model.frame( ~ sic2, data = sic2_codes)
View(sic2_frame)
sic2_frame <- model.frame( permno ~ sic2, data = sic2_codes)
sic2_frame <- model.matrix(~ sic2, data = sic2_codes)
View(sic2_frame)
dmy <- dummyVars(" ~ .", data = sic2_codes)
dmy <- dummyVars(" ~ .", data = sic2_codes)
sic2_frame <- data.frame(predict(dmy, newdata = sic2_codes))
object.size(sic2_frame)
colnames(sic2_codes)
colnames(sic2_frame)
dmy <- dummyVars(" ~ sic2", data = sic2_codes)
sic2_frame <- data.frame(predict(dmy, newdata = sic2_codes))
colnames(sic2_frame)
dim(sic2_frame)
# Generate 74 characteristics dummy variables
dmy <- dummyVars(" ~ sic2", data = datashare)
sic2_frame <- data.frame(predict(dmy, newdata = datashare))
# Check Dimensions
# 74 dummy variables as required
dim(sic2_frame)
datashare <- datashare_RAW %>%
mutate(Time = as.yearmon(as.character(DATE), "%Y%m%d")) %>%
select(-DATE) %>%
# Convert sic2 codes to factor
mutate(sic2 = as.factor(sic2)) %>%
# Reorder
select(Time, permno, everything())
# Check how many IDs there are
# There are 74, consistent with Gu et al
unique(datashare$sic2)
# Generate 74 characteristics dummy variables
dmy <- dummyVars(" ~ sic2", data = datashare)
sic2_frame <- data.frame(predict(dmy, newdata = datashare))
dim(datashare)
dim(sic2_frame)
datashare[1,]
datashare[1]$Time
datashare$sic2[1]
View(datashare)
datashare$sic2
as.matrix(macro_predictors)
macro_matrix <- as.matrix(macro_predictors)
View(macro_matrix)
dimnames(macro_matrix)
datashare_matrix <- datashare %>%
select(-Time, -permno, -sic2) %>%
as.matrix()
View(datashare_matrix)
combined_matrix <- kronecker(macro_matrix, datashare_matrix, make.dimnames = TRUE)
?typeof(macro_matrix)
typeof(macro_matrix)
typeof(datashare_matrix)
summary(macro_matrix)
?as.matrix
# Subset so that we have the predictors we actually care about
# Note that some of these by default have the same names as those in the individual factor set
# Therefore, prefix them with macro_ to make it clearer
# Also filter out all the entries that are not in the datashare dataset as they can't be used (Note that this also takes care of all missing values in this dataset)
macro_predictors <- PredictorData2017 %>%
select(Time, dp, ep, bm, ntis, tbl, tms, dfy, svar) %>%
rename_at(vars(-Time), function(x) paste0("macro_", x)) %>%
filter(Time >= min(datashare$Time) & Time <= max(datashare$Time)) %>%
# Add constant term so we can apply kronecker product later
mutate(constant = 1) %>%
# Reorder
select(Time, constant, everything())
summary(macro_predictors)
macro_matrix <- macro_predictors %>%
select(-Time) %>%
as.matrix()
summary(macro_matrix)
combined_matrix <- kronecker(macro_matrix, datashare_matrix, make.dimnames = TRUE)
combined_matrix <- kronecker(t(macro_matrix), datashare_matrix, make.dimnames = TRUE)
combined <- full_join(macro_predictors, datashare)
View(combined)
model.matrix(~ (colnames(macro_predictors):colnames(datashare)), combined)
model.matrix(~.^2), combined)
model.matrix(~.^2, combined)
model.matrix(~.^2 -1, combined)
paste(colnames(macro_predictors))
?paste
paste(1, 2, sep = "+")
paste(colnames(macro_predictors), colnames(datshare))
paste(colnames(macro_predictors), colnames(datashare))
paste(colnames(macro_predictors), colnames(datshare), sep = ":")
paste(colnames(macro_predictors), colnames(datashare), sep = ":")
macro_factor_names <- colnames(macro_predictors)
paste(colnames(macro_predictors), colnames(datashare), sep = ":")
macro_factor_names
macro_factor_names <- colnames(select(macro_predictors, -Time))
macro_factor_names
individual_factor_names <- colnames(select(datashare, -permno, -Time))
individual_factor_names
individual_factor_names <- colnames(select(datashare, -permno, -Time, -sic2))
interaction_terms <- paste(macro_factor_names, individual_factor_names, sep = ":")
interaction_terms
length(interaction_terms)
interaction_terms <- paste(individual_factor_names, macro_factor_names, sep = ":")
interaction_terms
interaction_terms <- paste(individual_factor_names, macro_factor_names[1], sep = ":")
interaction_terms
interaction_terms <- paste(macro_factor_names[1], individual_factor_names, sep = ":")
interaction_terms
interaction_terms <- rep(list(0), length(macro_factor_names))
interaction_terms
for (i in 1:length(macro_factor_names)) {
interaction_terms[[i]] <- paste(macro_factor_names[i], individual_factor_names, sep = ":")
}
?interaction
paste(interaction_terms[[1]], interaction_terms[[2]], sep = "+")
paste(interaction_terms, sep = "+")
?paste
paste(interaction_terms, collapse = "+")
for (i in 1:length(macro_factor_names)) {
interaction_terms[[i]] <- paste(macro_factor_names[i], individual_factor_names, collapse = "+")
}
interaction_terms[[1]]
interaction_terms[[i]] <- paste(macro_factor_names[i], individual_factor_names, collapse = ":")
for (i in 1:length(macro_factor_names)) {
interaction_terms[[i]] <- paste(macro_factor_names[i], individual_factor_names, collapse = ":")
}
interaction_terms[[1]]
for (i in 1:length(macro_factor_names)) {
interaction_terms[[i]] <- paste(macro_factor_names[i], individual_factor_names, sep = ":", collapse = "+")
}
interaction_terms[[1]]
for (i in 1:length(macro_factor_names)) {
interaction_terms[[i]] <- paste(macro_factor_names[i], individual_factor_names, sep = ":", collapse = " + ")
}
interaction_terms[[1]]
paste(interaction_terms, collapse = "+")
model.matrix(~ paste(interaction_terms, collapse = "+"), combined)
as.formula(c("~ "), paste(interaction_terms, collapse = "+"))
as.formula(c("~ ", paste(interaction_terms, collapse = "+")))
f <- as.formula(c("~ ", paste(interaction_terms, collapse = "+")))
model.matrix(f, combined)
interaction_matrix <- model.matrix(f, combined)
colnames(interaction_matrix)
dim(interaction_matrix)
dim(datashare)
dim(combined)
?model.matrix
summary(interaction_matrix)
model.frame(f, combined, na.action=na.pass)
?model.frame
interaction_matrix <- model.matrix(f, model.frame(f, combined, na.action=na.pass))
interaction_matrix <- model.matrix(f, model.frame(~., combined, na.action=na.pass))
interaction_matrix <- model.matrix(f, model.frame(~., combined, na.action = na.pass))
interaction_matrix <- model.matrix(f, model.frame(~., combined[1:200], na.action = na.pass))
interaction_matrix <- model.matrix(f, model.frame(~., combined[1:200,], na.action = na.pass))
View(interaction_matrix)
interaction_matrix <- model.matrix(f, model.frame(~., combined, na.action = na.pass))
?sparse
?dcg
interaction_matrix <- model.matrix(f, model.frame(~., combined[1:1000,], na.action = na.pass))
View(interaction_matrix)
colnames(interaction_matrix)
dim(combined)
SparseM::as.matrix(interaction_matrix)
?sparseM
interaction_matrix <- sparse.model.matrix(f, model.frame(~., combined[1:1000,], na.action = na.pass))
library(Matrix)
interaction_matrix <- sparse.model.matrix(f, model.frame(~., combined[1:1000,], na.action = na.pass))
interaction_matrix <- sparse.model.matrix(f, model.frame(~., combined, na.action = na.pass))
knitr::opts_chunk$set(echo = TRUE)
################
##Load Libraries
################
library(tidyverse)
library(keras)
library(ggplot2)
library(forecast)
library(rlist)
library(Metrics)
library(ranger)
library(caret)
library(readr)
library(zoo)
library(readxl)
library(Matrix)
#Parallel Computing
library(foreach)
library(doFuture)
#Registering
registerDoFuture()
plan(multisession)
set.seed(27935248)
#################################################
# Load RAW data courtesy of Gu et al
#################################################
# This is about ~ 3GB in size in total
datashare_RAW <- read_csv("data/datashare/datashare.csv",
# Always make sure to force col_types so that read_csv doesn't assume weird stuff
col_types = cols(.default = "d"))
individual_factor_names <- colnames(datashare_RAW)[3:96]
datashare <- datashare_RAW %>%
mutate(Time = as.yearmon(as.character(DATE), "%Y%m%d")) %>%
select(-DATE) %>%
# Convert sic2 codes to factor
mutate(sic2 = as.factor(sic2)) %>%
# Reorder
select(Time, permno, everything())
# Check how many IDs there are
# There are 74, consistent with Gu et al
unique(datashare$sic2)
# Generate 74 characteristics dummy variables
dmy <- dummyVars(" ~ sic2", data = datashare)
sic2_frame <- data.frame(predict(dmy, newdata = datashare))
# Check Dimensions
# 74 dummy variables as required
dim(sic2_frame)
# sic2_frame is now ready to be combined to the entire predictor set at the end
# Summary Statistics
length(unique(datashare$permno))
# There are 29892 unique stocks to begin with
# There are 94 lagged characteristics/factors
# Export stock IDs so that we can query WRDS returns
datashare_stock_ids <- unique(datashare$permno)
write.csv(datashare_stock_ids, file = "datashare_stock_ids.csv")
# It seems as though that data is only fully available for some stocks in the dataset
# Absolutely no clue how Gu et al dealt with missing data issues
df_10006 <- datashare %>%
filter(permno == 10006)
####################################################
# Load RAW Welch Goyal Data
####################################################
# Note that Gu et al only used:
# Dividend price ratio dp, earnings price ratio ep, book to market ratio bm,
# net equity expansion ntis, Treasury bill rate tbl, term spread tms,
# Default spread dfy, stock variance svar
PredictorData2017_RAW <- read_excel("data/factors/PredictorData2017.xlsx",
na = "NaN")
PredictorData2017 <- PredictorData2017_RAW %>%
mutate(Time = as.yearmon(as.character(yyyymm), "%Y%m")) %>%
select(-yyyymm) %>%
# Dividend price ratio is the difference between the log of dividends and the log of prices
# Note that log(D12) - log(Index) is negative which doesn't make sense as a ratio
mutate(dp = abs(log(D12) - log(Index))) %>%
# earnings price ratio is the difference between the log of earnings and the log of prices
# Note that log(E12) - log(Index) is negative which doesn't make sense as a ratio
mutate(ep = abs(log(E12) - log(Index))) %>%
# Term Spread is the difference between long term yield on gov bonds and treasury bills
mutate(tms = lty - tbl) %>%
# Default spread is the difference between BAA and AAA-rated corporate bond yields
mutate(dfy = abs(BAA - AAA)) %>%
# Rename b/m to bm
rename(bm = `b/m`)
# Subset so that we have the predictors we actually care about
# Note that some of these by default have the same names as those in the individual factor set
# Therefore, prefix them with macro_ to make it clearer
# Also filter out all the entries that are not in the datashare dataset as they can't be used (Note that this also takes care of all missing values in this dataset)
macro_predictors <- PredictorData2017 %>%
select(Time, dp, ep, bm, ntis, tbl, tms, dfy, svar) %>%
rename_at(vars(-Time), function(x) paste0("macro_", x)) %>%
filter(Time >= min(datashare$Time) & Time <= max(datashare$Time)) %>%
# Add constant term so we can apply kronecker product later
mutate(constant = 1) %>%
# Reorder
select(Time, constant, everything())
#############################
# Combining everything
#############################
# macro predictors \kronecker individual factors (excluding ids)
# Kronecker product approach is waaay too involved. It would require sorting everything back into array form (i, j, t) and applying kronecker function to each individual stock's panel, as was the case with simulation
# Unlike the simulation code though, here we are starting from a panel dataframe which is significantly harder to turn back into an array
# Alternative approach: generate the individual factors * macro factors as a separate dataframe via model matrix (or similar), then combine them back together
# Remember that kronecker would give us constant*individual factors + individual factors*macro factors
# This EXCLUDES macro factors by themselves
macro_factor_names <- colnames(select(macro_predictors, -Time))
individual_factor_names <- colnames(select(datashare, -permno, -Time, -sic2))
interaction_terms <- rep(list(0), length(macro_factor_names))
for (i in 1:length(macro_factor_names)) {
interaction_terms[[i]] <- paste(macro_factor_names[i], individual_factor_names, sep = ":", collapse = " + ")
}
f <- as.formula(c("~ ", paste(interaction_terms, collapse = "+")))
combined <- full_join(macro_predictors, datashare)
interaction_matrix <- sparse.model.matrix(f, model.frame(~., combined, na.action = na.pass))
rm(datashare_RAW)
# Memory issues. This interaction matrix is way too large
interaction_matrix <- sparse.model.matrix(f, model.frame(~., combined, na.action = na.pass))
gc()
rm(datashare)
# Memory issues. This interaction matrix is way too large
interaction_matrix <- sparse.model.matrix(f, model.frame(~., combined, na.action = na.pass))
sum(complete.cases(combined))
# Memory issues. This interaction matrix is way too large
interaction_matrix <- sparse.model.matrix(f, model.frame(~., combined))
dim(interaction_matrix)
colnames(interaction_matrix)
?dummyVars
dmy <- dummyVars(f, data = combined)
> dmy
dmy
interaction_matrix <- predict(dmy, combined)
interaction_matrix <- predict(dmy, combined, sparse = TRUE)
?predict.dummyVars
