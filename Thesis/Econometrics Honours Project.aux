\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Topic}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Background Literature and Motivations}{2}{subsection.1.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:}  Data skepticism (have you set up the data properly?) Show/highlight non-robustness of ML methods Skepticism of validity of methods that include non-stationary factors (like dividend yield) Check validity via simulation methods Methods to consider: OLS, Elasticnet, RF, NN See how it performs on real data}{2}{section*.3}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{4736286}{10900141}
\pgfsyspdfmark {pgfid4}{36994278}{10845255}
\pgfsyspdfmark {pgfid5}{38845670}{10688515}
\citation{vuolteenaho_understanding_1999}
\citation{lettau_consumption_2001}
\citation{schwert_anomalies_2003}
\citation{hsu_finding_2014}
\citation{harvey__2016}
\citation{harvey_census_2019}
\citation{kozak_shrinking_2017}
\citation{rapach_forecasting_2013}
\citation{freyberger_dissecting_2017}
\citation{gu_empirical_2018}
\citation{hsu_finding_2014}
\citation{feng_deep_2018}
\citation{gu_empirical_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Main Findings}{3}{subsection.1.3}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} Pending}{3}{section*.4}\protected@file@percent }
\pgfsyspdfmark {pgfid6}{4736286}{24153542}
\pgfsyspdfmark {pgfid9}{36994278}{24098656}
\pgfsyspdfmark {pgfid10}{38845670}{23941916}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Limitations of Machine Learning}{3}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Methodology}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Overall Model Design}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Sample Splitting}{4}{subsection.2.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} insert a picture of how the windows work from say caret documentation, would be great}{4}{section*.5}\protected@file@percent }
\pgfsyspdfmark {pgfid11}{4736286}{18019358}
\pgfsyspdfmark {pgfid14}{36994278}{17964472}
\pgfsyspdfmark {pgfid15}{38845670}{17807732}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Loss Function}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Mean Absolute Error}{4}{subsubsection.2.3.1}\protected@file@percent }
\citation{huber_robust_1992}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of MAE, MSE and Huber Loss when $\xi = 1$}}{5}{figure.1}\protected@file@percent }
\newlabel{fig:loss_functions}{{1}{5}{Illustration of MAE, MSE and Huber Loss when $\xi = 1$}{figure.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Mean Squared Error and Root Mean Squared Error}{5}{subsubsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Huber Loss}{5}{subsubsection.2.3.3}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} cite something about outliers in financial data}{5}{section*.6}\protected@file@percent }
\pgfsyspdfmark {pgfid18}{4736286}{10540087}
\pgfsyspdfmark {pgfid21}{36994278}{10485201}
\pgfsyspdfmark {pgfid22}{38845670}{10328461}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Linear Model}{5}{subsection.2.4}\protected@file@percent }
\citation{zou_regularization_2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Penalized Linear Model}{6}{subsection.2.5}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} update when algorithm is written}{6}{section*.7}\protected@file@percent }
\pgfsyspdfmark {pgfid23}{4736286}{20231671}
\pgfsyspdfmark {pgfid26}{36994278}{20176785}
\pgfsyspdfmark {pgfid27}{38845670}{20020045}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Classification and Regression Trees}{6}{subsection.2.6}\protected@file@percent }
\citation{masters_practical_1993}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} this diagram needs work}{7}{section*.8}\protected@file@percent }
\pgfsyspdfmark {pgfid28}{4736286}{29943128}
\pgfsyspdfmark {pgfid31}{36994278}{29888242}
\pgfsyspdfmark {pgfid32}{38845670}{29731502}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Random Forests}{7}{subsection.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Neural Networks}{7}{subsection.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.1}Introduction}{7}{subsubsection.2.8.1}\protected@file@percent }
\citation{lecun_deep_2015}
\citation{ramachandran_searching_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Neural Network 5 (most complex considered)}}{8}{figure.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} would be best to customize neuron text}{8}{section*.9}\protected@file@percent }
\pgfsyspdfmark {pgfid62}{4736286}{24603947}
\pgfsyspdfmark {pgfid65}{36994278}{24549061}
\pgfsyspdfmark {pgfid66}{38845670}{24392321}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2}Activation Function}{8}{subsubsection.2.8.2}\protected@file@percent }
\citation{choromanska_loss_2014}
\citation{ioffe_batch_2015}
\citation{hansen_neural_1990}
\citation{gu_empirical_2018}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.3}Computation}{9}{subsubsection.2.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.4}Batch Normalization}{9}{subsubsection.2.8.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Simulation Design}{9}{subsection.2.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.1}Overall Design}{9}{subsubsection.2.9.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} justify properly}{9}{section*.10}\protected@file@percent }
\pgfsyspdfmark {pgfid68}{4736286}{9803690}
\pgfsyspdfmark {pgfid71}{36994278}{9748804}
\pgfsyspdfmark {pgfid72}{38845670}{9592064}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.2}Simulating Characteristics}{10}{subsubsection.2.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.3}Simulating Macroeconomic Series}{10}{subsubsection.2.9.3}\protected@file@percent }
\citation{diebold_comparing_2002}
\citation{harvey_testing_1997}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.4}Simulating Return Series}{11}{subsubsection.2.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.5}Sample Splitting}{11}{subsubsection.2.9.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10}Model Evaluation}{11}{subsection.2.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.10.1}R Squared}{11}{subsubsection.2.10.1}\protected@file@percent }
\citation{breiman_classification_2017}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.10.2}Diebold-Mariano Test}{12}{subsubsection.2.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11}Variable Importance}{12}{subsection.2.11}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} Pending}{12}{section*.11}\protected@file@percent }
\pgfsyspdfmark {pgfid73}{4736286}{33819053}
\pgfsyspdfmark {pgfid76}{36994278}{33764167}
\pgfsyspdfmark {pgfid77}{38845670}{33607427}
\@writefile{toc}{\contentsline {section}{\numberline {3}Study}{12}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data}{12}{subsection.3.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} Pending}{12}{section*.12}\protected@file@percent }
\pgfsyspdfmark {pgfid78}{4736286}{26988194}
\pgfsyspdfmark {pgfid81}{36994278}{26933308}
\pgfsyspdfmark {pgfid82}{38845670}{26776568}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Model}{12}{subsection.3.2}\protected@file@percent }
\citation{breiman_random_2001}
\@writefile{toc}{\contentsline {section}{\numberline {4}Appendix}{13}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Algorithms}{13}{subsection.4.1}\protected@file@percent }
\newlabel{Algorithms}{{4.1}{13}{Algorithms}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Penalized Linear}{13}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Classification and Regression Trees}{13}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Classification and Regression Tree}}{13}{algocf.1}\protected@file@percent }
\citation{kingma_adam:_2014}
\bibstyle{jfe}
\bibdata{Bibliography}
\bibcite{breiman_random_2001}{{1}{2001}{{Breiman}}{{}}}
\bibcite{breiman_classification_2017}{{2}{2017}{{Breiman}}{{}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Random Forest}{14}{subsubsection.4.1.3}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Random Forest}}{14}{algocf.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Neural Networks}{14}{subsubsection.4.1.4}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} research different types of algorithms. Paper used ADAM}{14}{section*.13}\protected@file@percent }
\pgfsyspdfmark {pgfid83}{4736286}{31861874}
\pgfsyspdfmark {pgfid86}{36994278}{31806988}
\pgfsyspdfmark {pgfid87}{38845670}{31650248}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Early stopping via validation}}{14}{algocf.3}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Batch Normalization for one activation over one batch}}{14}{algocf.4}\protected@file@percent }
\bibcite{choromanska_loss_2014}{{3}{2014}{{Choromanska et~al.}}{{Choromanska, Henaff, Mathieu, Arous, and LeCun}}}
\bibcite{diebold_comparing_2002}{{4}{2002}{{Diebold and Mariano}}{{}}}
\bibcite{feng_deep_2018}{{5}{2018}{{Feng et~al.}}{{Feng, He, and Polson}}}
\bibcite{freyberger_dissecting_2017}{{6}{2017}{{Freyberger et~al.}}{{Freyberger, Neuhierl, and Weber}}}
\bibcite{gu_empirical_2018}{{7}{2018}{{Gu et~al.}}{{Gu, Kelly, and Xiu}}}
\bibcite{hansen_neural_1990}{{8}{1990}{{Hansen and Salamon}}{{}}}
\bibcite{harvey_census_2019}{{9}{2019}{{Harvey and Liu}}{{}}}
\bibcite{harvey__2016}{{10}{2016}{{Harvey et~al.}}{{Harvey, Liu, and Zhu}}}
\bibcite{harvey_testing_1997}{{11}{1997}{{Harvey et~al.}}{{Harvey, Leybourne, and Newbold}}}
\bibcite{hsu_finding_2014}{{12}{2014}{{Hsu and Kalesnik}}{{}}}
\bibcite{huber_robust_1992}{{13}{1992}{{Huber}}{{}}}
\bibcite{ioffe_batch_2015}{{14}{2015}{{Ioffe and Szegedy}}{{}}}
\bibcite{kingma_adam:_2014}{{15}{2014}{{Kingma and Ba}}{{}}}
\bibcite{kozak_shrinking_2017}{{16}{2017}{{Kozak et~al.}}{{Kozak, Nagel, and Santosh}}}
\bibcite{lecun_deep_2015}{{17}{2015}{{Lecun et~al.}}{{Lecun, Bengio, and Hinton}}}
\bibcite{lettau_consumption_2001}{{18}{2001}{{Lettau and Ludvigson}}{{}}}
\bibcite{masters_practical_1993}{{19}{1993}{{Masters}}{{}}}
\bibcite{ramachandran_searching_2017}{{20}{2017}{{Ramachandran et~al.}}{{Ramachandran, Zoph, and Le}}}
\bibcite{rapach_forecasting_2013}{{21}{2013}{{Rapach and Zhou}}{{}}}
\bibcite{schwert_anomalies_2003}{{22}{2003}{{Schwert}}{{}}}
\bibcite{vuolteenaho_understanding_1999}{{23}{1999}{{Vuolteenaho}}{{}}}
\bibcite{zou_regularization_2005}{{24}{2005}{{Zou and Hastie}}{{}}}
