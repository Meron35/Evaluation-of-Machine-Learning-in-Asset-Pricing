layer_dense(units = 8,
bias_initializer = initializer_zeros(),
kernel_initializer = initializer_truncated_normal(mean = 0, stddev = 0.05, seed = NULL)) %>%
layer_activation(activation = "tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
#Layer 4
layer_dense(units = 4,
bias_initializer = initializer_zeros(),
kernel_initializer = initializer_truncated_normal(mean = 0, stddev = 0.05, seed = NULL)) %>%
layer_activation(activation = "tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
# Output Layer
layer_dense(units = 1, activation = "linear")
} else {
model <- keras_model_sequential() %>%
# Layer 1
layer_dense(units = 32, input_shape = ncol(train_x),
bias_initializer = initializer_zeros(),
kernel_initializer = initializer_truncated_normal(mean = 0, stddev = 0.05, seed = NULL)) %>%
layer_activation(activation = "tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
# Layer 2
layer_dense(units = 16,
bias_initializer = initializer_zeros(),
kernel_initializer = initializer_truncated_normal(mean = 0, stddev = 0.05, seed = NULL)) %>%
layer_activation(activation = "tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
#Layer 3
layer_dense(units = 8,
bias_initializer = initializer_zeros(),
kernel_initializer = initializer_truncated_normal(mean = 0, stddev = 0.05, seed = NULL)) %>%
layer_activation(activation = "tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
#Layer 4
layer_dense(units = 4,
bias_initializer = initializer_zeros(),
kernel_initializer = initializer_truncated_normal(mean = 0, stddev = 0.05, seed = NULL)) %>%
layer_activation(activation = "tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
#Layer 5
layer_dense(units = 2,
bias_initializer = initializer_zeros(),
kernel_initializer = initializer_truncated_normal(mean = 0, stddev = 0.05, seed = NULL)) %>%
layer_activation(activation = "tanh") %>%
layer_activity_regularization(l1 = l1_penalty) %>%
layer_batch_normalization() %>%
# Output Layer
layer_dense(units = 1, activation = "linear")
}
model %>% compile(
loss = loss_function,
optimizer = optimizer_adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999,
epsilon = NULL, decay = 0, amsgrad = FALSE, clipnorm = NULL,
clipvalue = NULL),
metrics = list("mae", "mse")
)
model
}
neural_network <- build_NN(hidden_layers, loss_function)
# Other options used throughout the neural network fitting process are specified here
# Namely, batch size
# In general, larger batch sizes result in faster progress in training, but don't always converge as fast. Smaller batch sizes train slower, but can converge faster.
# Default batch size is 32
neural_network %>% fit(as.matrix(train_x), as.matrix(train_y),
batch_size = batch_size, epochs = 500, verbose = 1,
validation_data = list(as.matrix(validation_x), as.matrix(validation_y)),
callbacks = list(early_stop, print_dot_callback))
# Model
# NNet_stats[[set]]$model <- neural_network
#Train
train_predict <- neural_network %>% predict(as.matrix(train_x))
NNet_stats[[set]]$loss_stats$train_MAE <- mae(train$rt, train_predict)
NNet_stats[[set]]$loss_stats$train_MSE <- mse(train$rt, train_predict)
NNet_stats[[set]]$loss_stats$train_RMSE <- rmse(train$rt, train_predict)
NNet_stats[[set]]$loss_stats$train_RSquare <- R2(train_predict, train$rt, form = "traditional")
#Validation
validation_predict <- neural_network %>% predict(as.matrix(validation_x))
NNet_stats[[set]]$loss_stats$validation_MAE <- mae(validation$rt, validation_predict)
NNet_stats[[set]]$loss_stats$validation_MSE <- mse(validation$rt, validation_predict)
NNet_stats[[set]]$loss_stats$validation_RMSE <- rmse(validation$rt, validation_predict)
NNet_stats[[set]]$loss_stats$validation_RSquare <- R2(validation_predict, validation$rt, form = "traditional")
#Test
test_predict <- neural_network %>% predict(as.matrix(test_x))
NNet_stats[[set]]$loss_stats$test_MAE <- mae(test$rt, test_predict)
NNet_stats[[set]]$loss_stats$test_MSE <- mse(test$rt, test_predict)
NNet_stats[[set]]$loss_stats$test_RMSE <- rmse(test$rt, test_predict)
NNet_stats[[set]]$loss_stats$test_RSquare <- R2(test_predict, test$rt, form = "traditional")
#Forecasts
NNet_stats[[set]]$forecasts <- test_predict
#Forecast residuals
NNet_stats[[set]]$forecast_resids <- nnet_ave_forecast_resids(nnet_model = neural_network, test = test)
#Variable Importance
NNet_stats[[set]]$variable_importance <- NNet_variable_importance(test, neural_network,
macro_factor_names, individual_factor_names)
}
# clear Keras session
k_clear_session()
NNet_stats
}
###################################################################################################################
# Line which changes doFuture max memory limits (1.5GB currently)
options(future.globals.maxSize = 1.5e+9)
f <- real_panel_formula(final_dataset)
LM_stats_mae <- LM_fit(final_dataset, realdata_timeSlices, "mae", f,
macro_factor_names, individual_factor_names)
library(quantreg)
LM_stats_mae <- LM_fit(final_dataset, realdata_timeSlices, "mae", f,
macro_factor_names, individual_factor_names)
final_dataset <- final_dataset %>%
mutate(rt = jitter(rt))
LM_stats_mae <- LM_fit(final_dataset, realdata_timeSlices, "mae", f,
macro_factor_names, individual_factor_names)
?bandwidth.rq
library(Matrix)
install.packages("matrixcalc")
library(matrixcalc)
?is.singular.matrix
final_dataset[, -c(1:3)]
final_dataset[, -c(1:3)] %>% as.matrix() %>% is.singular.matrix()
final_dataset[, -c(1:3)] %>% as.matrix() %>% findLinearCombos()
## Setting up time slices, formulas, etc
## time slices function
## Different function needed due to different time format (inclusion of quarters)
## Makes it so that it works with all of our model fitting function from earlier
realdata_custom_timeslices <- function(start, initialWindow, horizon, validation_size, test_size, set_no) {
time_slice <- list(train = 0, validation = 0, test = 0)
time_slices <- rep(list(time_slice), set_no)
for (t in 1:set_no) {
time_slice$train <- seq(start,
(start + initialWindow + (t-1) * horizon + 3/4),
0.25)
time_slice$validation <- seq(
(start + initialWindow + (t-1) * horizon + 1),
(start + initialWindow + (t-1) * horizon + validation_size + 3/4),
0.25
)
time_slice$test <- seq(
(start + initialWindow + (t-1) * horizon + validation_size + 1),
(start + (initialWindow + (t-1) * horizon) + validation_size + test_size + 3/4),
0.25
)
time_slices[[t]] <- time_slice
}
time_slices
}
# Formula
real_panel_formula <- function(panel){
#Remove the first 3 colNames, as these correspond to the return, time and stock id
panel_colnames <- colnames(panel)[-c(1:3)]
f <- as.formula(c("rt ~", paste(panel_colnames, collapse = "+")))
return(f)
}
# These are the settings working with a dataset going from 1993 - 2016
# Results in a traing:validation size ratio of 1.5
realdata_timeSlices <- realdata_custom_timeslices(
start = 1994, initialWindow = 12, horizon = 1, validation_size = 7, test_size = 1, set_no = 3
)
# Add the two quarters in from 1993
for(i in 1:3) {
realdata_timeSlices[[i]]$train <- c(1993.5, 1993.75, realdata_timeSlices[[i]]$train)
}
ELN_stats_mse <- ELN_fit_stats(alpha_grid = seq(0, 1, 0.01), nlamb = 100,
realdata_timeSlices, final_dataset, "mse",
macro_factor_names, individual_factor_names)
saveRDS(ELN_stats_mse, file = "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Model_results/empirical_train_valid_2/ELN_stats_mse.rds")
ELN_stats_mae <- ELN_fit_stats(alpha_grid = seq(0, 1, 0.01), nlamb = 100,
realdata_timeSlices, final_dataset, "mae",
macro_factor_names, individual_factor_names)
RF_grid <- expand.grid(
#ntree usually isn't tuned. Just set to max of computationally feasible
ntree = 50,
mtry = seq(20, round(ncol(final_dataset[4:ncol(final_dataset)])/4), 20),
nodesize = seq(6, 15, 3)
# nodedepth recommended not to be changed
#nodedepth = 1
)
RF_mse_stats <- RF_fit_stats(final_dataset, RF_grid, realdata_timeSlices, "mse", f,
macro_factor_names, individual_factor_names)
library(randomForestSRC)
RF_grid <- expand.grid(
#ntree usually isn't tuned. Just set to max of computationally feasible
ntree = 50,
mtry = seq(20, round(ncol(final_dataset[4:ncol(final_dataset)])/4), 20),
nodesize = seq(6, 15, 3)
# nodedepth recommended not to be changed
#nodedepth = 1
)
RF_mse_stats <- RF_fit_stats(final_dataset, RF_grid, realdata_timeSlices, "mse", f,
macro_factor_names, individual_factor_names)
saveRDS(RF_mse_stats, file = "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Model_results/empirical_train_valid_2/RF_mse_stats_1.5_train_valid.rds")
RF_mae_stats <- RF_fit_stats(final_dataset, RF_grid, realdata_timeSlices, "mae", f,
macro_factor_names, individual_factor_names)
saveRDS(RF_mae_stats, file = "~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/Model_results/empirical_train_valid_2/RF_mae_stats_1.5_train_valid.rds")
RF_mae_stats[[1]]$loss_stats
RF_mse_stats[[1]]$loss_stats
RF_mae_stats[[2]]$loss_stats
RF_mse_stats[[2]]$loss_stats
RF_mse_stats[[3]]$loss_stats
RF_mae_stats[[3]]$loss_stats
RF_mae_stats[[1]]$variable_importance %>%
arrange(desc(importance))
ELN_stats_mae <- ELN_fit_stats(alpha_grid = seq(0, 1, 0.01), nlamb = 100,
realdata_timeSlices, final_dataset, "mae",
macro_factor_names, individual_factor_names)
# Forecasting Variable Importance Metrics
## Linear Model
# Given a an lm object and a test dataset, return the cross sectional average forecast errors
lm_ave_forecast_resids <- function(lm_model, test) {
time_periods <- unique(test$time)
# Set .combine to "c" to return a vector of results, which is what we want
ave_forecast_resids_vector <- foreach(t = 1:length(time_periods), .combine = "c", .packages = c("speedglm", "quantreg")) %dopar% {
test_cross_section <- test %>%
filter(time == time_periods[t])
residuals <- test_cross_section$rt - predict(lm_model, newdata = test_cross_section)
mean(residuals)
}
ave_forecast_resids_vector
}
## Elastic Net
eln_ave_forecast_resids <- function(eln_model, test, alpha, lambda) {
time_periods <- unique(test$time)
# Set .combine to "c" to return a vector of results, which is what we want
ave_forecast_resids_vector <- foreach(t = 1:length(time_periods), .combine = "c") %dopar% {
test_cross_section <- test %>%
filter(time == time_periods[t])
test_cross_section_x <- as.matrix(test_cross_section[4:ncol(test_cross_section)])
residuals <- test_cross_section$rt - predict(eln_model, test_cross_section_x,
alpha = alpha, lambda = lambda)
mean(residuals)
}
ave_forecast_resids_vector
}
## Random Forest
rf_ave_forecast_resids <- function(rf_model, test) {
time_periods <- unique(test$time)
# Set .combine to "c" to return a vector of results, which is what we want
ave_forecast_resids_vector <- foreach(t = 1:length(time_periods), .combine = "c") %do% {
test_cross_section <- test %>%
filter(time == time_periods[t])
residuals <- test_cross_section$rt - predict(rf_model, newdata = test_cross_section)$predicted
mean(residuals)
}
ave_forecast_resids_vector
}
## Neural Networks
nnet_ave_forecast_resids <- function(nnet_model, test) {
time_periods <- unique(test$time)
# Set .combine to "c" to return a vector of results, which is what we want
ave_forecast_resids_vector <- foreach(t = 1:length(time_periods), .combine = "c") %do% {
test_cross_section <- test %>%
filter(time == time_periods[t])
test_cross_section_x <- test_cross_section[4:ncol(test_cross_section)]
residuals <- test_cross_section$rt - (nnet_model %>% predict(as.matrix(test_cross_section_x)))
mean(residuals)
}
ave_forecast_resids_vector
}
ELN_stats_mae <- ELN_fit_stats(alpha_grid = seq(0, 1, 0.01), nlamb = 100,
realdata_timeSlices, final_dataset, "mae",
macro_factor_names, individual_factor_names)
install.packages(c("broom", "callr", "chron", "dplyr", "fracdiff", "jsonlite", "prettyunits", "RcppArmadillo", "rlang", "stringi", "tidyr", "tidyselect", "tsibble", "vctrs", "yaml"))
knitr::opts_chunk$set(echo = TRUE)
################
##Load Libraries
################
library(keras)
library(ggplot2)
library(forecast)
library(rlist)
library(Metrics)
library(ranger)
library(caret)
library(readr)
library(zoo)
library(readxl)
library(Matrix)
library(speedglm)
library(tidyimpute)
library(tidyverse)
library(hqreg)
library(xtable)
#Parallel Computing
library(foreach)
library(doFuture)
#Registering
registerDoFuture()
plan(multisession)
set.seed(27935248)
#################################################
# Load RAW data courtesy of Gu et al
#################################################
# This is about ~ 3GB in size in total
# Note that because the honours lab computers don't have their own hard drives (files are stored on some network location), this initial loading processis very slow (bottlenecked by network speed)
datashare_RAW <- read_csv("~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/data/datashare/datashare.csv",
# Always make sure to force col_types so that read_csv doesn't assume weird stuff
col_types = cols(.default = "d"))
# Export stock IDs so that we can query WRDS returns
# WRDS wants a txt file with one code per line and nothing else
datashare_stock_ids <- unique(datashare_RAW$permno)
write.table(datashare_stock_ids, file = "datashare_stock_ids.txt", sep = " ",
row.names = FALSE, col.names = FALSE)
# datashare with RET, Prices, and primary exchange
datashare_RET_RAW <- read_csv("~/GitHub/Evaluation-of-Machine-Learning-in-Asset-Pricing/R/data/datashare/datashare_PRC.csv") %>%
# Rename some columns
mutate(DATE = date) %>%
dplyr::select(-date) %>%
mutate(permno = PERMNO) %>%
dplyr::select(-PERMNO)
# It seems that datashare with RET has more rows than the datashare file
# Full join them for now
datashare_RAW_join <- full_join(datashare_RAW, datashare_RET_RAW, by = c("permno", "DATE")) %>%
# Reorder variables
mutate(stock = permno) %>%
dplyr::select(-permno) %>%
dplyr::select(DATE, stock, PRC, everything())
colnames(datashare_RAW_join)
head(datashare_RAW_join)
rm(datashare_RAW)
rm(datashare_RET_RAW)
datashare <- datashare_RAW_join %>%
mutate(time = as.yearmon(as.character(DATE), "%Y%m%d")) %>%
dplyr::select(-DATE) %>%
# Generate log prices
# Drop RET which is monthly return
dplyr::select(time, stock, PRC, -RET, everything()) %>%
# Filter so that we only have NASDAQ stocks
# Remember that the NASDAQ only opened in 1971 ish
filter(PRIMEXCH == "Q") %>%
dplyr::select(-PRIMEXCH) %>%
# Negative PRC means that there was no closing price, and the dash denotes the bid ask average instead
# Not too unreasonable to just take this as the actual price
# Note that PRC has not been corrected for stock splits etc. This is more sensible for modelling purposes
mutate(PRC = abs(PRC)) %>%
# Prices of 0 mean that neither the bid ask average or price were available, ie missing
filter(PRC != 0) %>%
# Filter out PRC < 5 to get rid of penny stocks
filter(PRC >= 5) %>%
# Filter out so that only shares with share codes of 10 or 11 are included (other codes refer to other instruments such as REITs, etc)
# Don't have any idea why Gu et al thought this was originally sensible
filter(SHRCD == 10 | SHRCD == 11) %>%
dplyr::select(-SHRCD) %>%
# SIC codes according to WRDS/CRSP are recommended to be used with caution, as they are not strictly enforced
# Companies can also belong in multiple SIC codes, or change SIC codes over time. This is not adequately captured by CRSP
# Also don't make much consistent sense either
# Personal decision: drop them entirely
dplyr::select(-sic2) %>%
# Adjust lags for monthly data, such that they will correspond to quaterly conversion
mutate(baspread = lag(baspread, 2)) %>%
mutate(baspread = lag(beta, 2)) %>%
mutate(baspread = lag(betasq, 2)) %>%
mutate(idiovol = lag(idiovol, 2)) %>%
mutate(ill = lag(ill, 2)) %>%
mutate(indmom = lag(indmom, 2)) %>%
mutate(mvel1 = lag(mvel1, 2)) %>%
mutate(pricedelay = lag(pricedelay, 2)) %>%
mutate(retvol = lag(retvol, 2)) %>%
mutate(sp = lag(sp, 2)) %>%
mutate(std_dolvol = lag(std_dolvol, 2)) %>%
mutate(std_turn = lag(std_turn, 2)) %>%
mutate(turn = lag(turn, 2)) %>%
mutate(zerotrade = lag(zerotrade, 2)) %>%
# time
mutate(time = as.yearmon(time)) %>%
# We will construct quarterly returns using the end of each month
# Ie using the 3rd, 6th, 9th and 12th month of each year
# yearmon stores year + 0 for January. Exploit this to filter out non-quarter months
filter((as.yearmon(time) %% 1) == 2/12 | (as.yearmon(time) %% 1) == 5/12 | (as.yearmon(time) %% 1) == 8/12 | (as.yearmon(time) %% 1) == 11/12) %>%
# Convert time to yearqtr format
# yearqtr stores data as year + 0/4 for q1, 1/4 for q2, etc
mutate(time = as.yearqtr(time - 2/12)) %>%
dplyr::select(-RET)
time_df <- data.frame(time = unique(datashare$time)) %>%
mutate(time = as.numeric(time))
#####################################
## Generate quarterly returns
#####################################
## This approach drops all companies which do not have comlete stock price history
## This is because many methods require there to be an uniterreupted time series, e.g. GARCH
## Other approaches such as imputation, etc are less sensible due to the unpredictability of the data
## Has obvious drawbacks of introducing lots of survivorship, but what can you do
## Other drawbacks that are important
## Because the original dataset goes back to when the stock exchange was founded, the dataset needs to be filtered by time first
## Otherwise, you will inadventerdently filter out so that only stocks that have been listed on the exchange since the begginning are included
## The old apparoch kept ~ 20000 unique stocks
## This approach keeps a highly variable number of stocks, depending on when you filter the data from
## Going with a filter of >= 1993.5 gives us 195 unique stocks, just going with this for now for feasibility
options(future.globals.maxSize = 3e+9)
datashare <- foreach(i = (1:length(unique(datashare$stock))), .combine = "rbind") %dopar% {
datashare_stock <- datashare %>%
mutate(time = as.numeric(time)) %>%
filter(stock == unique(datashare$stock)[i]) %>%
full_join(time_df, by = "time") %>%
arrange(time) %>%
mutate(rt = (PRC - lag(PRC))/lag(PRC)) %>%
drop_na(rt)
# Method to remove any incomplete univarriate series
# if(sum(is.na(datashare_stock$PRC)) > 0) {
#   datashare_stock <- NULL
# }
datashare_stock
}
length(unique(datashare$stock))
#####################################
## OLD, deprecated, NOT RUN
#####################################
## Generate quarterly returns
## This approach keeps companies that were were unlisted and relisted
## Sensible, because companies can be bought out and floated again, etc.
## Not likely to make a huge difference, but actual quarterly returns are computed, instead of log quarterly returns
## This is because stock prices can in some cases have rather large movements over a quarter
# datashare <- foreach(i = (1:length(unique(datashare$stock))), .combine = rbind) %dopar% {
#   datashare_stock <- datashare %>%
#     mutate(time = as.numeric(time)) %>%
#     filter(stock == unique(datashare$stock)[i]) %>%
#     full_join(time_df, by = "time") %>%
#     arrange(time) %>%
#     mutate(rt = (PRC - lag(PRC))/lag(PRC)) %>%
#     drop_na(rt)
#   datashare_stock
# }
# Reorder (again)
datashare <- datashare %>%
dplyr::select(time, stock, rt, everything()) %>%
dplyr::select(-PRC) %>%
mutate(time = as.yearqtr(time))
# Check Missing data stats
# Missing data tends to get a bit better as time goes forward
# Therefore conduct this with
# Rule of thumb: drop any column missing more than 20% of data
# Best trade off between missing columns and maintaing a large dataset seems to be cutting it off ~1990s.
missing_factors <- datashare %>%
# Change time filtering here
filter(time >= 1993.5) %>%
gather(col, value) %>%
group_by(col) %>%
summarize(missing_share = mean(is.na(value))) %>%
filter(missing_share > 0.20)
write.csv(missing_factors, file = "missing_factors.csv")
## Remove previously identified factors
datashare_filtered <- datashare %>%
filter(time >= 1993.5) %>%
dplyr::select(-c(missing_factors$col))
# Dealing with Missing characteristics
# Function to impute missing characteristics with their CROSS SECTIONAL median (as with gu et al) or mean (conventional) for each stock
# THIS FUNCTION WORKS PROPERLY, HOWEVER THE DATASET HAS TOO MUCH MISSING DATA
# Many of the earlier cross sections are completely missing any sort of data for some characteristics
# This means that it is impossible to impute a cross sectional mean/median
# The foreach loop may through some errors if this is the case but will still function correctly, check the output to see which exact factors are missing
# Don't know how Gu et al did this
# Function to calculate cross sectional medians/means from panel dataset, mainly for checking purposes
# Assumes that the dataset has a "time" column
# doFuture has a maxsize default of around 500 MB
# In the current setting this is sufficient for our dataset, but you can set the maxsize to something larger like so:
#options(future.globals.maxSize = 3e+9)
cross_sectional_values <- function(dataset, impute_type) {
time_periods <- unique(dataset$time)
cross_sectional_values_df <- foreach(t = 1:length(time_periods), .combine = "rbind") %dopar% {
dataset_cross_section <- dataset %>%
filter(time == time_periods[t])
# Mean Case
if (impute_type == "mean") {
cross_sectional_values <- dataset_cross_section %>%
summarize_all(mean, na.rm = TRUE) %>%
mutate(time = as.yearqtr(time))
}
# Median Case
else {
cross_sectional_values <- dataset_cross_section %>%
summarize_all(median, na.rm = TRUE) %>%
mutate(time = as.yearqtr(time))
}
cross_sectional_values
}
cross_sectional_values_df
}
test <- cross_sectional_values(datashare_filtered, impute_type = "median")
# Checks to see if there are any time periods where there is no cross sectional imputation possible due to missing data
# Looks all good
cbind(test$time, (test)[colSums(is.na(test)) > 0])
colnames(test)[colSums(is.na(test)) > 0]
# Function to impute cross sectional values
impute_cross_section <- function(dataset, impute_type) {
time_periods <- unique(dataset$time)
imputed_cross_section_df <- foreach(t = 1:length(time_periods), .combine = "rbind") %dopar% {
dataset_cross_section <- dataset %>%
filter(time == time_periods[t])
if (impute_type == "median") {
# Impute the median for ALL columns
dataset_cross_section %>%
impute_median()
} else {
dataset_cross_section %>%
impute_mean()
}
}
imputed_cross_section_df
}
datashare_imputed <- impute_cross_section(datashare_filtered, impute_type = "median") %>%
mutate(time = as.yearqtr(time)) %>%
# Rename some factors
mutate(beta1 = beta) %>%
dplyr::select(-beta) %>%
# Make the names clearer
rename_at(vars(-time, -stock, -rt), function(x) paste0("ind_", x))
# Summary Statistics
summary(datashare_imputed)
