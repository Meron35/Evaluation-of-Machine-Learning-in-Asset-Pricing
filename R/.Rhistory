ugarch_forecast <- ugarchforecast(ugarch_spec_fit, n.ahead = 12, n.roll = 11)
## Stochastic volatility model
## Theoretically the most correctly specified model, but very computatioally intensive, and may be infeasible
## Takes ~ 14 seconds to estimate
#stochvol_model <- svlsample(univariate_time_series, draws = 10000, burnin = 1000, designmatrix = "ar1",
priormu = c(0, 100), priorphi = c(5, 1.5), priorsigma = 1,
foreach(i = 1:length(unique(pooled_panel$stock)), .combine = "rbind") %dopar% {
## Filter Data first
stock_id <- unique(pooled_panel$stock)
univariate_time_series <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$train | time %in% timeSlices[[1]]$validation) %>%
select(rt) %>%
ts()
univariate_time_series_test <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$test) %>%
select(rt) %>%
ts()
## Estimation of consituent models
# Naive
naive_model <- naive(univariate_time_series, h = 12)
# Random walk with drift
random_walk_model <- rwf(univariate_time_series, h = 12, drift = TRUE)
# Seasonal Naive, this ends up being the same as naive
seasonal_naive_model <- snaive(univariate_time_series, h = 12)
# Theta Method
theta_model <- thetaf(univariate_time_series, h = 12)
## Auto arima
auto_arima_model <- auto.arima(univariate_time_series)
# Auto ETS
auto_ets_model <- ets(univariate_time_series)
# TBATS
tbats_model <- tbats(univariate_time_series)
# Neural Network time series forecasts
nnetar_model <- nnetar(univariate_time_series)
# Naive model that forecasts 0
# Neat idea, but practically speaking ends up being the sam eas auto arima's 0, 0, 0 model most of the time
# naive0_model <- rep(0, 12)
# mse(as.vector(univariate_time_series_test), naive0_model)
# ARMA 1, 1 with GARCH 1, 1 gaussian errors
ugarch_spec <- ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(1, 1),
include.mean = TRUE,
external.regressors = NULL),
distribution.model = "norm")
ugarch_spec_fit <- ugarchfit(ugarch_spec, data = univariate_time_series, out.sample = 12)
ugarch_forecast <- ugarchforecast(ugarch_spec_fit, n.ahead = 12, n.roll = 11)
## Stochastic volatility model
## Theoretically the most correctly specified model, but very computatioally intensive, and may be infeasible
## Takes ~ 14 seconds to estimate
#stochvol_model <- svlsample(univariate_time_series, draws = 10000, burnin = 1000, designmatrix = "ar1",
#priormu = c(0, 100), priorphi = c(5, 1.5), priorsigma = 1,
#priorrho = c(4, 4), priorbeta = c(0, 10000), thinpara = 1,
#thinlatent = 1, thintime = NULL, keeptime = "all", quiet = TRUE)
## Put errors into a single row
errors <- data.frame(naive = mse(as.vector(univariate_time_series_test), predict(naive_model)$mean),
random_walk = mse(as.vector(univariate_time_series_test), predict(random_walk_model)$mean),
theta = mse(as.vector(univariate_time_series_test), predict(theta_model)$mean),
auto_arima = mse(as.vector(univariate_time_series_test),
forecast(auto_arima_model, h = 12)$mean),
ets = mse(as.vector(univariate_time_series_test), forecast(auto_ets_model, h = 12)$mean),
tbats = mse(as.vector(univariate_time_series_test), forecast(tbats_model, h = 12)$mean),
nnetar = mse(as.vector(univariate_time_series_test), forecast(nnetar_model, h = 12)$mean),
garch_11 = mse(as.vector(univariate_time_series_test), fitted(ugarch_forecast)[1, ]))
#stochvol = mse(as.vector(univariate_time_series_test),
#apply(X = predict(stochvol_model, steps = 12)$y, MARGIN = 2, FUN = mean)))
errors
}
foreach(i = 1:length(unique(pooled_panel$stock)), .combine = "rbind") %dopar% {
## Filter Data first
stock_id <- unique(pooled_panel$stock)
univariate_time_series <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$train | time %in% timeSlices[[1]]$validation) %>%
select(rt) %>%
ts()
univariate_time_series_test <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$test) %>%
select(rt) %>%
ts()
## Estimation of consituent models
# Naive
naive_model <- naive(univariate_time_series, h = 12)
# Random walk with drift
random_walk_model <- rwf(univariate_time_series, h = 12, drift = TRUE)
# Seasonal Naive, this ends up being the same as naive
seasonal_naive_model <- snaive(univariate_time_series, h = 12)
# Theta Method
theta_model <- thetaf(univariate_time_series, h = 12)
## Auto arima
auto_arima_model <- auto.arima(univariate_time_series)
# Auto ETS
auto_ets_model <- ets(univariate_time_series)
# TBATS
tbats_model <- tbats(univariate_time_series)
# Neural Network time series forecasts
nnetar_model <- nnetar(univariate_time_series)
# Naive model that forecasts 0
# Neat idea, but practically speaking ends up being the sam eas auto arima's 0, 0, 0 model most of the time
# naive0_model <- rep(0, 12)
# mse(as.vector(univariate_time_series_test), naive0_model)
# ARMA 1, 1 with GARCH 1, 1 gaussian errors
ugarch_spec <- ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(1, 1),
include.mean = TRUE,
external.regressors = NULL),
distribution.model = "norm")
ugarch_spec_fit <- ugarchfit(ugarch_spec, data = univariate_time_series, out.sample = 12,
solver.control=list(trace = 1))
ugarch_forecast <- ugarchforecast(ugarch_spec_fit, n.ahead = 12, n.roll = 11)
## Stochastic volatility model
## Theoretically the most correctly specified model, but very computatioally intensive, and may be infeasible
## Takes ~ 14 seconds to estimate
#stochvol_model <- svlsample(univariate_time_series, draws = 10000, burnin = 1000, designmatrix = "ar1",
#priormu = c(0, 100), priorphi = c(5, 1.5), priorsigma = 1,
#priorrho = c(4, 4), priorbeta = c(0, 10000), thinpara = 1,
#thinlatent = 1, thintime = NULL, keeptime = "all", quiet = TRUE)
## Put errors into a single row
errors <- data.frame(naive = mse(as.vector(univariate_time_series_test), predict(naive_model)$mean),
random_walk = mse(as.vector(univariate_time_series_test), predict(random_walk_model)$mean),
theta = mse(as.vector(univariate_time_series_test), predict(theta_model)$mean),
auto_arima = mse(as.vector(univariate_time_series_test),
forecast(auto_arima_model, h = 12)$mean),
ets = mse(as.vector(univariate_time_series_test), forecast(auto_ets_model, h = 12)$mean),
tbats = mse(as.vector(univariate_time_series_test), forecast(tbats_model, h = 12)$mean),
nnetar = mse(as.vector(univariate_time_series_test), forecast(nnetar_model, h = 12)$mean),
garch_11 = mse(as.vector(univariate_time_series_test), fitted(ugarch_forecast)[1, ]))
#stochvol = mse(as.vector(univariate_time_series_test),
#apply(X = predict(stochvol_model, steps = 12)$y, MARGIN = 2, FUN = mean)))
errors
}
foreach(i = 1:length(unique(pooled_panel$stock)), .combine = "rbind") %dopar% {
## Filter Data first
stock_id <- unique(pooled_panel$stock)
univariate_time_series <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$train | time %in% timeSlices[[1]]$validation) %>%
select(rt) %>%
ts()
univariate_time_series_test <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$test) %>%
select(rt) %>%
ts()
## Estimation of consituent models
# Naive
naive_model <- naive(univariate_time_series, h = 12)
# Random walk with drift
random_walk_model <- rwf(univariate_time_series, h = 12, drift = TRUE)
# Seasonal Naive, this ends up being the same as naive
seasonal_naive_model <- snaive(univariate_time_series, h = 12)
# Theta Method
theta_model <- thetaf(univariate_time_series, h = 12)
## Auto arima
auto_arima_model <- auto.arima(univariate_time_series)
# Auto ETS
auto_ets_model <- ets(univariate_time_series)
# TBATS
tbats_model <- tbats(univariate_time_series)
# Neural Network time series forecasts
nnetar_model <- nnetar(univariate_time_series)
# Naive model that forecasts 0
# Neat idea, but practically speaking ends up being the sam eas auto arima's 0, 0, 0 model most of the time
# naive0_model <- rep(0, 12)
# mse(as.vector(univariate_time_series_test), naive0_model)
# ARMA 1, 1 with GARCH 1, 1 gaussian errors
ugarch_spec <- ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(1, 1),
include.mean = TRUE,
external.regressors = NULL),
distribution.model = "norm")
ugarch_spec_fit <- ugarchfit(ugarch_spec, data = univariate_time_series, out.sample = 12,
solver.control = list(tol = 1e-12))
ugarch_forecast <- ugarchforecast(ugarch_spec_fit, n.ahead = 12, n.roll = 11)
## Stochastic volatility model
## Theoretically the most correctly specified model, but very computatioally intensive, and may be infeasible
## Takes ~ 14 seconds to estimate
#stochvol_model <- svlsample(univariate_time_series, draws = 10000, burnin = 1000, designmatrix = "ar1",
#priormu = c(0, 100), priorphi = c(5, 1.5), priorsigma = 1,
#priorrho = c(4, 4), priorbeta = c(0, 10000), thinpara = 1,
#thinlatent = 1, thintime = NULL, keeptime = "all", quiet = TRUE)
## Put errors into a single row
errors <- data.frame(naive = mse(as.vector(univariate_time_series_test), predict(naive_model)$mean),
random_walk = mse(as.vector(univariate_time_series_test), predict(random_walk_model)$mean),
theta = mse(as.vector(univariate_time_series_test), predict(theta_model)$mean),
auto_arima = mse(as.vector(univariate_time_series_test),
forecast(auto_arima_model, h = 12)$mean),
ets = mse(as.vector(univariate_time_series_test), forecast(auto_ets_model, h = 12)$mean),
tbats = mse(as.vector(univariate_time_series_test), forecast(tbats_model, h = 12)$mean),
nnetar = mse(as.vector(univariate_time_series_test), forecast(nnetar_model, h = 12)$mean),
garch_11 = mse(as.vector(univariate_time_series_test), fitted(ugarch_forecast)[1, ]))
#stochvol = mse(as.vector(univariate_time_series_test),
#apply(X = predict(stochvol_model, steps = 12)$y, MARGIN = 2, FUN = mean)))
errors
}
foreach(i = 1:length(unique(pooled_panel$stock)), .combine = "rbind") %dopar% {
## Filter Data first
stock_id <- unique(pooled_panel$stock)
univariate_time_series <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$train | time %in% timeSlices[[1]]$validation) %>%
select(rt) %>%
ts()
univariate_time_series_test <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$test) %>%
select(rt) %>%
ts()
## Estimation of consituent models
# Naive
naive_model <- naive(univariate_time_series, h = 12)
# Random walk with drift
random_walk_model <- rwf(univariate_time_series, h = 12, drift = TRUE)
# Seasonal Naive, this ends up being the same as naive
seasonal_naive_model <- snaive(univariate_time_series, h = 12)
# Theta Method
theta_model <- thetaf(univariate_time_series, h = 12)
## Auto arima
auto_arima_model <- auto.arima(univariate_time_series)
# Auto ETS
auto_ets_model <- ets(univariate_time_series)
# TBATS
tbats_model <- tbats(univariate_time_series)
# Neural Network time series forecasts
nnetar_model <- nnetar(univariate_time_series)
# Naive model that forecasts 0
# Neat idea, but practically speaking ends up being the sam eas auto arima's 0, 0, 0 model most of the time
# naive0_model <- rep(0, 12)
# mse(as.vector(univariate_time_series_test), naive0_model)
# ARMA 1, 1 with GARCH 1, 1 gaussian errors
ugarch_spec <- ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(1, 1),
include.mean = TRUE,
external.regressors = NULL),
distribution.model = "norm")
ugarch_spec_fit <- ugarchfit(ugarch_spec, data = univariate_time_series, out.sample = 12,
solver = "hybrid",
solver.control = list(tol = 1e-12))
ugarch_forecast <- ugarchforecast(ugarch_spec_fit, n.ahead = 12, n.roll = 11)
## Stochastic volatility model
## Theoretically the most correctly specified model, but very computatioally intensive, and may be infeasible
## Takes ~ 14 seconds to estimate
#stochvol_model <- svlsample(univariate_time_series, draws = 10000, burnin = 1000, designmatrix = "ar1",
#priormu = c(0, 100), priorphi = c(5, 1.5), priorsigma = 1,
#priorrho = c(4, 4), priorbeta = c(0, 10000), thinpara = 1,
#thinlatent = 1, thintime = NULL, keeptime = "all", quiet = TRUE)
## Put errors into a single row
errors <- data.frame(naive = mse(as.vector(univariate_time_series_test), predict(naive_model)$mean),
random_walk = mse(as.vector(univariate_time_series_test), predict(random_walk_model)$mean),
theta = mse(as.vector(univariate_time_series_test), predict(theta_model)$mean),
auto_arima = mse(as.vector(univariate_time_series_test),
forecast(auto_arima_model, h = 12)$mean),
ets = mse(as.vector(univariate_time_series_test), forecast(auto_ets_model, h = 12)$mean),
tbats = mse(as.vector(univariate_time_series_test), forecast(tbats_model, h = 12)$mean),
nnetar = mse(as.vector(univariate_time_series_test), forecast(nnetar_model, h = 12)$mean),
garch_11 = mse(as.vector(univariate_time_series_test), fitted(ugarch_forecast)[1, ]))
#stochvol = mse(as.vector(univariate_time_series_test),
#apply(X = predict(stochvol_model, steps = 12)$y, MARGIN = 2, FUN = mean)))
errors
}
foreach(i = 1:length(unique(pooled_panel$stock)), .combine = "rbind") %dopar% {
## Filter Data first
stock_id <- unique(pooled_panel$stock)
univariate_time_series <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$train | time %in% timeSlices[[1]]$validation) %>%
select(rt) %>%
ts()
univariate_time_series_test <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$test) %>%
select(rt) %>%
ts()
## Estimation of consituent models
# Naive
naive_model <- naive(univariate_time_series, h = 12)
# Random walk with drift
random_walk_model <- rwf(univariate_time_series, h = 12, drift = TRUE)
# Seasonal Naive, this ends up being the same as naive
seasonal_naive_model <- snaive(univariate_time_series, h = 12)
# Theta Method
theta_model <- thetaf(univariate_time_series, h = 12)
## Auto arima
auto_arima_model <- auto.arima(univariate_time_series)
# Auto ETS
auto_ets_model <- ets(univariate_time_series)
# TBATS
tbats_model <- tbats(univariate_time_series)
# Neural Network time series forecasts
nnetar_model <- nnetar(univariate_time_series)
# Naive model that forecasts 0
# Neat idea, but practically speaking ends up being the sam eas auto arima's 0, 0, 0 model most of the time
# naive0_model <- rep(0, 12)
# mse(as.vector(univariate_time_series_test), naive0_model)
# ARMA 1, 1 with GARCH 1, 1 gaussian errors
ugarch_spec <- ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(1, 1),
include.mean = TRUE,
external.regressors = NULL),
distribution.model = "norm")
ugarch_spec_fit <- ugarchfit(ugarch_spec, data = univariate_time_series, out.sample = 12,
solver = "hybrid")
ugarch_forecast <- ugarchforecast(ugarch_spec_fit, n.ahead = 12, n.roll = 11)
## Stochastic volatility model
## Theoretically the most correctly specified model, but very computatioally intensive, and may be infeasible
## Takes ~ 14 seconds to estimate
#stochvol_model <- svlsample(univariate_time_series, draws = 10000, burnin = 1000, designmatrix = "ar1",
#priormu = c(0, 100), priorphi = c(5, 1.5), priorsigma = 1,
#priorrho = c(4, 4), priorbeta = c(0, 10000), thinpara = 1,
#thinlatent = 1, thintime = NULL, keeptime = "all", quiet = TRUE)
## Put errors into a single row
errors <- data.frame(naive = mse(as.vector(univariate_time_series_test), predict(naive_model)$mean),
random_walk = mse(as.vector(univariate_time_series_test), predict(random_walk_model)$mean),
theta = mse(as.vector(univariate_time_series_test), predict(theta_model)$mean),
auto_arima = mse(as.vector(univariate_time_series_test),
forecast(auto_arima_model, h = 12)$mean),
ets = mse(as.vector(univariate_time_series_test), forecast(auto_ets_model, h = 12)$mean),
tbats = mse(as.vector(univariate_time_series_test), forecast(tbats_model, h = 12)$mean),
nnetar = mse(as.vector(univariate_time_series_test), forecast(nnetar_model, h = 12)$mean),
garch_11 = mse(as.vector(univariate_time_series_test), fitted(ugarch_forecast)[1, ]))
#stochvol = mse(as.vector(univariate_time_series_test),
#apply(X = predict(stochvol_model, steps = 12)$y, MARGIN = 2, FUN = mean)))
errors
}
errors <- foreach(i = 1:length(unique(pooled_panel$stock)), .combine = "rbind") %dopar% {
## Filter Data first
stock_id <- unique(pooled_panel$stock)
univariate_time_series <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$train | time %in% timeSlices[[1]]$validation) %>%
select(rt) %>%
ts()
univariate_time_series_test <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$test) %>%
select(rt) %>%
ts()
## Estimation of consituent models
# Naive
naive_model <- naive(univariate_time_series, h = 12)
# Random walk with drift
random_walk_model <- rwf(univariate_time_series, h = 12, drift = TRUE)
# Seasonal Naive, this ends up being the same as naive
seasonal_naive_model <- snaive(univariate_time_series, h = 12)
# Theta Method
theta_model <- thetaf(univariate_time_series, h = 12)
## Auto arima
auto_arima_model <- auto.arima(univariate_time_series)
# Auto ETS
auto_ets_model <- ets(univariate_time_series)
# TBATS
tbats_model <- tbats(univariate_time_series)
# Neural Network time series forecasts
nnetar_model <- nnetar(univariate_time_series)
# Naive model that forecasts 0
# Neat idea, but practically speaking ends up being the sam eas auto arima's 0, 0, 0 model most of the time
# naive0_model <- rep(0, 12)
# mse(as.vector(univariate_time_series_test), naive0_model)
# ARMA 1, 1 with GARCH 1, 1 gaussian errors
ugarch_spec <- ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(1, 1),
include.mean = TRUE,
external.regressors = NULL),
distribution.model = "norm")
ugarch_spec_fit <- ugarchfit(ugarch_spec, data = univariate_time_series, out.sample = 12,
solver = "hybrid")
ugarch_forecast <- ugarchforecast(ugarch_spec_fit, n.ahead = 12, n.roll = 11)
## Stochastic volatility model
## Theoretically the most correctly specified model, but very computatioally intensive, and may be infeasible
## Takes ~ 14 seconds to estimate
#stochvol_model <- svlsample(univariate_time_series, draws = 10000, burnin = 1000, designmatrix = "ar1",
#priormu = c(0, 100), priorphi = c(5, 1.5), priorsigma = 1,
#priorrho = c(4, 4), priorbeta = c(0, 10000), thinpara = 1,
#thinlatent = 1, thintime = NULL, keeptime = "all", quiet = TRUE)
## Put errors into a single row
errors <- data.frame(naive = mse(as.vector(univariate_time_series_test), predict(naive_model)$mean),
random_walk = mse(as.vector(univariate_time_series_test), predict(random_walk_model)$mean),
theta = mse(as.vector(univariate_time_series_test), predict(theta_model)$mean),
auto_arima = mse(as.vector(univariate_time_series_test),
forecast(auto_arima_model, h = 12)$mean),
ets = mse(as.vector(univariate_time_series_test), forecast(auto_ets_model, h = 12)$mean),
tbats = mse(as.vector(univariate_time_series_test), forecast(tbats_model, h = 12)$mean),
nnetar = mse(as.vector(univariate_time_series_test), forecast(nnetar_model, h = 12)$mean),
garch_11 = mse(as.vector(univariate_time_series_test), fitted(ugarch_forecast)[1, ]))
#stochvol = mse(as.vector(univariate_time_series_test),
#apply(X = predict(stochvol_model, steps = 12)$y, MARGIN = 2, FUN = mean)))
errors
}
which.min(errors)
which.min(errors[1, ])
which.min(errors[2, ])
foreach(1 = i:nrow(errors), .combine = "rbind") %dopar% {
foreach(i = 1:nrow(errors), .combine = "rbind") %dopar% {
which.min(errors[2, ])
}
which.min(errors[1, ])
which.min(errors[2, ])
which.min(errors[3, ])
which.min(errors[4, ])
as.numeric(which.min(errors[2, ]))
foreach(i = 1:nrow(errors), .combine = "rbind") %dopar% {
as.numeric(which.min(errors[2, ]))
}
which.min(errors[i, ])
foreach(i = 1:nrow(errors), .combine = "rbind") %dopar% {
which.min(errors[i, ])
}
foreach(i = 1:nrow(errors), .combine = "rbind") %dopar% {
as.numeric(which.min(errors[i, ]))
}
labels <- foreach(i = 1:nrow(errors), .combine = "rbind") %dopar% {
as.numeric(which.min(errors[i, ]))
}
View(labels)
labels <- foreach(i = 1:nrow(errors), .combine = "rbind") %dopar% {
data.frame(label = which.min(errors[i, ]))
}
View(labels)
train_list <- list(
data = data,
errors = errors,
labels = labels
)
View(train_list)
### Data matrix
# Just use fforma_features function from before, easy
data <- fforma_features(univariate_time_series)
fforma_features <- function(time_series) {
cbind(
# Series length
length = length(time_series),
# nperiods, seasonal_period, trend, seasonality, linearity, curvature, spikiness e_acr1 and e_acf10
tsfeatures(time_series, features = "stl_features"),
# Stability
tsfeatures(time_series, features = "stability"),
# Lumpiness
tsfeatures(time_series, features = "lumpiness"),
# Hurst
tsfeatures(time_series, features = "hurst"),
# Nonlinearity
tsfeatures(time_series, features = "nonlinearity"),
# Holt alpha and beta
tsfeatures(time_series, features = "holt_parameters"),
# HW alpha and beta, only applies for seasonal time series
#tsfeatures(time_series, features = "hw_parameters"),
# Unitroot statistics
tsfeatures(time_series, features = c("unitroot_kpss", "unitroot_pp")),
# ACF features
tsfeatures(time_series, features = "acf_features"),
# PACF features
tsfeatures(time_series, features = "pacf_features"),
# Crossing point
tsfeatures(time_series, features = "crossing_points"),
# flat_spots
tsfeatures(time_series, features = "flat_spots"),
# arch_lm
tsfeatures(time_series, features = "arch_stat"),
# Heterogeneity
tsfeatures(time_series, features = "heterogeneity")
)
}
# Test, works perfectly
fforma_features(univariate_time_series)
### Data matrix
# Just use fforma_features function from before, easy
data <- foreach(i = 1:length(unique(pooled_panel$stock)), .combine = "rbind") %dopar% {
stock_id <- unique(pooled_panel$stock)
univariate_time_series <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$train | time %in% timeSlices[[1]]$validation) %>%
select(rt) %>%
ts()
univariate_time_series_test <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$test) %>%
select(rt) %>%
ts()
fforma_features(univariate_time_series)
}
View(data)
train_list <- list(
data = data,
errors = errors,
labels = labels
)
View(train_list)
