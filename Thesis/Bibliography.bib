
@techreport{gu_empirical_2018,
	title = {Empirical asset pricing via machine learning},
	institution = {National Bureau of Economic Research},
	author = {Gu, Shihao and Kelly, Bryan and Xiu, Dacheng},
	year = {2018},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\IZI8E646\\Gu et al. - 2018 - Empirical asset pricing via machine learning.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\7AJ5R4DV\\w25398.html:text/html}
}

@article{kingma_adam:_2014,
	title = {Adam: {A} method for stochastic optimization},
	shorttitle = {Adam},
	journal = {arXiv preprint arXiv:1412.6980},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	year = {2014},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\XPQ84NTS\\Kingma and Ba - 2014 - Adam A method for stochastic optimization.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\TWXPALJ9\\1412.html:text/html}
}

@article{ioffe_batch_2015,
	title = {Batch normalization: {Accelerating} deep network training by reducing internal covariate shift},
	shorttitle = {Batch normalization},
	journal = {arXiv preprint arXiv:1502.03167},
	author = {Ioffe, Sergey and Szegedy, Christian},
	year = {2015},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\6AVA4J9P\\Ioffe and Szegedy - 2015 - Batch normalization Accelerating deep network tra.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\Z4QITTZ7\\1502.html:text/html}
}

@inproceedings{glorot_deep_2011,
	title = {Deep sparse rectifier neural networks},
	booktitle = {Proceedings of the fourteenth international conference on artificial intelligence and statistics},
	author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
	year = {2011},
	pages = {315--323},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\NBWYQJV3\\Glorot et al. - 2011 - Deep sparse rectifier neural networks.pdf:application/pdf}
}

@article{diebold_comparing_2002,
	title = {Comparing predictive accuracy},
	volume = {20},
	number = {1},
	journal = {Journal of Business \& economic statistics},
	author = {Diebold, Francis X. and Mariano, Robert S.},
	year = {2002},
	pages = {134--144},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\5PGXHY68\\Diebold and Mariano - 2002 - Comparing predictive accuracy.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\SKQKUQXP\\073500102753410444.html:text/html}
}

@article{diebold_comparing_2015,
	title = {Comparing predictive accuracy, twenty years later: {A} personal perspective on the use and abuse of {Diebold}–{Mariano} tests},
	volume = {33},
	shorttitle = {Comparing predictive accuracy, twenty years later},
	number = {1},
	journal = {Journal of Business \& Economic Statistics},
	author = {Diebold, Francis X.},
	year = {2015},
	pages = {1--1},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\3Z5EH8U9\\Diebold - 2015 - Comparing predictive accuracy, twenty years later.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\GW9SQ6NI\\07350015.2014.html:text/html}
}

@article{hansen_neural_1990,
	title = {Neural network ensembles},
	number = {10},
	journal = {IEEE Transactions on Pattern Analysis \& Machine Intelligence},
	author = {Hansen, Lars Kai and Salamon, Peter},
	year = {1990},
	pages = {993--1001},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\TM5TQF7C\\Hansen and Salamon - 1990 - Neural network ensembles.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\ZZ59T5J5\\13rRUyv53Gg.html:text/html}
}

@book{mcnelis_neural_2005,
	title = {Neural networks in finance: gaining predictive edge in the market},
	shorttitle = {Neural networks in finance},
	publisher = {Academic Press},
	author = {McNelis, Paul D.},
	year = {2005},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\M4QSXDIK\\McNelis - 2005 - Neural networks in finance gaining predictive edg.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\8HMDM9UG\\books.html:text/html}
}

@article{hornik_multilayer_1989,
	title = {Multilayer feedforward networks are universal approximators},
	volume = {2},
	number = {5},
	journal = {Neural networks},
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	year = {1989},
	pages = {359--366},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\QE6M8ZJ5\\Hornik et al. - 1989 - Multilayer feedforward networks are universal appr.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\SJJNRXX4\\0893608089900208.html:text/html}
}

@article{jagannathan_asymptotic_1998,
	title = {An {Asymptotic} {Theory} for {Estimating} {Beta}-{Pricing} {Models} {Using} {Cross}-{Sectional} {Regression}},
	volume = {53},
	issn = {00221082},
	url = {http://doi.wiley.com/10.1111/0022-1082.00053},
	doi = {10.1111/0022-1082.00053},
	abstract = {Without the assumption of conditional homoskedasticity, a general asymptotic distribution theory for the two-stage cross-sectional regression method shows that the standard errors produced by the Fama–MacBeth procedure do not necessarily overstate the precision of the risk premium estimates. When factors are misspecified, estimators for risk premiums can be biased, and the t-value of a premium may converge to infinity in probability even when the true premium is zero. However, when a beta-pricing model is misspecified, the t-values for firm characteristics generally converge to infinity in probability, which supports the use of firm characteristics in cross-sectional regressions for detecting model misspecification.},
	language = {en},
	number = {4},
	urldate = {2019-03-20},
	journal = {The Journal of Finance},
	author = {Jagannathan, Ravi and Wang, Zhenyu},
	month = aug,
	year = {1998},
	pages = {1285--1309},
	file = {Jagannathan and Wang - 1998 - An Asymptotic Theory for Estimating Beta-Pricing M.pdf:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\SCPBB599\\Jagannathan and Wang - 1998 - An Asymptotic Theory for Estimating Beta-Pricing M.pdf:application/pdf}
}

@article{fama_common_1993,
	title = {Common risk factors in the returns on stocks and bonds},
	volume = {33},
	number = {1},
	journal = {Journal of financial economics},
	author = {Fama, Eugene F. and French, Kenneth R.},
	year = {1993},
	pages = {3--56},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\HJLQHCQ5\\Fama and French - 1993 - Common risk factors in the returns on stocks and b.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\XYUZNGM5\\0304405X93900235.html:text/html}
}

@book{breiman_classification_1984,
	title = {Classification and {Regression} {Trees}},
	isbn = {978-1-351-46049-1},
	url = {https://www-taylorfrancis-com.ezproxy.lib.monash.edu.au/books/9781351460491},
	abstract = {The methodology used to construct tree structured rules is the focus of this monograph. Unlike many other statistical procedures, which moved from pencil and},
	language = {en},
	urldate = {2019-03-20},
	publisher = {Routledge},
	author = {Breiman, Leo},
	year = {1984},
	doi = {10.1201/9781315139470},
	file = {Full Text PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\BF5C28VE\\Breiman - 2017 - Classification and Regression Trees.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\86PUB4RZ\\9781351460491.html:text/html}
}

@article{breiman_random_2001,
	title = {Random forests},
	volume = {45},
	number = {1},
	journal = {Machine learning},
	author = {Breiman, Leo},
	year = {2001},
	pages = {5--32},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\QYE49SDE\\Breiman - 2001 - Random forests.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\6ECSQEI6\\A1010933404324.html:text/html}
}

@article{ramachandran_searching_2017,
	title = {Searching for {Activation} {Functions}},
	url = {http://arxiv.org/abs/1710.05941},
	abstract = {The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. Currently, the most successful and widely-used activation function is the Rectified Linear Unit (ReLU). Although various hand-designed alternatives to ReLU have been proposed, none have managed to replace it due to inconsistent gains. In this work, we propose to leverage automatic search techniques to discover new activation functions. Using a combination of exhaustive and reinforcement learning-based search, we discover multiple novel activation functions. We verify the effectiveness of the searches by conducting an empirical evaluation with the best discovered activation function. Our experiments show that the best discovered activation function, \$f(x) = x {\textbackslash}cdot {\textbackslash}text\{sigmoid\}({\textbackslash}beta x)\$, which we name Swish, tends to work better than ReLU on deeper models across a number of challenging datasets. For example, simply replacing ReLUs with Swish units improves top-1 classification accuracy on ImageNet by 0.9{\textbackslash}\% for Mobile NASNet-A and 0.6{\textbackslash}\% for Inception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it easy for practitioners to replace ReLUs with Swish units in any neural network.},
	urldate = {2019-03-20},
	journal = {arXiv:1710.05941 [cs]},
	author = {Ramachandran, Prajit and Zoph, Barret and Le, Quoc V.},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.05941},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: Updated version of "Swish: a Self-Gated Activation Function"},
	file = {arXiv\:1710.05941 PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\DCFSMR9X\\Ramachandran et al. - 2017 - Searching for Activation Functions.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\GQWT2ZRR\\1710.html:text/html}
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	issn = {0028-0836},
	url = {http://adsabs.harvard.edu/abs/2015Natur.521..436L},
	doi = {10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the
state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the
representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	urldate = {2019-03-20},
	journal = {Nature},
	author = {Lecun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	pages = {436--444}
}

@techreport{freyberger_dissecting_2017,
	title = {Dissecting characteristics nonparametrically},
	institution = {National Bureau of Economic Research},
	author = {Freyberger, Joachim and Neuhierl, Andreas and Weber, Michael},
	year = {2017},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\8U7N9M2U\\Freyberger et al. - 2017 - Dissecting characteristics nonparametrically.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\A7KCGDWR\\w23227.html:text/html}
}

@article{kelly_characteristics_2017,
	title = {Some characteristics are risk exposures, and the rest are irrelevant},
	journal = {Unpublished Manuscript, University of Chicago},
	author = {Kelly, Bryan T. and Pruitt, Seth and Su, Yinan},
	year = {2017},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\MQAV5V22\\Kelly et al. - 2017 - Some characteristics are risk exposures, and the r.pdf:application/pdf}
}

@book{masters_practical_1993,
	title = {Practical {Neural} {Network} {Recipes} in {C}++},
	isbn = {978-0-12-479040-7},
	abstract = {This text serves as a cookbook for neural network solutions to practical problems using C++. It will enable those with moderate programming experience to select a neural network model appropriate to solving a particular problem, and to produce a working program implementing that network. The book provides guidance along the entire problem-solving path, including designing the training set, preprocessing variables, training and validating the network, and evaluating its performance. Though the book is not intended as a general course in neural networks, no background in neural works is assumed and all models are presented from the ground up.The principle focus of the book is the three layer feedforward network, for more than a decade as the workhorse of professional arsenals. Other network models with strong performance records are also included.Bound in the book is an IBM diskette that includes the source code for all programs in the book. Much of this code can be easily adapted to C compilers. In addition, the operation of all programs is thoroughly discussed both in the text and in the comments within the code to facilitate translation to other languages.},
	language = {en},
	publisher = {Morgan Kaufmann},
	author = {Masters, Timothy},
	year = {1993},
	note = {Google-Books-ID: 7Ez\_Pq0sp2EC},
	keywords = {Computers / Intelligence (AI) \& Semantics}
}

@techreport{kozak_shrinking_2017,
	title = {Shrinking the cross section},
	institution = {National Bureau of Economic Research},
	author = {Kozak, Serhiy and Nagel, Stefan and Santosh, Shrihari},
	year = {2017},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\6RD9KTF4\\Kozak et al. - 2017 - Shrinking the cross section.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\WVYUV2Q9\\w24070.html:text/html}
}

@book{james_introduction_2013,
	address = {New York},
	series = {Springer texts in statistics},
	title = {An introduction to statistical learning: with applications in {R}},
	isbn = {978-1-4614-7137-0},
	shorttitle = {An introduction to statistical learning},
	language = {en},
	number = {103},
	publisher = {Springer},
	editor = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	year = {2013},
	note = {OCLC: ocn828488009},
	keywords = {Mathematical models, Mathematical statistics, Problems, exercises, etc, R (Computer program language), Statistics},
	file = {James et al. - 2013 - An introduction to statistical learning with appl.pdf:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\ANGVQ7ZP\\James et al. - 2013 - An introduction to statistical learning with appl.pdf:application/pdf}
}

@book{hastie_elements_2009,
	address = {New York, NY},
	edition = {2nd ed},
	series = {Springer series in statistics},
	title = {The elements of statistical learning: data mining, inference, and prediction},
	isbn = {978-0-387-84857-0 978-0-387-84858-7},
	shorttitle = {The elements of statistical learning},
	language = {en},
	publisher = {Springer},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, J. H.},
	year = {2009},
	keywords = {Statistics, Bioinformatics, Computational intelligence, Data mining, Forecasting, Inference, Machine learning, Methodology},
	file = {Hastie et al. - 2009 - The elements of statistical learning data mining,.pdf:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\NFXA4MB3\\Hastie et al. - 2009 - The elements of statistical learning data mining,.pdf:application/pdf}
}

@article{zou_regularization_2005,
	title = {Regularization and variable selection via the {Elastic} {Net}},
	volume = {67},
	abstract = {Summary. We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together.The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.},
	journal = {Journal of the Royal Statistical Society, Series B},
	author = {Zou, Hui and Hastie, Trevor},
	year = {2005},
	pages = {301--320},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\E8WMKCKI\\Zou and Hastie - 2005 - Regularization and variable selection via the Elas.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\SNV9ZISS\\summary.html:text/html}
}

@incollection{huber_robust_1992,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Robust {Estimation} of a {Location} {Parameter}},
	isbn = {978-1-4612-4380-9},
	url = {https://doi.org/10.1007/978-1-4612-4380-9_35},
	abstract = {This paper contains a new approach toward a theory of robust estimation; it treats in detail the asymptotic theory of estimating a location parameter for contaminated normal distributions, and exhibits estimators—intermediaries between sample mean and sample median—that are asymptotically most robust (in a sense to be specified) among all translation invariant estimators. For the general background, see Tukey (1960) (p. 448 ff.)},
	language = {en},
	urldate = {2019-03-23},
	booktitle = {Breakthroughs in {Statistics}: {Methodology} and {Distribution}},
	publisher = {Springer New York},
	author = {Huber, Peter J.},
	editor = {Kotz, Samuel and Johnson, Norman L.},
	year = {1992},
	doi = {10.1007/978-1-4612-4380-9_35},
	keywords = {Asymptotic Normality, Asymptotic Variance, Location Parameter, Maximum Likelihood Estimator, Robust Estimation},
	pages = {492--518},
	file = {Springer Full Text PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\EZS4B7KH\\Huber - 1992 - Robust Estimation of a Location Parameter.pdf:application/pdf}
}

@article{goldberger_econometric_1964,
	title = {Econometric theory.},
	url = {https://www.cabdirect.org/cabdirect/abstract/19651801180},
	abstract = {This textbook offers a systematic and thorough account of the leading current econometric parameter-estimation methods and their properties. The first part (155 pages) is devoted to a systematic treatment of matrix algebra and statistical inference including some reference to stochastic process and is followed by a discussion of the various estimation methods. The whole treatment is in matrix...},
	language = {English},
	urldate = {2019-03-23},
	journal = {Econometric theory.},
	author = {Goldberger, A. S.},
	year = {1964},
	file = {Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\B7BDSHQC\\www.cabdirect.org.html:text/html}
}

@article{hoerl_ridge_1970,
	title = {Ridge regression: {Biased} estimation for nonorthogonal problems},
	volume = {12},
	shorttitle = {Ridge regression},
	number = {1},
	journal = {Technometrics},
	author = {Hoerl, Arthur E. and Kennard, Robert W.},
	year = {1970},
	pages = {55--67},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\LZZJZLIE\\Hoerl and Kennard - 1970 - Ridge regression Biased estimation for nonorthogo.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\3SS8NFB2\\00401706.1970.html:text/html}
}

@article{tibshirani_regression_1996,
	title = {Regression shrinkage and selection via the lasso},
	volume = {58},
	number = {1},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Tibshirani, Robert},
	year = {1996},
	pages = {267--288},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\I2DVMFNE\\Tibshirani - 1996 - Regression shrinkage and selection via the lasso.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\NZE67FPA\\j.2517-6161.1996.tb02080.html:text/html}
}

@article{elliott_complete_2013,
	series = {Dynamic {Econometric} {Modeling} and {Forecasting}},
	title = {Complete subset regressions},
	volume = {177},
	issn = {0304-4076},
	url = {http://www.sciencedirect.com/science/article/pii/S0304407613000948},
	doi = {10.1016/j.jeconom.2013.04.017},
	abstract = {This paper proposes a new method for combining forecasts based on complete subset regressions. For a given set of potential predictor variables we combine forecasts from all possible linear regression models that keep the number of predictors fixed. We explore how the choice of model complexity, as measured by the number of included predictor variables, can be used to trade off the bias and variance of the forecast errors, generating a setup akin to the efficient frontier known from modern portfolio theory. In an application to predictability of stock returns, we find that combinations of subset regressions can produce more accurate forecasts than conventional approaches based on equal-weighted forecasts (which fail to account for the dimensionality of the underlying models), combinations of univariate forecasts, or forecasts generated by methods such as bagging, ridge regression or Bayesian Model Averaging.},
	number = {2},
	urldate = {2019-04-05},
	journal = {Journal of Econometrics},
	author = {Elliott, Graham and Gargano, Antonio and Timmermann, Allan},
	month = dec,
	year = {2013},
	keywords = {Forecast combination, Shrinkage, Subset regression},
	pages = {357--373},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\VDR6FJM9\\Elliott et al. - 2013 - Complete subset regressions.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\DLGAPY3J\\S0304407613000948.html:text/html}
}

@article{ghysels_5_1996,
	title = {5 {Stochastic} volatility},
	volume = {14},
	journal = {Handbook of statistics},
	author = {Ghysels, Eric and Harvey, Andrew C. and Renault, Eric},
	year = {1996},
	pages = {119--191},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\LDWMUKXK\\Ghysels et al. - 1996 - 5 Stochastic volatility.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\P8NTIUXA\\S0169716196140074.html:text/html}
}

@book{shephard_stochastic_2005,
	title = {Stochastic volatility: selected readings},
	shorttitle = {Stochastic volatility},
	publisher = {Oxford University Press on Demand},
	author = {Shephard, Neil},
	year = {2005},
	file = {Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\W8UI357K\\books.html:text/html}
}

@article{timmermann_elusive_2008,
	title = {Elusive return predictability},
	volume = {24},
	number = {1},
	journal = {International Journal of Forecasting},
	author = {Timmermann, Allan},
	year = {2008},
	pages = {1--18},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\6D9GXA5P\\Timmermann - 2008 - Elusive return predictability.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\JGQRQ74Q\\S0169207007000969.html:text/html}
}

@article{ang_stock_2006,
	title = {Stock return predictability: {Is} it there?},
	volume = {20},
	shorttitle = {Stock return predictability},
	number = {3},
	journal = {The Review of Financial Studies},
	author = {Ang, Andrew and Bekaert, Geert},
	year = {2006},
	pages = {651--707},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\XUFQ6EWR\\Ang and Bekaert - 2006 - Stock return predictability Is it there.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\73UMSBSM\\1563908.html:text/html}
}

@techreport{feng_taming_2019,
	title = {Taming the factor zoo: {A} test of new factors},
	shorttitle = {Taming the factor zoo},
	institution = {National Bureau of Economic Research},
	author = {Feng, Guanhao and Giglio, Stefano and Xiu, Dacheng},
	year = {2019},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\E8GDD6MN\\Feng et al. - 2019 - Taming the factor zoo A test of new factors.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\47GF9AWA\\w25481.html:text/html}
}

@misc{online_cover_nodate,
	title = {Cover image - {Handbook} of {Economic} {Forecasting}},
	url = {https://learning.oreilly.com/library/view/handbook-of-economic/9780444536839/xhtml/Cover.xml},
	language = {en},
	urldate = {2019-04-09},
	author = {Online, Safari Books},
	file = {Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\5S8ZHAGX\\Cover.html:text/html}
}

@incollection{rapach_forecasting_2013,
	title = {Forecasting {Stock} {Returns}},
	volume = {2},
	isbn = {978-0-444-53683-9},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780444536839000062},
	language = {en},
	urldate = {2019-04-09},
	booktitle = {Handbook of {Economic} {Forecasting}},
	publisher = {Elsevier},
	author = {Rapach, David and Zhou, Guofu},
	year = {2013},
	doi = {10.1016/B978-0-444-53683-9.00006-2},
	pages = {328--383}
}

@misc{online_chapter_nodate,
	title = {Chapter 6. {Forecasting} {Stock} {Returns} - {Handbook} of {Economic} {Forecasting}},
	url = {https://learning.oreilly.com/library/view/handbook-of-economic/9780444536839/xhtml/Cover.xml},
	language = {en},
	urldate = {2019-04-09},
	author = {Online, Safari Books},
	file = {Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\85R7F4QF\\CHP006.html:text/html}
}

@article{feng_deep_2018,
	title = {Deep {Learning} for {Predicting} {Asset} {Returns}},
	url = {http://arxiv.org/abs/1804.09314},
	abstract = {Deep learning searches for nonlinear factors for predicting asset returns. Predictability is achieved via multiple layers of composite factors as opposed to additive ones. Viewed in this way, asset pricing studies can be revisited using multi-layer deep learners, such as rectified linear units (ReLU) or long-short-term-memory (LSTM) for time-series effects. State-of-the-art algorithms including stochastic gradient descent (SGD), TensorFlow and dropout design provide imple- mentation and efficient factor exploration. To illustrate our methodology, we revisit the equity market risk premium dataset of Welch and Goyal (2008). We find the existence of nonlinear factors which explain predictability of returns, in particular at the extremes of the characteristic space. Finally, we conclude with directions for future research.},
	urldate = {2019-04-09},
	journal = {arXiv:1804.09314 [cs, econ, stat]},
	author = {Feng, Guanhao and He, Jingyu and Polson, Nicholas G.},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.09314},
	keywords = {Computer Science - Machine Learning, Economics - Econometrics, Statistics - Machine Learning},
	file = {arXiv\:1804.09314 PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\DP8MYWET\\Feng et al. - 2018 - Deep Learning for Predicting Asset Returns.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\KGK2XQ5B\\1804.html:text/html}
}

@article{harvey_testing_1997,
	title = {Testing the equality of prediction mean squared errors},
	volume = {13},
	issn = {0169-2070},
	url = {http://www.sciencedirect.com/science/article/pii/S0169207096007194},
	doi = {10.1016/S0169-2070(96)00719-4},
	abstract = {Given two sources of forecasts of the same quantity, it is possible to compare prediction records. In particular, it can be useful to test the hypothesis of equal accuracy in forecast performance. We analyse the behaviour of two possible tests, and of modifications of these tests designed to circumvent shortcomings in the original formulations. As a result of this analysis, a recommendation for one particular testing approach is made for practical applications.},
	number = {2},
	urldate = {2019-04-11},
	journal = {International Journal of Forecasting},
	author = {Harvey, David and Leybourne, Stephen and Newbold, Paul},
	month = jun,
	year = {1997},
	keywords = {Comparing forecasts, Correlated forecast errors, Evaluation of forecasts, Non-normality},
	pages = {281--291},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\QCKFNEZY\\Harvey et al. - 1997 - Testing the equality of prediction mean squared er.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\FE4BUD4G\\S0169207096007194.html:text/html}
}

@article{green_supraview_2013,
	title = {The supraview of return predictive signals},
	volume = {18},
	issn = {1380-6653, 1573-7136},
	url = {http://link.springer.com/10.1007/s11142-013-9231-1},
	doi = {10.1007/s11142-013-9231-1},
	abstract = {This study seeks to inform investment academics and practitioners by describing and analyzing the population of return predictive signals (RPS) publicly identiﬁed over the 40-year period 1970–2010. Our supraview brings to light new facts about RPS, including that more than 330 signals have been reported; the properties of newly discovered RPS are stable over time; and RPS with higher mean returns have larger standard deviations of returns and also higher Sharpe ratios. Using a sample of 39 readily programmed RPS, we estimate that the average crosscorrelation of RPS returns is close to zero and that the average correlation between RPS returns and the market is reliably negative. Abstracting from implementation costs, this implies that portfolios of RPS either on their own or in combination with the market will tend to have quite high Sharpe ratios. For academics who seek to document that they have found a genuinely new RPS, we show that the probability that a randomly chosen RPS has a positive alpha after being orthogonalized against ﬁve (25) other randomly chosen RPS is 62 \% (32 \%), suggesting that the returns of a potentially new RPS need to be orthogonalized against the returns of some but not all pre-existing RPS. Finally, we posit that our ﬁndings pose a challenge to investment academics in that they imply that either US stock markets are pervasively inefﬁcient, or there exist a much larger number of rationally priced sources of risk in equity returns than previously thought.},
	language = {en},
	number = {3},
	urldate = {2019-04-14},
	journal = {Review of Accounting Studies},
	author = {Green, Jeremiah and Hand, John R. M. and Zhang, X. Frank},
	month = sep,
	year = {2013},
	pages = {692--730},
	file = {Green et al. - 2013 - The supraview of return predictive signals.pdf:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\M5NFNS9Q\\Green et al. - 2013 - The supraview of return predictive signals.pdf:application/pdf}
}

@article{zhang_understanding_2016,
	title = {Understanding deep learning requires rethinking generalization},
	url = {http://arxiv.org/abs/1611.03530},
	abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.},
	urldate = {2019-04-17},
	journal = {arXiv:1611.03530 [cs]},
	author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.03530},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Published in ICLR 2017},
	file = {arXiv\:1611.03530 PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\39B45XME\\Zhang et al. - 2016 - Understanding deep learning requires rethinking ge.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\UJ7GV8QN\\1611.html:text/html}
}

@article{choromanska_loss_2014,
	title = {The {Loss} {Surfaces} of {Multilayer} {Networks}},
	url = {http://arxiv.org/abs/1412.0233},
	abstract = {We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural network and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii) redundancy in network parametrization, and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled neural network through the prism of the results from random matrix theory. We show that for large-size decoupled networks the lowest critical values of the random loss function form a layered structure and they are located in a well-defined band lower-bounded by the global minimum. The number of local minima outside that band diminishes exponentially with the size of the network. We empirically verify that the mathematical model exhibits similar behavior as the computer simulations, despite the presence of high dependencies in real networks. We conjecture that both simulated annealing and SGD converge to the band of low critical points, and that all critical points found there are local minima of high quality measured by the test error. This emphasizes a major difference between large- and small-size networks where for the latter poor quality local minima have non-zero probability of being recovered. Finally, we prove that recovering the global minimum becomes harder as the network size increases and that it is in practice irrelevant as global minimum often leads to overfitting.},
	urldate = {2019-04-17},
	journal = {arXiv:1412.0233 [cs]},
	author = {Choromanska, Anna and Henaff, Mikael and Mathieu, Michael and Arous, Gérard Ben and LeCun, Yann},
	month = nov,
	year = {2014},
	note = {arXiv: 1412.0233},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv\:1412.0233 PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\76A3BHLZ\\Choromanska et al. - 2014 - The Loss Surfaces of Multilayer Networks.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\TYD2YPRM\\1412.html:text/html}
}

@article{arpit_closer_2017,
	title = {A {Closer} {Look} at {Memorization} in {Deep} {Networks}},
	url = {http://arxiv.org/abs/1706.05394},
	abstract = {We examine the role of memorization in deep learning, drawing connections to capacity, generalization, and adversarial robustness. While deep networks are capable of memorizing noise data, our results suggest that they tend to prioritize learning simple patterns first. In our experiments, we expose qualitative differences in gradient-based optimization of deep neural networks (DNNs) on noise vs. real data. We also demonstrate that for appropriately tuned explicit regularization (e.g., dropout) we can degrade DNN training performance on noise datasets without compromising generalization on real data. Our analysis suggests that the notions of effective capacity which are dataset independent are unlikely to explain the generalization performance of deep networks when trained with gradient based methods because training data itself plays an important role in determining the degree of memorization.},
	urldate = {2019-04-17},
	journal = {arXiv:1706.05394 [cs, stat]},
	author = {Arpit, Devansh and Jastrzębski, Stanisław and Ballas, Nicolas and Krueger, David and Bengio, Emmanuel and Kanwal, Maxinder S. and Maharaj, Tegan and Fischer, Asja and Courville, Aaron and Bengio, Yoshua and Lacoste-Julien, Simon},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.05394},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Appears in Proceedings of the 34th International Conference on Machine Learning (ICML 2017), Devansh Arpit, Stanis\{{\textbackslash}l\}aw Jastrz{\textbackslash}k\{e\}bski, Nicolas Ballas, and David Krueger contributed equally to this work},
	file = {arXiv\:1706.05394 PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\THHKI2AT\\Arpit et al. - 2017 - A Closer Look at Memorization in Deep Networks.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\PHHNCYIX\\1706.html:text/html}
}

@article{hsu_finding_2014,
	title = {Finding smart beta in the factor zoo},
	journal = {Research Affiliates (July)},
	author = {Hsu, Jason and Kalesnik, Vitali},
	year = {2014},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\2KVSMMD7\\Hsu and Kalesnik - 2014 - Finding smart beta in the factor zoo.pdf:application/pdf}
}

@article{mclean_does_2016,
	title = {Does {Academic} {Research} {Destroy} {Stock} {Return} {Predictability}?},
	volume = {71},
	copyright = {© 2015 the American Finance Association},
	issn = {1540-6261},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/jofi.12365},
	doi = {10.1111/jofi.12365},
	abstract = {We study the out-of-sample and post-publication return predictability of 97 variables shown to predict cross-sectional stock returns. Portfolio returns are 26\% lower out-of-sample and 58\% lower post-publication. The out-of-sample decline is an upper bound estimate of data mining effects. We estimate a 32\% (58\%–26\%) lower return from publication-informed trading. Post-publication declines are greater for predictors with higher in-sample returns, and returns are higher for portfolios concentrated in stocks with high idiosyncratic risk and low liquidity. Predictor portfolios exhibit post-publication increases in correlations with other published-predictor portfolios. Our findings suggest that investors learn about mispricing from academic publications.},
	language = {en},
	number = {1},
	urldate = {2019-04-18},
	journal = {The Journal of Finance},
	author = {Mclean, R. David and Pontiff, Jeffrey},
	year = {2016},
	pages = {5--32},
	file = {Full Text PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\D5CQCZDG\\Mclean and Pontiff - 2016 - Does Academic Research Destroy Stock Return Predic.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\YLMYDNBH\\jofi.html:text/html}
}

@article{fan_estimation_2017,
	title = {Estimation of high dimensional mean regression in the absence of symmetry and light tail assumptions},
	volume = {79},
	issn = {13697412},
	url = {http://doi.wiley.com/10.1111/rssb.12166},
	doi = {10.1111/rssb.12166},
	abstract = {Data subject to heavy-tailed errors are commonly encountered in various scientiﬁc ﬁelds. To address this problem, procedures based on quantile regression and least absolute deviation regression have been developed in recent years. These methods essentially estimate the conditional median (or quantile) function. They can be very different from the conditional mean functions, especially when distributions are asymmetric and heteroscedastic. How can we efﬁciently estimate the mean regression functions in ultrahigh dimensional settings with existence of only the second moment? To solve this problem, we propose a penalized Huber loss with diverging parameter to reduce biases created by the traditional Huber loss. Such a penalized robust approximate (RA) quadratic loss will be called the RA lasso. In the ultrahigh dimensional setting, where the dimensionality can grow exponentially with the sample size, our results reveal that the RA lasso estimator produces a consistent estimator at the same rate as the optimal rate under the light tail situation. We further study the computational convergence of the RA lasso and show that the composite gradient descent algorithm indeed produces a solution that admits the same optimal rate after sufﬁcient iterations. As a by-product, we also establish the concentration inequality for estimating the population mean when there is only the second moment. We compare the RA lasso with other regularized robust estimators based on quantile regression and least absolute deviation regression. Extensive simulation studies demonstrate the satisfactory ﬁnite sample performance of the RA lasso.},
	language = {en},
	number = {1},
	urldate = {2019-04-21},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Fan, Jianqing and Li, Quefeng and Wang, Yuyan},
	month = jan,
	year = {2017},
	pages = {247--265},
	file = {Fan et al. - 2017 - Estimation of high dimensional mean regression in .pdf:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\H7338YUP\\Fan et al. - 2017 - Estimation of high dimensional mean regression in .pdf:application/pdf}
}

@article{foster_assessing_1997,
	title = {Assessing {Goodness}-of-{Fit} of {Asset} {Pricing} {Models}: {The} {Distribution} of the {Maximal} {R}2},
	volume = {52},
	copyright = {© 1997 the American Finance Association},
	issn = {1540-6261},
	shorttitle = {Assessing {Goodness}-of-{Fit} of {Asset} {Pricing} {Models}},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6261.1997.tb04814.x},
	doi = {10.1111/j.1540-6261.1997.tb04814.x},
	abstract = {The development of asset pricing models that rely on instrumental variables together with the increased availability of easily-accessible economic time-series have renewed interest in predicting security returns. Evaluating the significance of these new research findings, however, is no easy task. Because these asset pricing theory tests are not independent, classical methods of assessing goodness-of-fit are inappropriate. This study investigates the distribution of the maximal R2 when k of m regressors are used to predict security returns. We provide a simple procedure that adjusts critical R2 values to account for selecting variables by searching among potential regressors.},
	language = {en},
	number = {2},
	urldate = {2019-04-26},
	journal = {The Journal of Finance},
	author = {Foster, F. Douglas and Smith, Tom and Whaley, Robert E.},
	year = {1997},
	pages = {591--607},
	file = {Full Text PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\TYSAKP8D\\Foster et al. - 1997 - Assessing Goodness-of-Fit of Asset Pricing Models.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\A3WXMGZA\\j.1540-6261.1997.tb04814.html:text/html}
}

@article{bossaerts_implementing_1999,
	title = {Implementing {Statistical} {Criteria} to {Select} {Return} {Forecasting} {Models}: {What} {Do} {We} {Learn}?},
	volume = {12},
	issn = {0893-9454},
	shorttitle = {Implementing {Statistical} {Criteria} to {Select} {Return} {Forecasting} {Models}},
	url = {https://academic.oup.com/rfs/article/12/2/405/1594881},
	doi = {10.1093/rfs/12.2.405},
	abstract = {Abstract.  Statistical model selection criteria provide an informed choice of the model with best external (i.e., out-of-sample) validity. Therefore they guard},
	language = {en},
	number = {2},
	urldate = {2019-04-26},
	journal = {The Review of Financial Studies},
	author = {Bossaerts, Peter and Hillion, Pierre},
	month = apr,
	year = {1999},
	pages = {405--428},
	file = {Full Text PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\YZ7YAKVP\\Bossaerts and Hillion - 1999 - Implementing Statistical Criteria to Select Return.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\32RJFXHW\\1594881.html:text/html}
}

@article{lo_data-snooping_1990,
	title = {Data-{Snooping} {Biases} in {Tests} of {Financial} {Asset} {Pricing} {Models}},
	volume = {3},
	issn = {0893-9454},
	url = {http://academic.oup.com/rfs/article/3/3/431/1592120},
	doi = {10.1093/rfs/3.3.431},
	abstract = {Abstract.  Tests of financial asset pricing models may yield misleading inferences when properties of the data are used to construct the test statistics. In par},
	language = {en},
	number = {3},
	urldate = {2019-04-26},
	journal = {The Review of Financial Studies},
	author = {Lo, Andrew W. and MacKinlay, A. Craig},
	month = jul,
	year = {1990},
	pages = {431--467},
	file = {Full Text PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\Z9NSWARL\\Lo and MacKinlay - 1990 - Data-Snooping Biases in Tests of Financial Asset P.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\GV4ZFRCJ\\1592120.html:text/html}
}

@techreport{vuolteenaho_understanding_1999,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Understanding the {Aggregate} {Book}-to-{Market} {Ratio}},
	url = {http://papers.ssrn.com/abstract=161911},
	abstract = {In order to connect the stock market valuation level to medium-term cash-flow fundamentals, I develop a dynamic model that links the book-to-market ratio to subsequent profitability, interest rates, and excess stock returns. My approach avoids modeling the potentially unstable dividend process. Consistent with previous research, I find that fluctuating stock market valuations are primarily driven by variation in risk premia. However, interest rate and profitability expectations also play a role in determining market prices. The model generates return and profitability forecasts. Using 1997 data, the model predicts high profitability and low, but not implausible, stock returns over the next decade.},
	language = {en},
	number = {ID 161911},
	urldate = {2019-04-26},
	institution = {Social Science Research Network},
	author = {Vuolteenaho, Tuomo},
	month = apr,
	year = {1999},
	keywords = {SSRN, Tuomo Vuolteenaho, Understanding the Aggregate Book-to-Market Ratio},
	file = {Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\JUR5JALV\\papers.html:text/html}
}

@article{stambaugh_predictive_1999,
	title = {Predictive regressions},
	volume = {54},
	issn = {0304-405X},
	url = {http://www.sciencedirect.com/science/article/pii/S0304405X99000410},
	doi = {10.1016/S0304-405X(99)00041-0},
	abstract = {When a rate of return is regressed on a lagged stochastic regressor, such as a dividend yield, the regression disturbance is correlated with the regressor's innovation. The OLS estimator's finite-sample properties, derived here, can depart substantially from the standard regression setting. Bayesian posterior distributions for the regression parameters are obtained under specifications that differ with respect to (i) prior beliefs about the autocorrelation of the regressor and (ii) whether the initial observation of the regressor is specified as fixed or stochastic. The posteriors differ across such specifications, and asset allocations in the presence of estimation risk exhibit sensitivity to those differences.},
	number = {3},
	urldate = {2019-04-26},
	journal = {Journal of Financial Economics},
	author = {Stambaugh, Robert F.},
	month = dec,
	year = {1999},
	keywords = {Asset allocation, Bayesian analysis, Bias, Estimation risk, Predicting returns, Regression},
	pages = {375--421},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\856CYNHD\\Stambaugh - 1999 - Predictive regressions.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\HEHIP4PV\\S0304405X99000410.html:text/html}
}

@article{ferson_spurious_nodate,
	title = {Spurious {Regressions} in {Financial} {Economics}?},
	abstract = {We study biases associated with regression models in which persistent lagged variables predict stock returns, either linearly or in interaction with contemporaneous values of a market index return. We focus on the issue of spurious regression, related to the classic studies of Yule (1926) and Granger and Newbold (1974). We find that spurious regression is a concern in regressions of stock returns on persistent lagged instruments, especially when the predictable component of returns is large. In regressions where the lagged instruments interact with a market index return, the spurious regression problem is not as severe. Without persistent time-variation in the expected market return and beta, spurious regression bias is not an important issue. However, when a common persistent factor drives expected market returns and betas, spurious regression becomes a concern. Large sample sizes are no defense against the spurious regression bias.},
	language = {en},
	author = {Ferson, Wayne E and Sarkissian, Sergei and Simin, Timothy},
	pages = {36},
	file = {Ferson et al. - Spurious Regressions in Financial Economics.pdf:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\P7Z38IBY\\Ferson et al. - Spurious Regressions in Financial Economics.pdf:application/pdf}
}

@article{lettau_consumption_2001,
	title = {Consumption, {Aggregate} {Wealth}, and {Expected} {Stock} {Returns}},
	volume = {56},
	copyright = {© 2001 the American Finance Association},
	issn = {1540-6261},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/0022-1082.00347},
	doi = {10.1111/0022-1082.00347},
	abstract = {This paper studies the role of fluctuations in the aggregate consumption–wealth ratio for predicting stock returns. Using U.S. quarterly stock market data, we find that these fluctuations in the consumption–wealth ratio are strong predictors of both real stock returns and excess returns over a Treasury bill rate. We also find that this variable is a better forecaster of future returns at short and intermediate horizons than is the dividend yield, the dividend payout ratio, and several other popular forecasting variables. Why should the consumption–wealth ratio forecast asset returns? We show that a wide class of optimal models of consumer behavior imply that the log consumption–aggregate wealth (human capital plus asset holdings) ratio summarizes expected returns on aggregate wealth, or the market portfolio. Although this ratio is not observable, we provide assumptions under which its important predictive components for future asset returns may be expressed in terms of observable variables, namely in terms of consumption, asset holdings and labor income. The framework implies that these variables are cointegrated, and that deviations from this shared trend summarize agents' expectations of future returns on the market portfolio.},
	language = {en},
	number = {3},
	urldate = {2019-04-27},
	journal = {The Journal of Finance},
	author = {Lettau, Martin and Ludvigson, Sydney},
	year = {2001},
	pages = {815--849},
	file = {Full Text PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\LCUSQ59G\\Lettau and Ludvigson - 2001 - Consumption, Aggregate Wealth, and Expected Stock .pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\AHZXNF39\\0022-1082.html:text/html}
}

@article{schwert_anomalies_2003,
	title = {Anomalies and market efficiency},
	volume = {1},
	journal = {Handbook of the Economics of Finance},
	author = {Schwert, G. William},
	year = {2003},
	pages = {939--974},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\UNAUIJEQ\\Schwert - 2003 - Anomalies and market efficiency.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\FBQY69KP\\S1574010203010240.html:text/html}
}

@article{harvey_census_2019,
	title = {A {Census} of the {Factor} {Zoo}},
	abstract = {The rate of factor production in the academic research is out of control. We document over 400 factors published in top journals. Surely, many of them are false. We explore the incentives that lead to factor mining and explore reasons why many of the factors are simply lucky findings. The backtested results published in academic outlets are routinely cited to support commercial products. As a consequence, investors develop exaggerated expectations based on inflated backtested results and are then disappointed by the live trading experience. We provide a comprehensive census of factors published in top academic journals through January 2019. We also offer a link to a Google sheet that has detailed information on each factor, including citation information and download links. Finally, we propose a citizen science project that allows researchers to add to our database both published papers as well as working papers.},
	language = {en},
	journal = {Social Science Research Network},
	author = {Harvey, Campbell R and Liu, Yan},
	month = feb,
	year = {2019},
	pages = {7},
	file = {Harvey and Liu - A Census of the Factor Zoo.pdf:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\H6JNZ66T\\Harvey and Liu - A Census of the Factor Zoo.pdf:application/pdf}
}

@article{harvey__2016,
	title = {… and the {Cross}-{Section} of {Expected} {Returns}},
	volume = {29},
	issn = {0893-9454},
	url = {http://academic.oup.com/rfs/article/29/1/5/1843824},
	doi = {10.1093/rfs/hhv059},
	abstract = {Abstract.  Hundreds of papers and factors attempt to explain the cross-section of expected returns. Given this extensive data mining, it does not make sense to},
	language = {en},
	number = {1},
	urldate = {2019-04-28},
	journal = {The Review of Financial Studies},
	author = {Harvey, Campbell R. and Liu, Yan and Zhu, Heqing},
	month = jan,
	year = {2016},
	pages = {5--68},
	file = {Full Text PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\3VL4LT7A\\Harvey et al. - 2016 - … and the Cross-Section of Expected Returns.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\S6CSX8XK\\1843824.html:text/html}
}

@article{goetzmann_testing_1993,
	title = {Testing the predictive power of dividend yields},
	volume = {48},
	number = {2},
	journal = {The Journal of Finance},
	author = {Goetzmann, William N. and Jorion, Philippe},
	year = {1993},
	pages = {663--679},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\CBG2Q4UP\\Goetzmann and Jorion - 1993 - Testing the predictive power of dividend yields.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\BBGAJ6D4\\j.1540-6261.1993.tb04732.html:text/html}
}

@article{goyal_predicting_2003,
	title = {Predicting the equity premium with dividend ratios},
	volume = {49},
	number = {5},
	journal = {Management Science},
	author = {Goyal, Amit and Welch, Ivo},
	year = {2003},
	pages = {639--654},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\BK5MAS9C\\Goyal and Welch - 2003 - Predicting the equity premium with dividend ratios.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\K28KRSA6\\mnsc.49.5.639.html:text/html}
}

@article{campbell_stock_1988,
	title = {Stock prices, earnings, and expected dividends},
	volume = {43},
	number = {3},
	journal = {The Journal of Finance},
	author = {Campbell, John Y. and Shiller, Robert J.},
	year = {1988},
	pages = {661--676},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\YQMF4C3H\\Campbell and Shiller - 1988 - Stock prices, earnings, and expected dividends.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\8UBA27ZW\\j.1540-6261.1988.tb04598.html:text/html}
}

@article{campbell_dividend-price_1988,
	title = {The dividend-price ratio and expectations of future dividends and discount factors},
	volume = {1},
	number = {3},
	journal = {The Review of Financial Studies},
	author = {Campbell, John Y. and Shiller, Robert J.},
	year = {1988},
	pages = {195--228},
	file = {Full Text:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\M9A32NJB\\Campbell and Shiller - 1988 - The dividend-price ratio and expectations of futur.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\TL2BTV9A\\1580239.html:text/html}
}

@article{welch_comprehensive_2008,
	title = {A {Comprehensive} {Look} at {The} {Empirical} {Performance} of {Equity} {Premium} {Prediction}},
	volume = {21},
	issn = {0893-9454, 1465-7368},
	url = {https://academic.oup.com/rfs/article-lookup/doi/10.1093/rfs/hhm014},
	doi = {10.1093/rfs/hhm014},
	language = {en},
	number = {4},
	urldate = {2019-05-11},
	journal = {Review of Financial Studies},
	author = {Welch, Ivo and Goyal, Amit},
	month = jul,
	year = {2008},
	pages = {1455--1508},
	file = {Welch and Goyal - 2008 - A Comprehensive Look at The Empirical Performance .pdf:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\K35JA9MS\\Welch and Goyal - 2008 - A Comprehensive Look at The Empirical Performance .pdf:application/pdf}
}

@article{cochrane_presidential_2011,
	title = {Presidential {Address}: {Discount} {Rates}},
	volume = {66},
	issn = {1540-6261},
	shorttitle = {Presidential {Address}},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6261.2011.01671.x},
	doi = {10.1111/j.1540-6261.2011.01671.x},
	language = {en},
	number = {4},
	urldate = {2019-05-11},
	journal = {The Journal of Finance},
	author = {Cochrane, John H.},
	month = aug,
	year = {2011},
	pages = {1047--1108},
	file = {Full Text PDF:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\38GQ465K\\Cochrane - 2011 - Presidential Address Discount Rates.pdf:application/pdf;Snapshot:C\:\\Users\\Zeyu Zhong\\Zotero\\storage\\KH3FSUC4\\j.1540-6261.2011.01671.html:text/html}
}