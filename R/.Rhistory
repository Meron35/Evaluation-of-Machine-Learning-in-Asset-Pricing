forecast_resids = 0,
model = 0,
hyperparameters = 0,
variable_importance = 0)
#Model
model <- ELN_model_grid[[best_model_params$list_index]]$model
#ELN_stats[[set]]$model <- model
#Hyperparameters
ELN_stats[[set]]$hyperparameters <- best_model_params
#Loss Stats Dataframe
#Train
train_predict <- predict(model, train_x, alpha = best_model_params$alpha, lambda = best_model_params$lambda)
ELN_stats[[set]]$loss_stats$train_MAE <- mae(train_y, train_predict)
ELN_stats[[set]]$loss_stats$train_MSE <- mse(train_y, train_predict)
ELN_stats[[set]]$loss_stats$train_RMSE <- rmse(train_y, train_predict)
ELN_stats[[set]]$loss_stats$train_RSquare <- (1 - sse(train_y, train_predict) / sum((train_y - mean(train_y))^2))
#Validation
valid_predict <- predict(model, validation_x, alpha = best_model_params$alpha, lambda = best_model_params$lambda)
ELN_stats[[set]]$loss_stats$validation_MAE <- mae(validation_y, valid_predict)
ELN_stats[[set]]$loss_stats$validation_MSE <- mse(validation_y, valid_predict)
ELN_stats[[set]]$loss_stats$validation_RMSE <- rmse(validation_y, valid_predict)
ELN_stats[[set]]$loss_stats$validation_RSquare <- (1 - sse(validation_y, valid_predict) / sum((validation_y - mean(validation_y))^2))
#Test
test_predict <- predict(model, test_x, alpha = best_model_params$alpha, lambda = best_model_params$lambda)
ELN_stats[[set]]$loss_stats$test_MAE <- mae(test_y, test_predict)
ELN_stats[[set]]$loss_stats$test_MSE <- mse(test_y, test_predict)
ELN_stats[[set]]$loss_stats$test_RMSE <- rmse(test_y, test_predict)
ELN_stats[[set]]$loss_stats$test_RSquare <- (1 - sse(test_y, test_predict) / sum((test_y - mean(test_y))^2))
#Forecast residuals
ELN_stats[[set]]$forecast_resids <- eln_ave_forecast_resids(eln_model = model, test,
# Hyperparameters
alpha = best_model_params$alpha,
lambda = best_model_params$lambda)
#Variable Importance
ELN_stats[[set]]$variable_importance <- ELN_variable_importance(test, model, alpha = best_model_params$alpha, lambda = best_model_params$lambda)
}
return(ELN_stats)
}
LM_fit <- function(pooled_panel, timeSlices, loss_function, f) {
#Initialize Loss Function Statistics
LM_stats <- rep(list(0), 3)
for (set in 1:3) {
LM_stats[[set]] <- list(loss_stats = data.frame(train_MAE = 0, train_MSE = 0, train_RMSE = 0, train_RSquare = 0,
validation_MAE = 0, validation_MSE = 0, validation_RMSE = 0, validation_RSquare = 0,
test_MAE = 0, test_MSE = 0, test_RMSE = 0, test_RSquare = 0),
#Other useful things
forecast_resids = 0,
model = 0,
#Variable Importance
variable_importance = 0)
#Load Training, validation and test sets
train <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$train)
validation <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$validation)
test <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$test)
#Train Model on training set
# Set model = FALSE so that it won't save a copy of the training data in the model object
# Doen for memory efficiency
#MSE case
if (loss_function == "mse") {
lm <- lm(f, data = train, model = FALSE, fitted = FALSE, y = FALSE)
} else {
# Use pfn as method here for much faster computation
lm <- rq(f, data = train, tau = 0.5, method = "pfn")
}
#LM_stats[[set]]$model <- lm
#No Tuning Needed
#Statistics
#Training Set
train_predict <- predict(lm, newdata = train)
LM_stats[[set]]$loss_stats$train_MAE <- mae(train$rt, train_predict)
LM_stats[[set]]$loss_stats$train_MSE <- mse(train$rt, train_predict)
LM_stats[[set]]$loss_stats$train_RMSE <- rmse(train$rt, train_predict)
LM_stats[[set]]$loss_stats$train_RSquare <- R2(train_predict, train$rt, form = "traditional")
#Validation Set Statistics
validation_predict <- predict(lm, newdata = validation)
LM_stats[[set]]$loss_stats$validation_MAE <- mae(validation$rt, validation_predict)
LM_stats[[set]]$loss_stats$validation_MSE <- mse(validation$rt, validation_predict)
LM_stats[[set]]$loss_stats$validation_RMSE <- rmse(validation$rt, validation_predict)
LM_stats[[set]]$loss_stats$validation_RSquare <- R2(validation_predict, validation$rt, form = "traditional")
#Test Set Statistics
test_predict <- predict(lm, newdata = test)
LM_stats[[set]]$loss_stats$test_MAE <- mae(test$rt, test_predict)
LM_stats[[set]]$loss_stats$test_MSE <- mse(test$rt, test_predict)
LM_stats[[set]]$loss_stats$test_RMSE <- rmse(test$rt, test_predict)
LM_stats[[set]]$loss_stats$test_RSquare <- R2(test_predict, test$rt, form = "traditional")
#Forecast Residuals
LM_stats[[set]]$forecast_resids <- lm_ave_forecast_resids(lm_model = lm, test = test)
#Variable Importance
LM_stats[[set]]$variable_importance <- LM_variable_importance(test, lm)
}
return(LM_stats)
}
RF_fit_stats <- function(pooled_panel, RF_grid, timeSlices, loss_function, f) {
#Initialize
RF_stats <- rep(list(0), 3)
#Load training, validation and test sets
for (set in 1:3) {
RF_stats[[set]] <- list(loss_stats = data.frame(train_MAE = 0, train_MSE = 0, train_RMSE = 0, train_RSquare = 0,
validation_MAE = 0, validation_MSE = 0, validation_RMSE = 0, validation_RSquare = 0,
test_MAE = 0, test_MSE = 0, test_RMSE = 0, test_RSquare = 0),
#Other useful things
forecast_resids = 0,
model = 0,
hyperparameters = 0,
variable_importance = 0)
train <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$train)
validation <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$validation)
test <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$test)
#Fit on training Set over grid of hyperparameters
model_grid <- RF_fit_model_grid(f, train, validation, RF_grid, loss_function)
#Get the best hyperparameters
best_model_params <- get_RF_best_tune(model_grid)
RF_stats[[set]]$hyperparameters <- best_model_params
#Compute the optimal model
if (loss_function == "mse") {
model <- rfsrc(f, train,
#Hyperparameters
ntree = best_model_params$ntree,
mtry = best_model_params$mtry,
nodesize = best_model_params$nodesize,
splitrule = "mse",
bootstrap = "by.root", samptype = "swr"
)
} else {
model <- rfsrc(f, train,
#Hyperparameters
ntree = best_model_params$ntree,
mtry = best_model_params$mtry,
nodesize = best_model_params$nodesize,
splitrule = "quantile.regr",
prob = 0.5,
bootstrap = "by.root", samptype = "swr"
)
}
#RF_stats[[set]]$model <- model
#Train
train_predict <- predict(model, train)$predicted
RF_stats[[set]]$loss_stats$train_MAE <- mae(train$rt, train_predict)
RF_stats[[set]]$loss_stats$train_MSE <- mse(train$rt, train_predict)
RF_stats[[set]]$loss_stats$train_RMSE <- rmse(train$rt, train_predict)
RF_stats[[set]]$loss_stats$train_RSquare <- (1 - sse(train$rt, train_predict) / sum((train$rt - mean(train$rt))^2))
#Validation
valid_predict <- predict(model, newdata = validation)$predicted
RF_stats[[set]]$loss_stats$validation_MAE <- mae(validation$rt, valid_predict)
RF_stats[[set]]$loss_stats$validation_MSE <- mse(validation$rt, valid_predict)
RF_stats[[set]]$loss_stats$validation_RMSE <- rmse(validation$rt, valid_predict)
RF_stats[[set]]$loss_stats$validation_RSquare <- (1 - sse(validation$rt, valid_predict) / sum((validation$rt - mean(validation$rt))^2))
#Test
test_predict <- predict(model, newdata = test)$predicted
RF_stats[[set]]$loss_stats$test_MAE <- mae(test$rt, test_predict)
RF_stats[[set]]$loss_stats$test_MSE <- mse(test$rt, test_predict)
RF_stats[[set]]$loss_stats$test_RMSE <- rmse(test$rt, test_predict)
RF_stats[[set]]$loss_stats$test_RSquare <- (1 - sse(test$rt, test_predict) / sum((test$rt - mean(test$rt))^2))
#Forecast residuals
RF_stats[[set]]$forecast_resids <- rf_ave_forecast_resids(rf_model = model, test = test)
#Variable Importance
RF_stats[[set]]$variable_importance <- RF_variable_importance(test, model)
}
return(RF_stats)
}
View(LM_fit)
fit_all_models <- function(dataset_list, batch_process_range,
# Logical arguments specifying which models you want to fit
# This is useful if you don't want to fit some of the most intensive methods such as RF and Neural Networks
LM, ELN, RF, NNet) {
# Initialize List
simulation_results_list <- rep(list(0), length(batch_process_range))
for (batch in (batch_process_range)) {
simulation_results_list[[batch]] <- list(
# Panel Statistics
Dataset_stats = 0,
# Models
LM_MSE = 0, LM_MAE = 0,
ELN_MSE = 0, ELN_MAE = 0,
RF_MSE = 0, RF_MAE = 0,
# Neural Networks
NN1_MSE = 0, NN1_MAE = 0,
NN2_MSE = 0, NN2_MAE = 0,
NN3_MSE = 0, NN3_MAE = 0,
NN4_MSE = 0, NN4_MAE = 0,
NN5_MSE = 0, NN5_MAE = 0
)
# Load Dataset
pooled_panel <- dataset_list[[batch]]$panel
simulation_results_list[[batch]]$Dataset_stats <- dataset_list[[batch]]$statistics
simulation_results_list[[batch]]$returns <- pooled_panel$rt
timeSlices <- customTimeSlices(start = 2, initialWindow = 84, horizon = 12, validation_size = 36, test_size = 36, set_no = 3)
f <- panel_formula(pooled_panel)
if (LM == 1) {
# Linear Models
simulation_results_list[[batch]]$LM_MSE <- LM_fit(pooled_panel, timeSlices, "mse", f)
simulation_results_list[[batch]]$LM_MAE <- LM_fit(pooled_panel, timeSlices, "mae", f)
}
if (ELN == 1) {
# Penalized Linear Models
alpha_grid <- seq(0, 1, 0.01)
simulation_results_list[[batch]]$ELN_MAE <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mae")
simulation_results_list[[batch]]$ELN_MSE <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mse")
}
if (RF == 1) {
# Random Forests
RF_grid <- expand.grid(
#ntree usually isn't tuned. Just set to max of computationally feasible
ntree = 100,
mtry = seq(20, round(ncol(pooled_panel[4:ncol(pooled_panel)])/3), 20)
# nodesize = seq(2, 14, 2)
# nodedepth recommended not to be changed
#nodedepth = 1
)
simulation_results_list[[batch]]$RF_MSE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mse", f)
simulation_results_list[[batch]]$RF_MAE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mae", f)
}
if (NNet == 1) {
# Neural Networks
# Commented for now because honours lab computers don't have keras/tensorflow
batch_size <- 32
patience <- 20
simulation_results_list[[batch]]$NN1_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 1, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN1_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 1, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN2_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 2, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN2_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 2, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN3_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 3, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN3_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 3, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN4_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 4, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN4_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 4, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN5_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 5, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN5_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 5, "mae", batch_size = batch_size, patience = patience)
}
}
simulation_results_list
}
g1_A1_sv_0.01_results <- fit_all_models(g1_A1_sv_0.01, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)
fit_all_models <- function(dataset_list, batch_process_range,
# Logical arguments specifying which models you want to fit
# This is useful if you don't want to fit some of the most intensive methods such as RF and Neural Networks
LM, ELN, RF, NNet) {
# Initialize List
simulation_results_list <- rep(list(0), length(batch_process_range))
for (batch in (batch_process_range)) {
simulation_results_list[[batch]] <- list(
# Panel Statistics
Dataset_stats = 0,
# Models
LM_MSE = 0, LM_MAE = 0,
ELN_MSE = 0, ELN_MAE = 0,
RF_MSE = 0, RF_MAE = 0,
# Neural Networks
NN1_MSE = 0, NN1_MAE = 0,
NN2_MSE = 0, NN2_MAE = 0,
NN3_MSE = 0, NN3_MAE = 0,
NN4_MSE = 0, NN4_MAE = 0,
NN5_MSE = 0, NN5_MAE = 0
)
# Load Dataset
pooled_panel <- dataset_list[[batch]]$panel
simulation_results_list[[batch]]$Dataset_stats <- dataset_list[[batch]]$statistics
simulation_results_list[[batch]]$returns <- pooled_panel$rt
timeSlices <- customTimeSlices(start = 2, initialWindow = 84, horizon = 12, validation_size = 36, test_size = 36, set_no = 3)
f <- panel_formula(pooled_panel)
if (LM == 1) {
# Linear Models
simulation_results_list[[batch]]$LM_MSE <- LM_fit(pooled_panel, timeSlices, "mse", f)
simulation_results_list[[batch]]$LM_MAE <- LM_fit(pooled_panel, timeSlices, "mae", f)
}
if (ELN == 1) {
# Penalized Linear Models
alpha_grid <- seq(0, 1, 0.01)
simulation_results_list[[batch]]$ELN_MAE <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mae")
simulation_results_list[[batch]]$ELN_MSE <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mse")
}
if (RF == 1) {
# Random Forests
RF_grid <- expand.grid(
#ntree usually isn't tuned. Just set to max of computationally feasible
ntree = 50,
mtry = seq(10, round(ncol(pooled_panel[4:ncol(pooled_panel)])/6), 10)
# nodesize = seq(2, 14, 2)
# nodedepth recommended not to be changed
#nodedepth = 1
)
simulation_results_list[[batch]]$RF_MSE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mse", f)
simulation_results_list[[batch]]$RF_MAE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mae", f)
}
if (NNet == 1) {
# Neural Networks
# Commented for now because honours lab computers don't have keras/tensorflow
batch_size <- 32
patience <- 20
simulation_results_list[[batch]]$NN1_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 1, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN1_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 1, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN2_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 2, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN2_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 2, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN3_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 3, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN3_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 3, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN4_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 4, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN4_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 4, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN5_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 5, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN5_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 5, "mae", batch_size = batch_size, patience = patience)
}
}
simulation_results_list
}
LM_fit <- function(pooled_panel, timeSlices, loss_function, f) {
#Initialize Loss Function Statistics
LM_stats <- rep(list(0), 3)
for (set in 1:3) {
LM_stats[[set]] <- list(loss_stats = data.frame(train_MAE = 0, train_MSE = 0, train_RMSE = 0, train_RSquare = 0,
validation_MAE = 0, validation_MSE = 0, validation_RMSE = 0, validation_RSquare = 0,
test_MAE = 0, test_MSE = 0, test_RMSE = 0, test_RSquare = 0),
#Other useful things
forecast_resids = 0,
model = 0,
#Variable Importance
variable_importance = 0)
#Load Training, validation and test sets
train <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$train)
validation <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$validation)
test <- pooled_panel %>%
filter(time %in% timeSlices[[set]]$test)
#Train Model on training set
# Set model = FALSE so that it won't save a copy of the training data in the model object
# Doen for memory efficiency
#MSE case
if (loss_function == "mse") {
lm <- lm(f, data = train, model = FALSE, y = FALSE)
} else {
# Use pfn as method here for much faster computation
lm <- rq(f, data = train, tau = 0.5, method = "pfn")
}
#LM_stats[[set]]$model <- lm
#No Tuning Needed
#Statistics
#Training Set
train_predict <- predict(lm, newdata = train)
LM_stats[[set]]$loss_stats$train_MAE <- mae(train$rt, train_predict)
LM_stats[[set]]$loss_stats$train_MSE <- mse(train$rt, train_predict)
LM_stats[[set]]$loss_stats$train_RMSE <- rmse(train$rt, train_predict)
LM_stats[[set]]$loss_stats$train_RSquare <- R2(train_predict, train$rt, form = "traditional")
#Validation Set Statistics
validation_predict <- predict(lm, newdata = validation)
LM_stats[[set]]$loss_stats$validation_MAE <- mae(validation$rt, validation_predict)
LM_stats[[set]]$loss_stats$validation_MSE <- mse(validation$rt, validation_predict)
LM_stats[[set]]$loss_stats$validation_RMSE <- rmse(validation$rt, validation_predict)
LM_stats[[set]]$loss_stats$validation_RSquare <- R2(validation_predict, validation$rt, form = "traditional")
#Test Set Statistics
test_predict <- predict(lm, newdata = test)
LM_stats[[set]]$loss_stats$test_MAE <- mae(test$rt, test_predict)
LM_stats[[set]]$loss_stats$test_MSE <- mse(test$rt, test_predict)
LM_stats[[set]]$loss_stats$test_RMSE <- rmse(test$rt, test_predict)
LM_stats[[set]]$loss_stats$test_RSquare <- R2(test_predict, test$rt, form = "traditional")
#Forecast Residuals
LM_stats[[set]]$forecast_resids <- lm_ave_forecast_resids(lm_model = lm, test = test)
#Variable Importance
LM_stats[[set]]$variable_importance <- LM_variable_importance(test, lm)
}
return(LM_stats)
}
batch_process_range <- c(1:10)
g1_A1_sv_0.01_results <- fit_all_models(g1_A1_sv_0.01, batch_process_range, LM = 1, ELN = 1, RF = 1, NNet = 0)
fit_all_models <- function(dataset_list, batch_process_range,
# Logical arguments specifying which models you want to fit
# This is useful if you don't want to fit some of the most intensive methods such as RF and Neural Networks
LM, ELN, RF, NNet) {
# Initialize List
simulation_results_list <- rep(list(0), length(batch_process_range))
for (batch in (batch_process_range)) {
simulation_results_list[[batch]] <- list(
# Panel Statistics
Dataset_stats = 0,
# Models
LM_MSE = 0, LM_MAE = 0,
ELN_MSE = 0, ELN_MAE = 0,
RF_MSE = 0, RF_MAE = 0,
# Neural Networks
NN1_MSE = 0, NN1_MAE = 0,
NN2_MSE = 0, NN2_MAE = 0,
NN3_MSE = 0, NN3_MAE = 0,
NN4_MSE = 0, NN4_MAE = 0,
NN5_MSE = 0, NN5_MAE = 0
)
# Load Dataset
pooled_panel <- dataset_list[[batch]]$panel
simulation_results_list[[batch]]$Dataset_stats <- dataset_list[[batch]]$statistics
simulation_results_list[[batch]]$returns <- pooled_panel$rt
timeSlices <- customTimeSlices(start = 2, initialWindow = 84, horizon = 12, validation_size = 36, test_size = 36, set_no = 3)
f <- panel_formula(pooled_panel)
if (LM == 1) {
# Linear Models
simulation_results_list[[batch]]$LM_MSE <- LM_fit(pooled_panel, timeSlices, "mse", f)
simulation_results_list[[batch]]$LM_MAE <- LM_fit(pooled_panel, timeSlices, "mae", f)
}
if (ELN == 1) {
# Penalized Linear Models
alpha_grid <- seq(0, 1, 0.01)
simulation_results_list[[batch]]$ELN_MAE <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mae")
simulation_results_list[[batch]]$ELN_MSE <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mse")
}
if (RF == 1) {
# Random Forests
RF_grid <- expand.grid(
#ntree usually isn't tuned. Just set to max of computationally feasible
ntree = 30,
mtry = seq(10, round(sqrt(ncol(pooled_panel[4:ncol(pooled_panel)])), 10))
# nodesize = seq(2, 14, 2)
# nodedepth recommended not to be changed
#nodedepth = 1
)
simulation_results_list[[batch]]$RF_MSE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mse", f)
simulation_results_list[[batch]]$RF_MAE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mae", f)
}
if (NNet == 1) {
# Neural Networks
# Commented for now because honours lab computers don't have keras/tensorflow
batch_size <- 32
patience <- 20
simulation_results_list[[batch]]$NN1_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 1, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN1_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 1, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN2_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 2, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN2_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 2, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN3_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 3, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN3_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 3, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN4_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 4, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN4_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 4, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN5_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 5, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN5_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 5, "mae", batch_size = batch_size, patience = patience)
}
}
simulation_results_list
}
batch_process_range <- c(1:10)
g1_A1_sv_0.01_results <- fit_all_models(g1_A1_sv_0.01, batch_process_range, LM = 1, ELN = 1, RF = 0, NNet = 0)
timeSlices <- customTimeSlices(start = 2, initialWindow = 84, horizon = 12, validation_size = 60, test_size = 12, set_no = 3)
View(timeSlices)
fit_all_models <- function(dataset_list, batch_process_range,
# Logical arguments specifying which models you want to fit
# This is useful if you don't want to fit some of the most intensive methods such as RF and Neural Networks
LM, ELN, RF, NNet) {
# Initialize List
simulation_results_list <- rep(list(0), length(batch_process_range))
for (batch in (batch_process_range)) {
simulation_results_list[[batch]] <- list(
# Panel Statistics
Dataset_stats = 0,
# Models
LM_MSE = 0, LM_MAE = 0,
ELN_MSE = 0, ELN_MAE = 0,
RF_MSE = 0, RF_MAE = 0,
# Neural Networks
NN1_MSE = 0, NN1_MAE = 0,
NN2_MSE = 0, NN2_MAE = 0,
NN3_MSE = 0, NN3_MAE = 0,
NN4_MSE = 0, NN4_MAE = 0,
NN5_MSE = 0, NN5_MAE = 0
)
# Load Dataset
pooled_panel <- dataset_list[[batch]]$panel
simulation_results_list[[batch]]$Dataset_stats <- dataset_list[[batch]]$statistics
simulation_results_list[[batch]]$returns <- pooled_panel$rt
timeSlices <- customTimeSlices(start = 2, initialWindow = 84, horizon = 12, validation_size = 60, test_size = 12, set_no = 3)
f <- panel_formula(pooled_panel)
if (LM == 1) {
# Linear Models
simulation_results_list[[batch]]$LM_MSE <- LM_fit(pooled_panel, timeSlices, "mse", f)
simulation_results_list[[batch]]$LM_MAE <- LM_fit(pooled_panel, timeSlices, "mae", f)
}
if (ELN == 1) {
# Penalized Linear Models
alpha_grid <- seq(0, 1, 0.01)
simulation_results_list[[batch]]$ELN_MAE <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mae")
simulation_results_list[[batch]]$ELN_MSE <- ELN_fit_stats(alpha_grid, nlamb = 100, timeSlices, pooled_panel, loss_function = "mse")
}
if (RF == 1) {
# Random Forests
RF_grid <- expand.grid(
#ntree usually isn't tuned. Just set to max of computationally feasible
ntree = 30,
mtry = seq(10, round(sqrt(ncol(pooled_panel[4:ncol(pooled_panel)])), 10))
# nodesize = seq(2, 14, 2)
# nodedepth recommended not to be changed
#nodedepth = 1
)
simulation_results_list[[batch]]$RF_MSE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mse", f)
simulation_results_list[[batch]]$RF_MAE <- RF_fit_stats(pooled_panel, RF_grid, timeSlices, "mae", f)
}
if (NNet == 1) {
# Neural Networks
# Commented for now because honours lab computers don't have keras/tensorflow
batch_size <- 32
patience <- 20
simulation_results_list[[batch]]$NN1_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 1, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN1_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 1, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN2_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 2, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN2_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 2, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN3_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 3, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN3_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 3, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN4_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 4, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN4_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 4, "mae", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN5_MSE <- NNet_fit_stats(pooled_panel, timeSlices, 5, "mse", batch_size = batch_size, patience = patience)
simulation_results_list[[batch]]$NN5_MAE <- NNet_fit_stats(pooled_panel, timeSlices, 5, "mae", batch_size = batch_size, patience = patience)
}
}
simulation_results_list
}
g1_A1_sv_0.01_results <- fit_all_models(g1_A1_sv_0.01, batch_process_range, LM = 1, ELN = 1, RF = 0, NNet = 0)
