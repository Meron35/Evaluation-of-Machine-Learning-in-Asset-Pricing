\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{vuolteenaho_understanding_1999}
\citation{lettau_consumption_2001}
\citation{schwert_anomalies_2003}
\citation{hsu_finding_2014}
\citation{harvey__2016}
\citation{harvey_census_2019}
\citation{kozak_shrinking_2017}
\citation{rapach_forecasting_2013}
\citation{freyberger_dissecting_2017}
\citation{gu_empirical_2018}
\citation{hsu_finding_2014}
\citation{feng_deep_2018}
\citation{gu_empirical_2018}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Topic}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Background Literature and Motivations}{1}{subsection.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methodology}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Overall Model Design}{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Sample Splitting}{2}{subsection.2.2}}
\citation{huber_robust_1992}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Loss Function}{3}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Mean Absolute Error}{3}{subsubsection.2.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Mean Squared Error and Root Mean Squared Error}{3}{subsubsection.2.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Huber Loss}{3}{subsubsection.2.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Linear Model}{3}{subsection.2.4}}
\citation{zou_regularization_2005}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of MAE, MSE and Huber Loss when $\xi = 1$}}{4}{figure.1}}
\newlabel{fig:loss_functions}{{1}{4}{Illustration of MAE, MSE and Huber Loss when $\xi = 1$}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Penalized Linear Model}{4}{subsection.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Classification and Regression Trees}{5}{subsection.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Random Forests}{5}{subsection.2.7}}
\citation{masters_practical_1993}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Neural Network 5 (most complex considered)}}{6}{figure.2}}
\newlabel{Neural_Network}{{2}{6}{Neural Network 5 (most complex considered)}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Neural Networks}{6}{subsection.2.8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.1}Introduction}{6}{subsubsection.2.8.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2}Notation}{6}{subsubsection.2.8.2}}
\citation{lecun_deep_2015}
\citation{ramachandran_searching_2017}
\citation{choromanska_loss_2014}
\citation{kingma_adam:_2014}
\citation{ioffe_batch_2015}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.3}Activation Function}{7}{subsubsection.2.8.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.4}Computation}{7}{subsubsection.2.8.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.5}Batch Normalization}{7}{subsubsection.2.8.5}}
\citation{hansen_neural_1990}
\citation{choromanska_loss_2014}
\citation{gu_empirical_2018}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.6}Initialization}{8}{subsubsection.2.8.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Simulation Design}{8}{subsection.2.9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.1}Overall Design}{8}{subsubsection.2.9.1}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} justify properly}{8}{section*.1}}
\pgfsyspdfmark {pgfid4}{4736286}{34658360}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} double check conformability of everything, make sure that the errors are corrected}{8}{section*.2}}
\pgfsyspdfmark {pgfid9}{4736286}{34658360}
\pgfsyspdfmark {pgfid7}{36994278}{34670648}
\pgfsyspdfmark {pgfid8}{38845670}{34446734}
\pgfsyspdfmark {pgfid12}{36994278}{32649958}
\pgfsyspdfmark {pgfid13}{38845670}{32426044}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} still not too sure with possible sigma squared term, double check}{8}{section*.3}}
\pgfsyspdfmark {pgfid14}{5719326}{27501812}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} double check SV parameters and cite them}{8}{section*.4}}
\pgfsyspdfmark {pgfid19}{5719326}{27501812}
\pgfsyspdfmark {pgfid17}{36994278}{27514100}
\pgfsyspdfmark {pgfid18}{38845670}{27290186}
\pgfsyspdfmark {pgfid22}{36994278}{23904166}
\pgfsyspdfmark {pgfid23}{38845670}{23680252}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.2}Simulating Characteristics}{8}{subsubsection.2.9.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.3}Simulating Macroeconomic Series}{9}{subsubsection.2.9.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.4}Simulating Return Series}{9}{subsubsection.2.9.4}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} explain what each function is doing}{9}{section*.5}}
\pgfsyspdfmark {pgfid24}{5719326}{8625354}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} these thetas are not tuned yet, update them}{9}{section*.6}}
\pgfsyspdfmark {pgfid29}{5719326}{8625354}
\pgfsyspdfmark {pgfid27}{36994278}{8637642}
\pgfsyspdfmark {pgfid28}{38845670}{8413728}
\pgfsyspdfmark {pgfid32}{36994278}{5848726}
\pgfsyspdfmark {pgfid33}{38845670}{5624812}
\citation{diebold_comparing_2002}
\citation{harvey_testing_1997}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.5}Sample Splitting}{10}{subsubsection.2.9.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10}Model Evaluation}{10}{subsection.2.10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.10.1}R Squared}{10}{subsubsection.2.10.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.10.2}Diebold-Mariano Test}{10}{subsubsection.2.10.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11}Variable Importance}{11}{subsection.2.11}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} Pending}{11}{section*.7}}
\pgfsyspdfmark {pgfid34}{4736286}{48755354}
\pgfsyspdfmark {pgfid37}{36994278}{48767642}
\pgfsyspdfmark {pgfid38}{38845670}{48543728}
\@writefile{toc}{\contentsline {section}{\numberline {3}Study}{11}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data}{11}{subsection.3.1}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} Pending}{11}{section*.8}}
\pgfsyspdfmark {pgfid39}{4736286}{38857403}
\pgfsyspdfmark {pgfid42}{36994278}{38869691}
\pgfsyspdfmark {pgfid43}{38845670}{38645777}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Model}{11}{subsection.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Outline of Results Thus Far}{11}{section.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Concluding Remarks and Other Considerations}{11}{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Research Timeline}{11}{section.6}}
\citation{breiman_classification_2017}
\citation{breiman_random_2001}
\@writefile{toc}{\contentsline {section}{\numberline {7}Appendix}{13}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Algorithms}{13}{subsection.7.1}}
\newlabel{Algorithms}{{7.1}{13}{Algorithms}{subsection.7.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Penalized Linear}{13}{subsubsection.7.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Classification and Regression Trees}{13}{subsubsection.7.1.2}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Classification and Regression Tree}}{13}{algocf.1}}
\citation{kingma_adam:_2014}
\citation{ioffe_batch_2015}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.3}Random Forest}{14}{subsubsection.7.1.3}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Random Forest}}{14}{algocf.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.4}Neural Networks}{14}{subsubsection.7.1.4}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Early stopping via validation}}{14}{algocf.3}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Batch Normalization for one activation over one batch}}{14}{algocf.4}}
\bibstyle{jfe}
\bibdata{Bibliography}
\bibcite{breiman_random_2001}{{1}{2001}{{Breiman}}{{}}}
\bibcite{breiman_classification_2017}{{2}{2017}{{Breiman}}{{}}}
\bibcite{choromanska_loss_2014}{{3}{2014}{{Choromanska et~al.}}{{Choromanska, Henaff, Mathieu, Arous, and LeCun}}}
\bibcite{diebold_comparing_2002}{{4}{2002}{{Diebold and Mariano}}{{}}}
\bibcite{feng_deep_2018}{{5}{2018}{{Feng et~al.}}{{Feng, He, and Polson}}}
\bibcite{freyberger_dissecting_2017}{{6}{2017}{{Freyberger et~al.}}{{Freyberger, Neuhierl, and Weber}}}
\bibcite{gu_empirical_2018}{{7}{2018}{{Gu et~al.}}{{Gu, Kelly, and Xiu}}}
\bibcite{hansen_neural_1990}{{8}{1990}{{Hansen and Salamon}}{{}}}
\bibcite{harvey_census_2019}{{9}{2019}{{Harvey and Liu}}{{}}}
\bibcite{harvey__2016}{{10}{2016}{{Harvey et~al.}}{{Harvey, Liu, and Zhu}}}
\bibcite{harvey_testing_1997}{{11}{1997}{{Harvey et~al.}}{{Harvey, Leybourne, and Newbold}}}
\bibcite{hsu_finding_2014}{{12}{2014}{{Hsu and Kalesnik}}{{}}}
\bibcite{huber_robust_1992}{{13}{1992}{{Huber}}{{}}}
\bibcite{ioffe_batch_2015}{{14}{2015}{{Ioffe and Szegedy}}{{}}}
\bibcite{kingma_adam:_2014}{{15}{2014}{{Kingma and Ba}}{{}}}
\bibcite{kozak_shrinking_2017}{{16}{2017}{{Kozak et~al.}}{{Kozak, Nagel, and Santosh}}}
\bibcite{lecun_deep_2015}{{17}{2015}{{Lecun et~al.}}{{Lecun, Bengio, and Hinton}}}
\bibcite{lettau_consumption_2001}{{18}{2001}{{Lettau and Ludvigson}}{{}}}
\bibcite{masters_practical_1993}{{19}{1993}{{Masters}}{{}}}
\bibcite{ramachandran_searching_2017}{{20}{2017}{{Ramachandran et~al.}}{{Ramachandran, Zoph, and Le}}}
\bibcite{rapach_forecasting_2013}{{21}{2013}{{Rapach and Zhou}}{{}}}
\bibcite{schwert_anomalies_2003}{{22}{2003}{{Schwert}}{{}}}
\bibcite{vuolteenaho_understanding_1999}{{23}{1999}{{Vuolteenaho}}{{}}}
\bibcite{zou_regularization_2005}{{24}{2005}{{Zou and Hastie}}{{}}}
