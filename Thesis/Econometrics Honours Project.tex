%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Preamble
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\PassOptionsToPackage{usenames, dvipsnames}{xcolor}

\documentclass[a4paper, table]{article}
\usepackage[english]{babel}
\usepackage[margin=1in]{geometry}
\usepackage[ruled, vlined]{algorithm2e}

\usepackage{amsfonts}
\usepackage{setspace,graphicx,epstopdf,amsmath}
\usepackage{marginnote, datetime, url, enumitem, subfigure}

%Journal Style
%JFE looks nice, JF looks awful
	\usepackage{amsthm}
	\usepackage{jfe}

%Bibliography Stuff
	%Use natbib even though it's old because it's compliant with journal styles
	%Actual bibliography style etc are specified where you actually want it
	\usepackage{natbib}

%Fluff
	\linespread{1.3}

%Neural Network Packages
	\usepackage{neuralnetwork}
	\usepackage{xpatch}
	\makeatletter
	% \linklayers have \nn@lastnode instead of \lastnode,
	% patch it to replace the former with the latter, and similar for thisnode
	\xpatchcmd{\linklayers}{\nn@lastnode}{\lastnode}{}{}
	\xpatchcmd{\linklayers}{\nn@thisnode}{\thisnode}{}{}
	\makeatother
	
%Regression Tree
	\usepackage{tikz,forest}
	\usetikzlibrary{arrows.meta}
	
	\forestset{
		.style={
			for tree={
				base=bottom,
				child anchor=north,
				align=center,
				s sep+=1cm,
				straight edge/.style={
					edge path={\noexpand\path[\forestoption{edge},thick,-{Latex}] 
						(!u.parent anchor) -- (.child anchor);}
				},
				if n children={0}
				{tier=word, draw, thick, rectangle}
				{draw, diamond, thick, aspect=2},
				if n=1{%
					edge path={\noexpand\path[\forestoption{edge},thick,-{Latex}] 
						(!u.parent anchor) -| (.child anchor) node[pos=.2, above] {Y};}
				}{
					edge path={\noexpand\path[\forestoption{edge},thick,-{Latex}] 
						(!u.parent anchor) -| (.child anchor) node[pos=.2, above] {N};}
				}
			}
		}
	}

\usepackage{lscape}
\usepackage{longtable}

%%TODONOTE commands
\usepackage[colorinlistoftodos]{todonotes}
\newcommand{\smalltodo}[2][] {\todo[caption={#2}, size=\scriptsize,%
	fancyline,#1]{\begin{spacing}{.5}#2\end{spacing}}}
\newcommand{\rhs}[2][]{\smalltodo[color=green!30,#1]{{\bf RS:} #2}}
%%

%Graphs
\usepackage{tikz}
\usepackage{pgfplots}

%Coloured Tables

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%Title and other fluff, just before document start
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Hyperref apparently is a big package and causes a lot of issues, so it's recommended to load this last

\usepackage{hyperref}

%Gets rid of the neon green boxes around boxes

\usepackage[]{xcolor}

\hypersetup{
	colorlinks,
	linkcolor = {red!50!black},
	citecolor = {blue!50!black},
	urlcolor = {blue!80!black}
}

\title{Evaluation of Machine Learning in Empirical Asset Pricing}
\author{Ze Yu Zhong}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%BEGIN DOCUMENT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\tableofcontents

\section{Introduction}

\subsection{Topic}

This thesis aims to evaluate the application of machine learning algorithms in empirical asset pricing. While there has been a significant recent interest in applying machine learning to the problem of predicting asset returns, there is little literature that focuses on how well these algorithms are at capturing true underlying variables in determining stock returns. 12 different simulated datasets ranging from linear to highly non-linear data generating processes incorporating observed phenomena of cross sectional correlation, persistence, and stochastic volatility, in addition to real world data will be used to assess the performance of linear models, elastic net models, random forests and neural networks. Model performance will be assessed according to their out of sample predictive $R^2$ and errors, in addition to whether or not they were able to identify the correct variables in the data generating process according to a variable importance metric.

\subsection{Background Literature and Motivations}

This paper is motivated by evaluating the performance of machine learning algorithms in empirical asset pricing, focusing on how well they deal with the many unique problems in financial returns data. Here, we define ``performance" to refer to two forms of metrics conventional in the literature: $R^2$ (and more specifically, out of sample $R^2$), and forecast errors (see \ref{model_evaluation} for more details).

We first begin by defining ``factors" with the more contemporary definition as suggested by \cite{harvey__2016}: a collection of regressors to be used in pricing returns that can be used to proxy for unknown underlying risk factors due to their correlation with cross sectional returns. Most notably, their definition rejects the more strict view that risk factors should be variables that have unpredictable variation through time, and that they should be able explain cross sectional return patterns. \cite{harvey__2016} further groups factors into the two broad categories of ``common" and individual firm ``characteristics." ``Common" factors under this definition can be viewed as proxies for sources of risk constant across all firms, such as macroeconomic variables. They note that individual firm characteristics are unlikely to satisfy the more strict definition because they are often pre-known and display limited time series variation.

Because of this less strict definition, factors introduced and used in the literature often exhibit properties which makes them unsuitable for inclusion in models, such as high persistence, high levels of non-stationarity and cross sectional correlation. 

\cite{goetzmann_testing_1993} and \cite{ang_stock_2006} note the persistence present in dividend ratio factors. This means that movements in dividend ratios are dominated by movements in price and therefore dividend ratios are correlated with lagged dependent variables on the right hand side of the regression equation. This violates the assumptions of independent regressors required for traditional regression models (ordinary least squares) to be unbiased, resulting in t statistics which are biased upwards and increase with time horizon due to autocorrelated errors. Importantly, \cite{goetzmann_testing_1993} show that corrections to t statistics using the Generalized Method of Moments and Newey-West standard errors also appear to be biased upwards, making them unreliable. 

\cite{goyal_predicting_2003} provide a more comprehensive study on the performance of lagged dividend price ratios, with specific focus on out of sample predictive performance both in terms of $R^2$ and forecast errors. They conclude that while models incorporating dividend related factors were able to achieve higher in sample performance prior to 1990 than the historical mean, they could not have outperformed the historical mean \textit{out of sample}. \cite{goyal_predicting_2003} attribute this to the increasing persistence and non-stationarity of dividend ratios, noting that they have become like random walks as of 2001. This mirrors the sentiment of (\cite{lettau_consumption_2001}, \cite{schwert_anomalies_2003} and others) who conclude that models incorporating dividend ratios seemed to break down in the 2000s due to a changing economic environment despite having performed well in the 1990s.

Despite the controversy, the prevailing tone within the literature was that various factors such as dividend ratios, earnings price ratio, interest and inflation and other financial indicators were able to predict excess returns, with \cite{lettau_consumption_2001} remarking that this was now ``widely accepted." However, \cite{welch_comprehensive_2008} extend upon the work of \cite{goyal_predicting_2003} by including a more comprehensive set of variables and time horizons. They conclude that not a single variable had any statistical forecasting power. Crucially, they demonstrate the non-robustness of models incorporating these factors by showing that the significance values of some factors change with the choice of sample periods.

Despite this, the literature has continued to produce more factors: quantitative trading firms were using 81 factor models as the norm by 2014 \citep{hsu_finding_2014}, and \cite{harvey_census_2019} currently document well over 600 different factors suggested in the literature. 

The dramatic increase in the number of factors in of itself poses challenges to traditional statistical techniques. \cite{harvey__2016} detail the false discovery problem when the number of potential factors is extremely high. The significance of a factor in a traditional regression setting is determined by a single hypothesis test, which by construction carries a level of significance $\alpha$ controlling the type I error rate: the probability of finding a factor that is significant but is not. When the number of potential factors is very high, it is very likely that a factor will be concluded as significant by pure chance. \cite{harvey__2016} produce a multiple testing framework to mitigate this, and conclude that many of the historically discovered would have been deemed significant by chance.

Furthermore, \cite{feng_taming_2019} note that the number of potential factors discovered in the literature has increased to the same scale as, if not greater, than the number of stocks considered in a typical portfolio, or the time horizon, producing highly inefficient covariances in a standard cross sectional regression. Moreover, when the number of factors exceeds the sample size, traditional cross sectional regressions become infeasible and do not produce solutions altogether. 

It does not help that many factors are cross sectionally correlated, meaning that factors which are discovered to be significant may simply be so because they are correlated with a true, underlying factor and do not provide independent information themselves, a concern which \cite{cochrane_presidential_2011} calls the multidimensional challenge. \cite{freyberger_dissecting_2017} notes that this is especially challenging for traditional regression models, which make strong functional form assumptions and are sensitive to outliers. 

More recently, machine learning algorithms have emerged within the literature and appear to be well suited to the task of predicting asset returns. The definition of machine learning can be vague and is often context specific; \cite{hastie_elements_2009} in \textit{An Introduction to Statistical Learning} describes statistical (machine) learning as a vast set of tools for understanding data, and \textit{supervised} learning specifically as the process of building a statistical model for the prediction or estimation of an output based on input(s). In the context asset pricing, we use the term to refer to a diverse collection of:

\begin{enumerate}
	\item high-dimensional models for statistical prediction, 
	\item the ``regularization" methods for model selection and mitigation of overfitting input data, 
	\item and the efficient systematic methods for searching potential model specifications.
\end{enumerate}

The high dimensional and hence flexible nature of machine learning brings more hope to approximating unknown and likely complex data generating processes that underlie excess returns. The flexibility however, comes at a cost of potentially overfitting in sample data (referred to as training data in the machine learning literature), generalizing poorly and producing poor forecasts. The regularization aspect of machine learning explicitly guards against problem and emphasizes out of sample performance. Finally, machine learning offers tools which are designed to produce an an optimal model specification from all possible models with manageable computational cost, all in a systematically consistent way.

Machine learning has seen some applications in the empirical asset pricing literature. \cite{kozak_shrinking_2017}, \cite{rapach_forecasting_2013} and \cite{freyberger_dissecting_2017} all apply shrinkage and selection methods from machine learning in factor selection.  

Most importantly, portfolios constructed using machine learning have been demonstrated to outperform traditional models in predicting stock returns (\cite{gu_empirical_2018}, \cite{hsu_finding_2014} and \cite{feng_deep_2018}) in terms of out of sample predictive $R^2$ and Sharpe Ratios. \cite{gu_empirical_2018} attribute this to machine learning's ability to evaluate and consider non-linear complexities among factors that cannot be feasibly achieved using traditional techniques. 

However, there is little work done on how machine learning actually recognises and deals with the challenges of returns prediction documented in the literature. Prior work has been done by \cite{gu_empirical_2018}, however; only basic simulation designs which were not representative of real financial data were considered. In particular, their design did not consider cross sectionally correlated factors.

Furthermore, \cite{feng_deep_2018} in particular use cross validation as part of their model building procedure, destroying the temporal aspect of returns data, in addition to only using a handful of factors. \cite{gu_empirical_2018} produce models using a training sample which ends in the 1970s to ultimately produce forecasts for the most recent 30 years. Given the non-robustness of financial data affecting even traditional regressions which are considered to be more inflexible, more research should be done into the robustness of more flexible machine learning methods with regards to sample selection.

For the aspect of factor selection specifically, \cite{gu_empirical_2018} concludes that all of the machine methods agree on the same subset of important factors. However, while their factor importance metrics for regression-tree based methods and neural networks (the most complex methods considered) are mostly consistent, they have differences in terms of the relative importance of each factor, in addition to completely different conclusions for the dividend yield factor.

This paper will be the first in focusing on how machine learning algorithms perform in environments with problems exhibited by financial returns data through extending the simulation designs of \cite{gu_empirical_2018}. In addition, these algorithms will once again be evaluated on real world data, but with only more recent and representative data included in order to test their short term robustness in predicting stock returns. These two aspects of the study together are able to offer a better glimpse as to how ``black box" machine learning algorithms deal with the challenges present in asset pricing, if at all.

%\subsection{Main Findings}

%\rhs{Pending}

%\subsection{Limitations of Machine Learning}

%Machine learning excels at prediction problems, namely estimating \( E(r_{i, t+1}|\mathcal{F}_t) \), where \( r_{i, t+1} \) is an asset's excess return over the risk free rate, and \( \mathcal{F}_t \) is the set of all information (including unobservable) available to market participants in this context.

%This means that machine learning algorithms do not, nor do they aim to, explain how the market works in terms of underlying dynamics and equilibria. Though a machine learning algorithm may be able to identify patterns that otherwise cannot be easily found, an economist is still required to analyse these patterns to construct and hypothesize economic theory.

\section{Methodology}

\subsection{Overall Model Design}

Each model will be presented and explained so that a reader without any machine learning background can understand the basic idea behind each model. Details such as the computational and specific algorithm used for each model are included in the Appendix (\ref{Algorithms}). This is because there are many variations of algorithms available, and more importantly, specific understanding of how the algorithm works is not necessary. 

An an extension to \cite{gu_empirical_2018}'s work, we strive to use a similar design. All asset excess monthly returns denoted as $r_{i, t+1}$ are modelled as an additive prediction error model conditional on the true and unobservable information set available to market participants up to and including time $t$, $\mathcal{F}_t)$:

\begin{equation}
	r_{i, t+1} = E(r_{i, t+1} | \mathcal{F}_t) + \epsilon_{i, t+1}
\end{equation}

where 

\begin{equation}
	E(r_{i, t+1} | \mathcal{F}_t) = g^*(z_{i,t})
\end{equation}

Stocks are indexed as $i = 1, \dots, N$ and months by $t = 1, \dots, T$. $g^*(z_{i,t})$ represents the model approximation using the $P$ dimensional predictor set $z_{i,t}$. We allow $g^*(z_{i,t})$ to be a flexible function of the predictor set $z_{i,t}$, and most notably, not depend on $i$ or $t$ directly. This means that we do not re-estimate a model for each time period, or independently estimate a model for each stock. Note that $g^*(z_{i,t})$ only contains information in time $t$ for individual stock $i$, meaning that while the model and its parameters will be estimated using $\mathcal{F}_t$ for stock $i$, predictions for $r_{i, t+1}$ will only use information at time $t$ as an input, analogous to using variables lagged by one period. 

\subsection{Sample Splitting}
\label{sample_split}

Imperative to any machine learning technique is the establishment of how the dataset is to be split into training, validation and test sets. The training set is used to initially build the model and provide initial estimates of parameters, whereas the validation set is used to tune model parameters to optimise out of sample performance, thus preventing overfitting. The validation set acts as a simulation of out of sample testing, whereas the test set is used only for evaluation, and is thus truly out of sample.

There are three main approaches to splitting temporal data (such as financial data). 

The first is to decide arbitrarily on a single training, validation and test set. This method is straightforward and the least computationally intensive, but is limited and inflexible in evaluating how models perform when more recent data is provided for training. 

The second method is a "rolling window" method, where a fixed size or "window" for the training and validation set is first chosen. This window then incrementally move forwards in time to include more recent data, with a set of forecasts for the test sets made for all possible windows.

The third is a "recursive" method, which is the same as the rolling window method, but different in that the training set always contains previous data, with only the validation set staying fixed in size and "rolling" forwards. Hence, it is also referred to as a "growing window."

Both the rolling window and recursive schemes are very computationally intensive. Therefore, a hybrid of the rolling and recursive schemes was considered: the training set is increased by one year with each refit, the validation set remains one year in length but moves forward by one year, and forecasts are made using that model for the subsequent year. Cross validation was not done to maintain the temporal ordering of the data.

\subsection{Loss Function}

The choice of the loss function used in models is imperative to machine learning. The loss functions considered are Mean Absolute Error (MAE), Mean Squared Error and Root Mean Squared Error (MSE, and RMSE).

\subsubsection{Mean Absolute Error}

The mean absolute error (MAE) is simply the average magnitude of errors. Because of this, it places equal weighting to all magnitudes of errors and is more robust to outliers. 

\begin{equation}
	\text{MAE} = \frac{1}{n} \sum_{j = i}^{n} |y_j - \hat{y_j}|
\end{equation}

It should be noted that minimizing the MAE criterion is equivalent to minimizing 0.5 quantile loss. 

\subsubsection{Mean Squared Error and Root Mean Squared Error}

The mean squared error (MSE) and root mean squared error (RMSE) are quadratic scoring methods. This means that they place higher weight on large errors. Models that minimize this metric are therefore more sensitive to outliers. 

\begin{align}
	\text{MSE} &= \frac{1}{n} \sum_{j = i}^{n} \left( y_j - \hat{y_j}\right) ^2 \\
	\text{RMSE} &= \sqrt{ \frac{1}{n} \sum_{j = i}^{n} \left( y_j - \hat{y_j}\right) ^2}
\end{align}

%not too sure about huber loss, just leave it out for now

%\subsubsection{Huber Loss}
%
%The Huber Loss metric \citep{huber_robust_1992} offers a combination of mean squared error and mean absolute error, with errors smaller than the threshold $\xi$ being mean squared error and errors larger than the threshold $\xi$ being absolute error. This allows for the model fit to be less sensitive to outliers which are quite common in financial data. 
%
%\begin{align}
%	H(\epsilon_j = y_j - \hat{y_j};\xi) = 
%		\begin{cases}
%		\left( y_j - \hat{y_j}\right) ^2, 
%		\quad &\text{if} \quad |y_j - \hat{y_j}| \leq \xi ; \\
%		2 \xi  |y_j - \hat{y_j}| - \xi^2, 
%		\quad &\text{if} \quad |y_j - \hat{y_j}| > \xi
%	\end{cases}
%\end{align}
%
%\begin{figure}
%	\begin{center}
%		\begin{tikzpicture}
%		\begin{axis}[ xlabel={$\epsilon$}, ylabel={Loss}, axis lines=middle, samples=41, grid, thick, domain=-2:2]
%		\addplot+[no marks] {abs(x)};
%		\addlegendentry{MAE}
%		\addplot+[no marks] {x^2};
%		\addlegendentry{MSE}
%		\addplot+[no marks] {(2 * abs(x) - 1)*(abs(x) > 1) +
%			(x^2)*(abs(x) <= 1 )};
%		\addlegendentry{Huber Loss}
%		\end{axis}
%		\end{tikzpicture}
%	\end{center}
%	\caption{Illustration of MAE, MSE and Huber Loss when $\xi = 1$}
%	\label{fig:loss_functions}
%\end{figure}

\subsection{Linear Model}

The least complex model considered is the simple linear regression model, also known that ordinary least squares in the case of the using mean squared error as the loss function. Linear models struggle with high-dimensionality. Nevertheless, despite being expected to perform poorly it was implemented as a ``control."

The simple linear model assumes that the underlying conditional expectation \( g^*(z_{i, t}) \) can be modelled as a linear function of the predictors and the parameter vector \( \theta \):

\begin{equation}
	g(z_{i, t};\theta) = z_{i, t}' \theta
\end{equation}

This model can capture non-linearities only if the predictor set \(z^*_{i, t}\) contains specified non-linear transformations or interaction terms. 

Note that computing this model with respect to minimizing the mean squared error yields the pooled ordinary least squares estimator (POLS).

\subsection{Penalized Linear Model}

Penalized linear models have the same underlying statistical model as simple linear models, but differ in their addition of a new penalty term in the loss function:

\begin{equation}
	\mathcal{L(\theta;.)} = 
	\underset{\text{Loss Function}}{\underbrace{\mathcal{L(\theta)}}} + 
	\underset{\text{Penalty Term}}{\underbrace{\phi(\theta;.)}}
\end{equation}

Several choices exist for the choice of the penalty function \( \phi(\theta;.) \). This focus of this paper is the popular "elastic net" penalty \citep{zou_regularization_2005}:

\begin{equation}
	\phi(\theta;\lambda,\rho) = 
	\lambda(1-\rho) \sum_{j = 1}^{P}|\theta_j| +
	\frac{1}{2} \lambda \rho \sum_{j = 1}^{P}\theta_j^2
\end{equation}

The elastic net has two hyperparameters: $\lambda$, which controls the overall magnitude of the loss, and $\rho$, which controls the shape of the penalization. 

The $\rho = 1$ case corresponds to ridge regression proposed by \cite{hoerl_ridge_1970}, which uses $l_2$ that shrinks all coefficients closer to 0, but not to 0. Ridge regression is therefore a shrinkage method which prevents coefficients from becoming too large and overpowering. For \(0 < \rho < 1\), the elastic net aims to produce parsimonious models through both shrinkage and selection.

The $\rho = 0$ case corresponds to the popular LASSO and uses absolute ($l_1$) parameter penalization proposed by \cite{tibshirani_regression_1996}, which geometrically allows the coefficients to be shrunk to 0. This allows it to impose sparsity, and can be thought of as a variable selection tool.

By combining the properties of LASSO and ridge regression, the elastic net aims to produce parsimonious models through both coefficient shrinkage and selection.

The hyperparameters $\lambda$ and $\rho$ are both tuned using the validation sample (see \ref{Algorithms}). 

\pagebreak

\subsection{Classification and Regression Trees}

Classification and regression trees are fully non-parametric models that can capture complex multi-way interactions. A tree "grows" in a series of iterations. With each iteration, a split ("branch") is made along one predictor such that it is the best split available at that stage with respect to minimizing the loss function. These steps are continued until each observation is its own node, or more commonly until the stopping criterion is met. The eventual model slices the predictor space into rectangular partitions, and predicts the unknown function $g^*(z_{i,t})$ with the average value of the outcome variable in each partition.

The prediction of a tree, $\mathcal{T}$, with \(K\) "leaves" (terminal nodes), and depth $L$ is

\begin{equation}
	g(z_{i,t};\theta,K,L) = \sum_{k=1}^{K}\theta_k\textbf{1}_{z_{i,t}\in C_k(L)}
\end{equation}

where $C_k(L)$ is one of the $K$ partitions in the model.

For this study, only recursive binary trees (the most common and easy to implement) are considered. Though trees were originally proposed and fit with respect to minimizing mean squared error, they can be grown with respect to a variety of loss functions, including mean absolute error, mean squared error:

\begin{equation}
	H(\theta, C) = \frac{1}{|C|} \sum_{z_{i,t} \in C} L(r_{i,t+1} - \theta)
\end{equation}

where $|C|$ denotes the number of observations in set C (partition). Given $C$, it is clear that the optimal choice for minimising the loss function when it is mean squared error is simply $\theta = \frac{1}{|C|} \sum_{z_{io,t}\in C}^{ }r_{i,t+1}$ i.e. the average of the partition, and the median of the partition when the loss function is mean absolute error.

Trees, grown to a deep enough level, are highly unbiased and flexible. The tradeoff of course, is their high variance and instability. Thus, an ensemble method called "Random Forest" was proposed by \cite{breiman_random_2001} to regularize trees by combining many different trees into a single prediction.

\subsection{Random Forests}
Random Forests are an extension of trees that attempt to address some of their problems. A random forest algorithm creates $B$ different bootstrap samples from the training dataset, fits an overfit (and hence low bias) regression tree to each using only a random subset $m$ size from all available predictors (also known as dropout), and then averages their forecasts as the final output. The overfit trees means that the underlying trees has low bias, and the dropout procedure means that they have low correlation. Thus, averaging these low bias, uncorrelated trees results in a low bias, yet stable model. Specific details of the random forest algorithm are detailed in the appendix.

\pagebreak

\subsection{Neural Networks}

\subsubsection{Introduction}

Neural networks have theoretical underpinnings as ``universal approximators" for any smooth predictive association, (\cite{hornik_multilayer_1989}). They are arguably the most complex type of model available, able to capture several non-linear interactions through their many layers, hence its other name ``deep learning."  On the flipside, their high flexibility often means that they are among the most parameterized and least interpretable models, earning them the reputation as a black box model.

The scope of this paper is limited to traditional ``feed-forward" networks. The feed forward network consists of an ``input layer" of scaled data inputs, one or more ``hidden layers" which interact and non-linearly transform the inputs, and finally an output layer that aggregates the hidden layers and transform them a final time for the final output. 

More specifcally, a neural network consists of layers denoted by $l = 0, 1, \dots, L$, with $l = 0$ denoting the input layer and $l = L$ denoting the output layer, and $K^{(l)}$ denoting the number of neurons in each hidden layer. The input layer is defined using predictors, $x^{(0)} = (1, z_1, \dots, z_N)'$. The output of neuron $k$ in layer $l$ is then $x_k^{(l)}$. Next, define the vector of outputs for this layer as $x^{(l)} = (1, x_1^{(l)}, \dots, x_{K^(l)}^{(l)})'$.  The recursive output formula for the neural network at each neuron in layer $l > 0$ is then:

\begin{equation}
x_k^{(l)} = \alpha(x^{(l-1)'}\theta_k^{l-1}),
\end{equation}

where $\alpha()$ represents the activation function for that layer (see next section) with the final output

\begin{equation}
g(z;\theta) = x^{(L-1)'}\theta^{L-1}
\end{equation}

Note that the specification of a constant ``1" at the beginning of each layer is the same as specifying a bias term as is popular in other parametrizations. 

Neural networks with up to 5 hidden layers were considered, each named NNX where X represents the number of hidden layers. The number of neurons is each layer was chosen according to the geometric pyramid rule \citep{masters_practical_1993}: NN1 has 32 neurons, NN2 has 32 and 16 neurons in the first and second hidden layers respectively, NN3 has 32, 16, and 8 neurons, NN4 has 32, 16, 8, and 4 neurons, and NN5 has 32, 16, 8, 4, 2 neurons respectively. All units are fully connected; that is, each neurons receives input from all neurons the layer before it (see Figure \ref{Neural_Network}). This mimics the methodology in \cite{gu_empirical_2018}.

\begin{figure}
	\begin{center}
		\begin{neuralnetwork}
			%Options
			[nodespacing=12mm, layerspacing=20mm,
			maintitleheight=2.5em, layertitleheight=2.5em,
			height=9, toprow=false, nodesize=20pt, style={},
			title={}, titlestyle={}]
			\newcommand{\nodetextclear}[2]{}
		    %use \ifnum to get different labels, such as x_n on the last neuron
			\newcommand{\nodetextx}[2]{\ifnum #2=8 $x_n^{(0)}$ \else $x_#2^{(0)}$ \fi}
			\newcommand{\nodetexty}[2]{$y_#2$}
			%Hidden layer textcommands
				%32 neurons
				\newcommand{\nodetextxa}[2]{\ifnum #2=7 $x_{32}^{(1)}$ \else $x_#2^{(1)}$ \fi}
				%16 neurons
				\newcommand{\nodetextxb}[2]{\ifnum #2=6 $x_{16}^{(2)}$ \else $x_#2^{(2)}$ \fi}
				%8 neurons
				\newcommand{\nodetextxc}[2]{\ifnum #2=5 $x_{8}^{(3)}$ \else $x_#2^{(3)}$ \fi}
				\newcommand{\nodetextxd}[2]{$x_#2^{(4)}$}
				\newcommand{\nodetextxe}[2]{$x_#2^{(5)}$}
			%Input Layer
			\inputlayer[count=8, bias=false, exclude = {7}, title=Input Layer, text=\nodetextx]
			%Hidden Layer 1
			\hiddenlayer[count=7, bias=false, exclude = {6}, title=Hidden Layer 1, text=\nodetextxa] 
				\linklayers[not from = {7}, not to = {6}]
			%Hidden Layer 2
			\hiddenlayer[count=6, bias=false, exclude = {5}, title=Hidden Layer 2, text=\nodetextxb] 
				\linklayers[not from = {6}, not to = {5}]
			%Hidden Layer 3
			\hiddenlayer[count=5, bias=false, exclude = {4}, title=Hidden Layer 3, text=\nodetextxc] 
				\linklayers[not from = {5}, not to = {4}]
			%Hidden Layer 4
			\hiddenlayer[count=4, bias=false, title=Hidden Layer 4, text=\nodetextxd] 
				\linklayers[not from = {4}]
			%Hidden Layer 5
			\hiddenlayer[count=2, bias=false, title=Hidden Layer 5, text=\nodetextxe] \linklayers
			%Final Layer
			\outputlayer[count=1, title=Output Layer, text=\nodetexty] \linklayers
			% draw dots
			\path (L0-6) -- node{$\vdots$} (L0-8);
			\path (L1-5) -- node{$\vdots$} (L1-7);
			\path (L2-4) -- node{$\vdots$} (L2-6);
			\path (L3-3) -- node{$\vdots$} (L3-5);
		\end{neuralnetwork}
	\end{center}
\caption{Neural Network 5 (most complex considered), without biases terms drawn}
\label{Neural_Network}
\end{figure}

\subsubsection{Activation Function}

The ReLU activation function

\begin{equation}
	\operatorname{ReLU}(x) = max(0, x)
\end{equation}

was used for all hidden layers owing to its high computational speed, and hence popularity within recent literature  (see \cite{lecun_deep_2015} and \cite{ramachandran_searching_2017}, among others). Other potential choices for activation functions such as sigmoid, softmax, tanh etc. were not used due to the additional complexities and computational costs involved with validating the choice of activation function.

\subsubsection{Computation}

The neural network's weight and bias parameters for each layer are estimated by minimizing the loss function with respect to the parameters, i.e. by calculating the partial derivative with respect to a specific weight or bias element.

The solution to this is typically found via backpropagation, an iterative alogrithm similar to Gauss-Newton steps and produces a local minimum. These steps can be visualized as a descent towards the local minimum of the loss function; it is thus also known as "gradient descent." Note that the lack of a global minimum is actually desirable, as global minimums tend to be overfit solutions to the problem, \citep{choromanska_loss_2014}. This is to be calculated and averaged across all training observations, and is thus extremely computationally intensive. 

A common solution is to use ``stochastic gradient descent" (SGD) where instead of optimising the loss function with respect to the entire training sample, only a small, random subset of the data (batch) is used at each optimisation step. This sacrifices some accuracy for a dramatic improvement in computational speed.

Due the noisiness (randomness) introduced by SGD, the path towards the local minimum is more of a quick ``zig zag" and has the potential to ``overshoot" the local minimum and not converge to a solution. This is typically controlled via a hyperparameter known as the learning rate, which controls the step size of each gradient descent iteration. Note that it is also common to apply a learning rate hyperparameter in non SGD environments as a way to control the magnitude of each step towards the solution to assist with convergence. The learning rate is to be tuned so that the solution path descends quickly enough to be computationally feasible, but slow enough so that it does not overshoot the local minimum and not converge. In this paper, a learning rate shrinkage algorithm which adaptively shrinks the learning rate as convergence occurs was employed (see \cite{kingma_adam:_2014}).

\subsubsection{Batch Normalization}

``Batch normalization" is a technique for addressing a phenomenon known as internal covariate shift, a particularly prevalent problem in training deep, complex neural networks, \citep{ioffe_batch_2015}. Internal covariate shift occurs when the distributions of each layers' inputs change as the parameters of the previous layer change, resulting in the need for much slower learning rates and more careful initialization of parameters. By normalizing (de-meaning and variance standardizing) each training step (batch) input, the representation power of each neuron (unit) is restored. Additionally, significant gains in computational speed may also be achieved.

\subsubsection{Initialization}

Finally, multiple random starting values for the weights and biases (seeds) were used in training neural networks, with the resulting predictions averaged in an ensemble model, \cite{hansen_neural_1990}. This regularizes the variance associated with the initial starting values for the weights and biases. It should be noted however, that contemporary literature suggests that all local solutions are of similar quality and thus this is not strictly necessary, \citep{choromanska_loss_2014}.

\subsection{Simulation Design}

\subsubsection{Overall Design}

\rhs{double check conformability of everything, make sure that the errors are corrected}

Though \cite{gu_empirical_2018} explore the performance of machine learning on simulated returns series, their design used factors are uncorrelated across $i$, and, in particular, that the factors which enter the return equation are uncorrelated with the factors that do not enter the return equation. As note by \cite{harvey__2016} and many others, this is not what is observed in practice. 

Therefore, we simulate an extension: a latent factor model with stochastic volatility for excess return, $r_{t+1}$, for $t=1,\dots,T$:

\begin{flalign}
r_{i, t+1} &= 
g\left(z_{i, t}\right) + \beta_{i,t+1}v_{t+1} + e_{i, t+1}; 
\quad z_{i, t}=\left(1, x_{t}\right)^{\prime} \otimes c_{i, t}, 
\quad \beta_{i, t}=\left(c_{i 1, t}, c_{i 2, t}, c_{i 3, t}\right) \\ 
e_{i, t+1} &= 
\exp\left( \frac{\sigma_{i, t+1}^2}{2} \right) \varepsilon_{i, t+1}; \\
\sigma^2_{i,t+1} &= 
\omega + \gamma \sigma^2_{t} + w_{t+1}
\end{flalign}

Let $v_{t+1}$ be a $3\times 1$ vector of errors, and $w_{t+1} \sim N(0, 1)$ and $\varepsilon_{i,t+1} \sim N(0, 1)$ scalar error terms. The parameters of these are tuned such that the R squared for each individual return series was 50\% and annualized volatility 30\%.

The matrix $C_t$ is an $N\times P_c$ vector of latent factors, where the first three columns correspond to $\beta_{i,t}$, across the $1\leq i\leq N$ dimensions, while the remaining $P_c-3$ factors do not enter the return equation. The $P_x\times1$ vector $x_t$ is a $3 \times 1$ multivariate time series, and $\varepsilon_{t+1}$ is a $N\times 1$ vector of idiosyncratic errors. 

\subsubsection{Simulating Characteristics}

A simulation mechanism for $C_t$ that gives some correlation across the factors and across time was used. First consider drawing normal random numbers for each $1\leq i\leq N$ and $1\leq j\leq P_{c}$, according to 

\begin{equation}
	\overline{c}_{i j, t} = \rho_{j} \overline{c}_{i j, t-1}+\epsilon_{i j, t} ;
	\quad \rho_{j} \sim \mathcal{U} \left( \frac{1}{2},1 \right) 
\end{equation}

Then, define the matrix 

\begin{equation}
	B:=\Lambda\Lambda' + \frac{1}{10}\mathbb{I}_{n}, \quad
	\Lambda_i = (\lambda_{i1},\dots,\lambda_{i4}), \quad
	\lambda_{ik}\sim N(0,1), \; k=1,\dots,4
\end{equation}

which we transform into a correlation matrix $W$ via

\begin{equation}
	W = \left( \operatorname{diag}(B) \right) ^{\frac{-1}{2}}
	(B)
	\left( \operatorname{diag}(B) \right) ^{\frac{-1}{2}}
\end{equation}

To build in cross-sectional correlation, from the $N\times P_{c}$ matrix $\bar{C}_t$, we simulate characteristics according to
 
\begin{equation}
	\widehat{C}_{t}=W\overline{C}_{t}
\end{equation}
 
Finally, the "observed" characteristics for each $1\leq i\leq N$ and for $j=1, \dots, P_{c}$ are constructed according to:

\begin{equation}
	c_{i j, t} = \frac{2}{n+1} \operatorname{rank}\left(\hat{c}_{i j, t}\right) - 1.
\end{equation}

with the rank transformation normalizing all predictors to be within $[-1, 1]$. 

\subsubsection{Simulating Macroeconomic Series}

For simulation of $x_{t}$, a $3 \times 1$ multivariate time series, we consider a Vector Autoregression (VAR) model, a generalization of the univariate autoregressive model to multiple time series:

\begin{flalign*}
x_{t}=Ax_{t-1}+u_t, 
\quad u_t \sim N\left( \mu = (0, 0, 0)' , \Sigma = 
	\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 1 & 0 \\
		0 & 0 & 1
	\end{pmatrix}\
	\right) 
\end{flalign*}

where we have three separate specifications for the matrix $A$:

\begin{align}
(1)\; A =
	\begin{pmatrix}
		.95 & 0 & 0 \\
		0 & .95 & 0 \\
		0 & 0 & .95
	\end{pmatrix}\;
\;
(2)\; A=
	\begin{pmatrix}
		1 & 0 & .25 \\
		0 & .95 & 0 \\
		.25 & 0 &.95
	\end{pmatrix}\;
\;
(3)\; A=
	\begin{pmatrix}
		.99 & .2 & .1 \\
		.2 & .90 & -.3 \\
		.1 & -.3 & -.99
	\end{pmatrix}
\end{align}

\subsubsection{Simulating Return Series}

We will consider four different functions for $g(z_{i, t})$:

\begin{flalign*}
(1)\; & g_1 \left(z_{i, t}\right)=\left(c_{i 1, t}, c_{i 2, t}, c_{i 3, t} \times x_{t}'\right) \theta_{0};
	\quad \theta_{0} = (0.02, 0.02, 0.02)^{\prime} \\
(2)\; & g_2 \left(z_{i, t}\right)=\left(c_{i 1, t}^{2}, c_{i 1, t} \times c_{i 2, t}, \operatorname{sgn}\left(c_{i 3, t} \times  x_{t}'\right)\right) \theta_{0}; 
	\quad \theta_{0} = (0.04, 0.035, 0.01)^{\prime} \\
(3)\; & g_3 \left(z_{i, t}\right) = \left(1[c_{i3,t}>0],c_{i 2, t}^{3}, c_{i 1, t} \times c_{i 2, t}\times 1[c_{i3,t}>0], \text{logit}\left({c}_{i 3, t} \right)\right) \theta_{0};
	\quad \theta_{0} = (0.04, 0.035, 0.01, 0.01)^{\prime} \\
(4)\; & g_4 \left(z_{i, t}\right)=\left(\hat{c}_{i 1, t}, \hat{c}_{i 2, t}, \hat{c}_{i 3, t} \times x_{t}'\right) \theta_{0};
	\quad \theta_{0} = (0.02 ,0.02 ,0.02)^{\prime}
\end{flalign*}

$g_1 \left(z_{i, t}\right)$ allows the characteristics to enter the return equation linearly, and $g_2 \left(z_{i, t}\right)$ allows the characteristics to enter the return equation interactively and non-linearly. These two specifications correspond to the simulation design proposed by \cite{gu_empirical_2018}. 

$g_3 \left(z_{i, t}\right)$ allows the characteristics to enter in a highly complex and non-linear fashion.

$g_4 \left(z_{i, t}\right)$ builds returns using $\hat{c}$, which are the original characteristics without cross sectional correlation built in.

$\theta^0$ will be tuned such that the cross sectional $R^2$ for any given time period is 25\%, and the predictive $R^2$ across the entire time period is 5\%.

The simulation design results in $3 \times 4 = 12$ different simulated datasets, each with $N = 200$ stocks, $T = 180$ periods and $P_c = 100$ characteristics. Each design was simulated 50 times to assess the robustness of machine learning algorithms.

\subsubsection{Sample Splitting}

$T = 180$ monthly periods corresponds to 15 years. The training sample was set to start from $T = 108$ or 9 years, a validation set 1 year in length. The last 3 years were reserved as a test set never to be used for validation or training. We employ the hybrid growing window approach as described earlier in section \ref{sample_split} (see Figure \ref{sample_split_diag} for a graphical representation).

Unlike \cite{gu_empirical_2018} who split their simulated dataset into training, validation and test sets of equal length, we choose a splitting scheme that is consistent with the splitting scheme to be used for the real world dataset.

\begin{figure}
	\begin{center}
		\begin{tabular}{|c|p{0.25cm}p{0.25cm}p{0.25cm}p{0.25cm}p{0.25cm}p{0.25cm}p{0.25cm}p{0.25cm}p{0.25cm}p{0.25cm}p{0.25cm}p{0.25cm}|p{0.25cm}p{0.25cm}p{0.25cm}|}
			\hline
			Set No. &&&&&&&&&&&&&&& \\
			\hline
			%%%%%%%%
			3 & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} &
			\cellcolor{pink} & 
			\cellcolor{olive} & \cellcolor{olive} &	\cellcolor{olive} \\
			%%%%%%%%
			2 & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} &
			\cellcolor{pink} & 
			\cellcolor{olive} & \cellcolor{olive} &	\cellcolor{olive} & \cellcolor{olive} \\
			%%%%%%%%
			1 & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} & \cellcolor{cyan} &
			\cellcolor{pink} & 
			\cellcolor{olive} & \cellcolor{olive} &	\cellcolor{olive} & \cellcolor{olive} & \cellcolor{olive} \\
			\hline
			Year & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15\\
			\hline
		\end{tabular}
		\medskip
		\begin{tabular}{|c|p{0.25cm}|}
			\hline
			Training & \cellcolor{cyan} \\
			\hline
			Validation & \cellcolor{pink} \\
			\hline
			Test & \cellcolor{olive} \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Sample Splitting Procedure}
	\label{sample_split_diag}
\end{figure}

\subsection{Model Evaluation}
\label{model_evaluation}

\subsubsection{R Squared}

Overall predictive performance for individual excess stock returns were assessed using the out of sample $R^2$:

\begin{equation}
	R^2_{OOS} = 1 - \frac{\sum_{(i, t)\in\mathcal{T}_3}(r_{i, t+1} - \widehat{r}_{i, t+1})^2}
		{\sum_{(i, t)\in\mathcal{T}_3} \left( r_{i, t+1} - \bar{r}_{i, t+1} \right) ^2}
\end{equation}

where $\mathcal{T}_3$ indicates that the fits are only assessed on the test subsample, which is never used for training or tuning. 

\subsubsection{Diebold-Mariano Test}

The Diebold-Mariano test (\cite{diebold_comparing_2002}, and \cite{harvey_testing_1997}) is a procedure which compares the forecast accuracy of two forecast methods. It is different to the overall R squared metric because it tests whether or not the models' forecast accuracy is significantly different. 

Under the null hypothesis of the Diebold-Mariano test:

\begin{align}
	S_1^* &= \left[ 
		\frac{n + 1 - 2h + n^{-1}h(h-1)}
			{n} 
	\right]^{1/2}S_1 ; \quad S_1^* \sim N(0,1) \\
	S_1 &= \left[ 
		\hat{V}(\bar{d})
	\right] ^{-1/2}\bar{d} \\
	\hat{\gamma}_k &= n^{-1} \sum_{t = k + 1}^{n}(d_t - \bar{d})(d_{t-k} - \bar{d}) \\
	V(\bar{d}) &\approx n^{-1}\left[ 
		\gamma_0 + 2 \sum_{k = 1}^{h - 1}\gamma_k
	\right] 
\end{align}

where $d_t$ represents the difference series between the forecast errors of the two models $e_1t - e_2t$, $\hat{\gamma}_k$ represents the sample $k$th autocovariance for $d_t$, and $S_1$ represents the original unmodified Diebold Mariano test statistic.

As all models in this paper will be producing forecasts for an entire cross section of stocks, $e_1t$ and $e_2t$ will instead represent the average forecast errors for each model.

\subsection{Variable Importance}

The importance of each predictor $j$ is denoted as $VI_j$, and is defined as the reduction in predictive R-Squared from setting all values of predictor $j$ to 0, while holding the remaining model estimates fixed. This will allow us to see which variables each model determines to be important. 

\section{Study}

\subsection{Data}

\rhs{A large part of this section can be done now}

We mimic the data procedure of \cite{gu_empirical_2018}. This means that we obtain the dataset provided by Gu on his website. This dataset contains 94 stock level characteristics: 61 updated annually, 13 updated quarterly and 20 updated monthly. In addition, 74 industry dummies corresponding the the first two digits of the Standard Industrial Classification (SIC) codes are included. 

We then follow \cite{gu_empirical_2018} and construct eight macroeconomic factors following the variable definitions in \cite{welch_comprehensive_2008}: dividend-price ratio (dp), earnings-price ratio (ep), book-to-market ratio (bm), net equity expansion (ntis), Treasury-bill rate (tbl), term spread (tms), default spread (dfy) and stock variance (svar).

The full details of these factors are available in table X.

Throughout all methods and analysis we define the basline set of covariates as:

\begin{equation}
	z_{i,t} = (1, x_t)' \otimes c_{i, t}
\end{equation}

where $c_{i,t}$ is a $P_c$ matrix of characteristics for each stock $i$, and $(1, x_t)'$ is a $P_x \times 1$ vector of macroecnomic predictors. $z_{i,t}$ is therefore a $P_x P_c$ vector of features for predicting individual stock returns and includes interactions between stock level characteristics and macroeconomic variables. The total number of covariates in this baseline set is $94 \times (8 + 1) + 74 = 920$.



\subsection{Model}

All machine learning methods are designed to approximate the empirical model \( E_t(r_{i, t+1}) = g*(z_{i,t}) \) defined in equation (2). The baseline set of stock-level covariates \( z_{i,t} \) as:

\begin{equation}
	z_{i,t} = x_t \otimes c_{i,t}
\end{equation}

where \( c_{i,t} \) is a \( P_c \times 1 \) matrix of characteristics for each stock \(i\), and \(x_t\) is a $P_x \times 1$ vector of macroeconomic predictors (and are this common to all stocks, including a constant). $z_{i,t}$ is a $P \times 1$ vector of features for predicting individual stock returns ($P = P_cP_x$) and includes interactions between individual characteristics and macroeconomic characteristics. 

\section{Results}

All work has been and will be done in R.

Work is currently being done on tuning the simulated datasets.

If there is enough time and computing resources, Long Term Short Memory models, an extension of neural networks which includes the output of a neural network trained on previous data, will also be evaluated.

\section{Appendix}

\subsection{Data}

\begin{table}
	\caption{Stock Level Characteristics, data collected are in \citep{green_supraview_2013}}
	\begin{center}
		\begin{longtable}{lllllllll} \hline \hline
			No. & Acronym & Firm Characteristic & Paper's Author(s) & Year & Type & Data Source & Frequency \\ \hline \hline
			\endfirsthead
			No. & Acronym & Firm Characteristic & Paper's Author(s) & Year & Type & Data Source & Frequency \\ \hline \hline
			\endhead
			\endfoot
			\endlastfoot
			1 & absacc & Absolute Accruals & \cite{bandyopadhyay_accrual_2010} & year & Continuous & Compustat & Annual \\
			2 & acc & Working capital accruals & \cite{sloan_stock_1996} & year & Continuous & Compustat & Annual \\
			3 & aeavol & Abnormal earnings announcement volume & \cite{lerman_high-volume_2008} & year & Continuous & Compustat & Quarterly \\
			4 & age & \# years since first Compustat coverage & \cite{jiang_information_2005} & year & Continuous & Compustat & Annual \\
			5 & agr & Asset growth & \cite{cooper_asset_2008} & year & Continuous & Compustat & Annual \\
			6 & baspread & Bid-ask spread & \cite{amihud_effects_1989} & year & Continuous & Compustat & Monthly \\
			7 & beta & Beta & \cite{fama_risk_1973} & year & Continuous & Compustat & Monthly \\
			8 & betasq & Beta squared & \cite{fama_risk_1973} & year & Continuous & Compustat & Monthly \\
			9 & bm & Book-to-market & \cite{rosenberg_persuasive_1985} & year & Continuous & Compustat & Annual \\
			10 & bm\_ia & Industry-adjusted book to market & \cite{asness_predicting_2000} & year & Continuous & Compustat & Quarterly \\
			%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			11 & cash & Cash holdings & \cite{palazzo_cash_2012} & year & Continuous & Compustat & Annual \\
			12 & cashdebt & Cashflow to debt & \cite{ou_financial_1989} & year & Continuous & Compustat & Annual \\
			13 & cashpr & Cash productivity & \cite{chandrashekar_productivity_2009} & year & Continuous & Compustat & Annual \\
			14 & cfp & Cashflow to price ratio & \cite{desai_value-glamour_2004} & year & Continuous & Compustat & Annual \\
			15 & cfp\_ia & Industry-adjusted cashfow to price ratio & \cite{asness_predicting_2000} & year & Continuous & Compustat & Annual \\
			16 & chatoia & Industry-adjusted change in asset turnover & \cite{soliman_use_2008} & year & Continuous & Compustat & Annual \\
			17 & chcsho & Change in shares outstanding & \cite{pontiff_share_2008} & year & Continuous & Compustat & Annual \\
			18 & chempia & Industry-adjusted change in employee & \cite{asness_predicting_2000} & year & Continuous & Compustat & Annual \\
			19 & chinv & Change in inventory & \cite{thomas_inventory_2002} & year & Continuous & Compustat & Annual \\
			%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			20 & chmom & Change in 6-month momentum & \cite{gettleman_acceleration_2006} & year & Continuous & Compustat & Monthly \\
			21 & chpmia & Industry-adjusted change in profit margin & \cite{soliman_use_2008} & year & Continuous & Compustat & Annual \\
			22 & chtx & Change in tax expense & \cite{thomas_tax_2011} & year & Continuous & Compustat & Quarterly \\
			23 & cinvest & Corporate investment & \cite{titman_capital_2004} & year & Continuous & Compustat & Quarterly \\
			24 & convind & Convertible debt indicator & \cite{valta_strategic_2016} & year & Dummy & Compustat & Annual \\
			25 & currat & Current ratio & \cite{ou_financial_1989} & year & Continuous & Compustat & Annual \\
			26 & depr & Depreciation / PP\&E & \cite{holthausen_prediction_1992} & year & Continuous & Compustat & Annual \\
			27 & divi & Dividend initiation & \cite{michaely_price_1995} & year & Dummy & Compustat & Annual \\
			28 & divo & Dividend omission & \cite{michaely_price_1995} & year & Dummy & Compustat & Annual \\
			29 & dolvol & Dollar trading volume & \cite{chordia_trading_2001} & year & Continuous & Compustat & Monthly \\
			%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			30 & dy & Dividend to price & \cite{litzenberger_effects_1982} & year & Continuous & Compustat & Annual \\
			31 & ear & Earnings announcement return & \cite{brandt_earnings_2008} & year & Continuous & Compustat & Quarterly \\ \hline
			32 & egr & Growth in common shareholder eq & \cite{richardson_accrual_2005} & year & Continuous & Compustat & Annual \\
			33 & ep & Earnings to price & \cite{basu_investment_1977} & year & Continuous & Compustat & Annual \\
			34 & gma & Gross profitability & \cite{novy-marx_other_2013} & year & Continuous & Compustat & Annual \\
			35 & grCAPX & Growth in capital expenditures & \cite{anderson_empirical_2006} & year & Continuous & Compustat & Annual \\
			36 & grltnoa & Growth in long term net operating assets & \cite{fairfield_accrued_2003} & year & Continuous & Compustat & Annual \\
			37 & herf & Industry sales concentration & \cite{hou_industry_2006} & year & Continuous & Compustat & Annual \\
			38 & hire & Employee growth rate & \cite{belo_labor_2014} & year & Continuous & Compustat & Annual \\
			39 & idiovol & Idiosyncratic return volatility & \cite{ali_arbitrage_2003} & year & Continuous & Compustat & Monthly \\
			%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			40 & ill & Illiquidity & \cite{amihud_illiquidity_2002} & year & Continuous & Compustat & Monthly \\
			41 & indmom & Industry momentum & \cite{moskowitz_industries_1999} & year & Continuous & Compustat & Monthly \\
			42 & invest & Capital expenditures and inventory & \cite{chen_better_2010} & year & Continuous & Compustat & Annual \\
			43 & lev & Leverage & \cite{bhandari_debt/equity_1988} & year & Continuous & Compustat & Annual \\
			44 & lgr & Growth in long-term debt & \cite{richardson_accrual_2005} & year & Continuous & Compustat & Annual \\
			45 & maxret & Maximum daily return & \cite{bali_maxing_2011} & year & Continuous & Compustat & Monthly \\
			46 & mom12m & 12-month momentum & \cite{jegadeesh_evidence_1990} & year & Continuous & Compustat & Monthly \\
			47 & mom1 & 1-month momentum & \cite{jegadeesh_returns_1993} & year & Continuous & Compustat & Monthly \\
			48 & mom36m & 36-month momentum & \cite{jegadeesh_returns_1993} & year & Continuous & Compustat & Monthly \\
			49 & mom6m & 6-month momentum & \cite{jegadeesh_returns_1993} & year & Continuous & Compustat & Monthly \\
			%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			50 & ms & Financial statement score & \cite{mohanram_separating_2005} & year & Continuous & Compustat & Quarterly \\
			51 & mvel1 & Size & \cite{banz_relationship_1981} & year & Continuous & Compustat & Monthly \\
			52 & mve\_ia & Industry-adjusted size & \cite{asness_predicting_2000} & year & Continuous & Compustat & Annual \\
			53 & nincr & Number of earnings increases & \cite{barth_market_1999} & year & Categorical & Compustat & Quarterly \\
			54 & operprof & Operating profitability & \cite{fama_five-factor_2015} & year & Continuous & Compustat & Annual \\
			55 & orgcap & Organizational capital & \cite{eisfeldt_organization_2013} & year & Continuous & Compustat & Annual \\
			56 & pchcapx\_ia & Industry adjusted \% change in capital expenditures & \cite{abarbanell_abnormal_1998} & year & Continuous & Compustat & Annual \\
			57 & pchcurrat & \% change in current ratio & \cite{ou_financial_1989} & year & Continuous & Compustat & Annual \\
			58 & pchdepr & \% change in depreciation & \cite{holthausen_prediction_1992} & year & Continuous & Compustat & Annual \\
			59 & pchgm\_pchsale & \% change in gross margin - \% change in sales & \cite{abarbanell_abnormal_1998} & year & Continuous & Compustat & Annual \\ \hline
			%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			60 & pchquick & \% change in quick ratio & \cite{ou_financial_1989} & year & Continuous & Compustat & Annual \\
			61 & pchsale\_pchinvt & \% change in sales - \% change in inventory & \cite{abarbanell_abnormal_1998} & year & Continuous & Compustat & Annual \\
			62 & pchsale\_pchrect & \% change in sales - \% change in A/R & \cite{abarbanell_abnormal_1998} & year & Continuous & Compustat & Annual \\
			63 & pchsale\_pchxsga & \% change in sales - \% change in SG&A & \cite{abarbanell_abnormal_1998} & year & Continuous & Compustat & Annual \\
			64 & pchsaleinv & \% change sales-to-inventory & \cite{ou_financial_1989} & year & Continuous & Compustat & Annual \\
			65 & pctacc & Percent accruals & \cite{hafzalla_percent_2011} & year & Continuous & Compustat & Annual \\
			66 & pricedelay & Price delay & \cite{hou_market_2005} & year & Continuous & Compustat & Monthly \\
			67 & ps & Financial statements score & \cite{piotroski_value_2000} & year & Categorical & Compustat & Annual \\
			68 & quick & Quick ratio & \cite{ou_financial_1989} & year & Continuous & Compustat & Annual \\
			69 & rd & R\&D increase & \cite{eberhart_examination_2004} & year & Continuous & Compustat & Annual \\ \hline
			%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			70 & rd\_mve & R\&D to market capitalization & \cite{guo_explaining_2006} & year & Continuous & Compustat & Annual \\
			71 & rd\_sale & R\&D to sales & \cite{guo_explaining_2006} & year & Continuous & Compustat & Annual \\
			72 & realestate & Real estate holdings & \cite{tuzel_corporate_2010} & year & Continuous & Compustat & Annual \\
			73 & retvol & Return volatility & \cite{ang_cross-section_2006} & year & Continuous & Compustat & Monthly \\
			74 & roaq & Return on assets & \cite{balakrishnan_post_2010} & year & Continuous & Compustat & Quarterly \\
			75 & roavol & Earnings volatility & cite & year & Continuous & Compustat & Quarterly \\
			76 & roeq & Return on equity & \cite{hou_digesting_2015} & year & Continuous & Compustat & Quarterly \\
			77 & roic & Return on invested capital & \cite{brown_productivity_2007} & year & Continuous & Compustat & Annual \\
			78 & rsup & Revenue surprise & cite & year & Continuous & Compustat & Quarterly \\
			79 & salecash & Sales to cash & \cite{ou_financial_1989} & year & Continuous & Compustat & Annual \\ \hline
			%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			80 & saleinv & Sales to inventory & \cite{ou_financial_1989} & year & Continuous & Compustat & Annual \\
			81 & salerec & Sales to receivables & \cite{ou_financial_1989} & year & Continuous & Compustat & Annual \\
			82 & secured & Secured debt & \cite{valta_strategic_2016} & year & Continuous & Compustat & Annual \\
			83 & securedind & Secured debt indicator & \cite{valta_strategic_2016} & year & Dummy & Compustat & Annual \\
			84 & sgr & Sales growth & \cite{barbee_jr_salesprice_1996} & year & Continuous & Compustat & Annual \\
			85 & sin & Sin stocks & \cite{hong_price_2009} & year & Dummy & Compustat & Annual \\
			86 & sp & Sales to price &  & year & Continuous & Compustat & Annual \\
			87 & std\_dolvol & Volatility of liquidity (dollar trading volume) & \cite{chordia_trading_2001} & year & Continuous & Compustat & Annual \\
			88 & std\_turn & Volatility of liquidity (share turnover) & \cite{chordia_trading_2001} & year & Continuous & Compustat & Monthly \\
			89 & stdacc & Accrual volatility & \cite{bandyopadhyay_accrual_2010} & year & Continuous & Compustat & Monthly \\ \hline
			%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
			90 & stdcf & Cashflow volatility & \cite{huang_cross_2009} & year & Continuous & Compustat & Quarterly \\
			91 & tang & Debt capacity/rm tangibility & \cite{almeida_financial_2007} & year & Continuous & Compustat & Quarterly \\
			92 & tb & Tax income to book income & \cite{lev_market-based_1982} & year & Continuous & Compustat & Annual \\
			93 & turn & Share turnover & \cite{datar_liquidity_1998} & year & Continuous & Compustat & Monthly \\
			94 & zerotrade & Zero trading days & \cite{liu_liquidity-augmented_2006} & year & Continuous & Compustat & Monthly \\	
		\end{longtable}
	\end{center}
\end{table}

\begin{table}
	\caption{Macroeconomic Factors}
	\begin{center}
	\begin{tabular}{lccc} \hline \hline
		No. & Acronym & Macroeconomic Factor \\ \hline \hline
		1 & macro\_dp & Dividend Price Ratio \\
		2 & macro\_ep & Earnings Price Ratio \\
		3 & macro\_bm & Book to Market Ratio \\
		4 & macro\_ntis & Net Equity Expansion \\
		5 & macro\_tbl & Treasury Bill Rate \\
		6 & macro\_tms & Term Spread \\
		7 & macro\_dfy & Default Spread \\
		8 & macro\_svar & Stock Variance \\
	\end{tabular}
	\end{center}
\end{table}

\subsection{Algorithms}
\label{Algorithms}

\subsubsection{Linear Models}

OLS used for fitting wrt MSE.

quantreg used for fitting wrt MAE. (minimizing 0.5 quantile loss is equivalent to minimizing mae).

\subsubsection{Penalized Linear}

package hqreg used for

\subsubsection{Classification and Regression Trees}

For full details of the Classification and Regression Tree algorithm see \cite{breiman_classification_1984}. 

\begin{algorithm}[H]
	\SetAlgoLined
	Initialize \;
	\For{$d$ from 1 to $L$}{
		\For{$i$ in ${C_l(d-1), l = 1, \dots, 2^{d-1}}$}{
			For each feature $j = 1, 2, \dots, P,$ and each threshold level $\alpha$, define a split as $s = (j, \alpha)$ which divides $C_l(d-1)$ into $C_{left}$ and $C_{right}$:
			\begin{equation*}
				C_{left}s = \{z_j \leq \alpha\} \cap C_l(d-1); C_{right}s = \{z_j > \alpha\} \cap C_l(d-1)
			\end{equation*}
			
			Define the impurity function:
			\begin{equation*}
				\mathcal{L}(C, C_{left}, C_{right}) = \frac{|C_{left}|}{|C|}H(C_{left}) + \frac{|C_{right}|}{|C|}H(C_{right})
			\end{equation*}
			where
			\begin{equation*}
			H(C) = \frac{1}{|C|} \sum_{ }^{z_{i,t}\in C}(r_{i,t+1}-\theta)^2, \theta = \frac{1}{|C|} \sum_{z_{i,t}\in C}^{ }r_{i,t+1}
			\end{equation*}
			and $|C|$ denotes the number of observations in set C
			
			Find the optimal split
			\begin{equation*}
				s^* \leftarrow \underset{s}{argmin}\mathcal{L}(C(s),C_{left}(s),C_{right}(s))
			\end{equation*}
			Update nodes (partition the data):
			\begin{equation*}
				C_{2l-1}(d) \leftarrow C_{left}(s^*), C_{2l}(d) \leftarrow C_{right}(s^*)
			\end{equation*}
		}
	}
	\KwResult{The prediction of a regression tree is:
	\begin{equation*}
		g(z_{i,t};\theta,L) = \sum_{k=1}^{2^L}\theta_k\textbf{1}_{z_{i,t}\in C_k(L)}; \theta_k = \frac{1}{|C_{k}(L)|} \sum_{z_{i,t}\in C_k(L)}^{ }r_{i,t+1}
	\end{equation*}
	}
	\caption{Classification and Regression Tree}
\end{algorithm}

\subsubsection{Random Forest}

For full details of the Random Forest algorithm see \cite{breiman_random_2001}. 

\begin{algorithm}[H]
	\SetAlgoLined
	\For{$b$ from $1$ to $B$}{
		Draw bootstrap samples {$(z_{i,t},r_{i,t+1}),(i,t) \in Bootstrap(b)$} from the dataset\
		Grow a tree $T_b$ using Algorithm, using only a random subsample, say $\sqrt{P}$ of all features \
		Denote the resulting $bth$ tree as
		\begin{equation*}
			\hat{g}_b (z_{i,t},\hat{\theta}_b, L) = \sum_{k=1}^{2^L}\theta_b^k\textbf{1}_{z_{i,t}\in C_k(L)}
		\end{equation*}
	}
	\KwResult{The final random forest prediction is given by the output of all trees:
		\begin{equation*}
			\hat{g}_b (z_{i,t}; L, B) = \frac{1}{B} \sum_{b=1}^B \hat{g}_b (z_{i,t},\hat{\theta}_b, L)
		\end{equation*}
	}
	\caption{Random Forest}
\end{algorithm}

\subsubsection{Neural Networks}

Fit using keras package (cite)

ADAM algorithm for stochastic gradient descent and learning rate shrinkage as detailed by \cite{kingma_adam:_2014}.

\begin{algorithm}
	\SetAlgoLined
	Initialize $j = 0$, $\epsilon = \infty$ and select the patience parameter $p$ (max iterations)\
	
	\While{j < p}{
		Update $\theta$ using the training algorithm\
		Calculate the prediction error from the validation sample, denoted as \(\epsilon'\)\
		
		\eIf{\(\epsilon' < \epsilon\)}
			{\(j \leftarrow 0\)\
				
			 \(\epsilon \leftarrow \epsilon'\)\
			 
		     \(\theta' \leftarrow \theta\)}
	     	{\(j \leftarrow j+1\)}
	}
	\KwResult{$\theta'$ is the final parameter estimate}
	\caption{Early stopping via validation}
\end{algorithm}

Batch Normalization Algorithm as detailed by \cite{ioffe_batch_2015}.

\begin{algorithm}
	Input: Values of \(x\) for each activation over a batch \(\mathcal{B} = {x_1, x_2, \dots, x_N}\)
	
	\(\mu_\mathcal{B} \leftarrow \frac{1}{N} \sum_{i = 1}^{N}x_i\)
	
	\(\sigma_\mathcal{B}^2 \leftarrow \frac{1}{N} \sum_{i = 1}^{N}(x_i - \mu_\mathcal{B})^2\)
	
	\(\hat{x_i} \leftarrow \frac{x_i - \mu_\mathcal{B}}{\sqrt{\sigma_\mathcal{B}^2 + \epsilon}}\)
	
	\(y_i \leftarrow \gamma\hat{x_i} + \beta := BN_{\gamma, \beta}(x_i)\)
	
	\KwResult{\(y_i = BN_{\gamma, \beta}(x_i) : i = 1, 2, ..., N\)}
	\caption{Batch Normalization for one activation over one batch}
\end{algorithm}

\subsubsection{Tuning of Simulated Datasets}

The simulated datasets were tuned according to three statistics: average individual time series R squared, average annualized volatility, and cross sectional R squared. 

The methodology for evaluating average time series R squared and cross sectional R squared is consistent with that detailed by \cite{cochrane_asset_2005}. The steps are reproduced here for reference; for complete details refer to \cite{cochrane_asset_2005}.

First evaluate the following OLS model:

\begin{equation}
	R_{it} = a_i + \beta_i' f_{it} + \epsilon_{it} 
\end{equation}

where $f_{it}$ represents the \textit{true} factors in the returns process. The corresponding R-squared value for this time series regression is calculated across all stocks and averaged.

A cross ssectional regression for the risk premia is then run across assets of average returns on the factor coefficients:

\begin{equation}
	\bar{R_{it}} = \alpha_i = \beta_i' \lambda
\end{equation}

where the $\beta_i'$ are the estimated coefficients from the time series regressions earlier.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%BIBLIOGRAPHY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{jfe}
\bibliography{Bibliography}

\end{document}