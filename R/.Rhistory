auto_ets_model <- ets(univariate_time_series)
# TBATS
tbats_model <- tbats(univariate_time_series)
# Neural Network time series forecasts
nnetar_model <- nnetar(univariate_time_series)
# Naive model that forecasts 0
# Neat idea, but practically speaking ends up being the sam eas auto arima's 0, 0, 0 model most of the time
# naive0_model <- rep(0, 12)
# mse(as.vector(univariate_time_series_test), naive0_model)
# ARMA 1, 1 with GARCH 1, 1 gaussian errors
ugarch_spec <- ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(1, 1),
include.mean = TRUE,
external.regressors = NULL),
distribution.model = "norm")
ugarch_spec_fit <- ugarchfit(ugarch_spec, data = univariate_time_series, out.sample = 12,
solver.control=list(trace = 1))
ugarch_forecast <- ugarchforecast(ugarch_spec_fit, n.ahead = 12, n.roll = 11)
## Stochastic volatility model
## Theoretically the most correctly specified model, but very computatioally intensive, and may be infeasible
## Takes ~ 14 seconds to estimate
#stochvol_model <- svlsample(univariate_time_series, draws = 10000, burnin = 1000, designmatrix = "ar1",
#priormu = c(0, 100), priorphi = c(5, 1.5), priorsigma = 1,
#priorrho = c(4, 4), priorbeta = c(0, 10000), thinpara = 1,
#thinlatent = 1, thintime = NULL, keeptime = "all", quiet = TRUE)
## Put errors into a single row
errors <- data.frame(naive = mse(as.vector(univariate_time_series_test), predict(naive_model)$mean),
random_walk = mse(as.vector(univariate_time_series_test), predict(random_walk_model)$mean),
theta = mse(as.vector(univariate_time_series_test), predict(theta_model)$mean),
auto_arima = mse(as.vector(univariate_time_series_test),
forecast(auto_arima_model, h = 12)$mean),
ets = mse(as.vector(univariate_time_series_test), forecast(auto_ets_model, h = 12)$mean),
tbats = mse(as.vector(univariate_time_series_test), forecast(tbats_model, h = 12)$mean),
nnetar = mse(as.vector(univariate_time_series_test), forecast(nnetar_model, h = 12)$mean),
garch_11 = mse(as.vector(univariate_time_series_test), fitted(ugarch_forecast)[1, ]))
#stochvol = mse(as.vector(univariate_time_series_test),
#apply(X = predict(stochvol_model, steps = 12)$y, MARGIN = 2, FUN = mean)))
errors
}
foreach(i = 1:length(unique(pooled_panel$stock)), .combine = "rbind") %dopar% {
## Filter Data first
stock_id <- unique(pooled_panel$stock)
univariate_time_series <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$train | time %in% timeSlices[[1]]$validation) %>%
select(rt) %>%
ts()
univariate_time_series_test <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$test) %>%
select(rt) %>%
ts()
## Estimation of consituent models
# Naive
naive_model <- naive(univariate_time_series, h = 12)
# Random walk with drift
random_walk_model <- rwf(univariate_time_series, h = 12, drift = TRUE)
# Seasonal Naive, this ends up being the same as naive
seasonal_naive_model <- snaive(univariate_time_series, h = 12)
# Theta Method
theta_model <- thetaf(univariate_time_series, h = 12)
## Auto arima
auto_arima_model <- auto.arima(univariate_time_series)
# Auto ETS
auto_ets_model <- ets(univariate_time_series)
# TBATS
tbats_model <- tbats(univariate_time_series)
# Neural Network time series forecasts
nnetar_model <- nnetar(univariate_time_series)
# Naive model that forecasts 0
# Neat idea, but practically speaking ends up being the sam eas auto arima's 0, 0, 0 model most of the time
# naive0_model <- rep(0, 12)
# mse(as.vector(univariate_time_series_test), naive0_model)
# ARMA 1, 1 with GARCH 1, 1 gaussian errors
ugarch_spec <- ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(1, 1),
include.mean = TRUE,
external.regressors = NULL),
distribution.model = "norm")
ugarch_spec_fit <- ugarchfit(ugarch_spec, data = univariate_time_series, out.sample = 12,
solver.control = list(tol = 1e-12))
ugarch_forecast <- ugarchforecast(ugarch_spec_fit, n.ahead = 12, n.roll = 11)
## Stochastic volatility model
## Theoretically the most correctly specified model, but very computatioally intensive, and may be infeasible
## Takes ~ 14 seconds to estimate
#stochvol_model <- svlsample(univariate_time_series, draws = 10000, burnin = 1000, designmatrix = "ar1",
#priormu = c(0, 100), priorphi = c(5, 1.5), priorsigma = 1,
#priorrho = c(4, 4), priorbeta = c(0, 10000), thinpara = 1,
#thinlatent = 1, thintime = NULL, keeptime = "all", quiet = TRUE)
## Put errors into a single row
errors <- data.frame(naive = mse(as.vector(univariate_time_series_test), predict(naive_model)$mean),
random_walk = mse(as.vector(univariate_time_series_test), predict(random_walk_model)$mean),
theta = mse(as.vector(univariate_time_series_test), predict(theta_model)$mean),
auto_arima = mse(as.vector(univariate_time_series_test),
forecast(auto_arima_model, h = 12)$mean),
ets = mse(as.vector(univariate_time_series_test), forecast(auto_ets_model, h = 12)$mean),
tbats = mse(as.vector(univariate_time_series_test), forecast(tbats_model, h = 12)$mean),
nnetar = mse(as.vector(univariate_time_series_test), forecast(nnetar_model, h = 12)$mean),
garch_11 = mse(as.vector(univariate_time_series_test), fitted(ugarch_forecast)[1, ]))
#stochvol = mse(as.vector(univariate_time_series_test),
#apply(X = predict(stochvol_model, steps = 12)$y, MARGIN = 2, FUN = mean)))
errors
}
foreach(i = 1:length(unique(pooled_panel$stock)), .combine = "rbind") %dopar% {
## Filter Data first
stock_id <- unique(pooled_panel$stock)
univariate_time_series <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$train | time %in% timeSlices[[1]]$validation) %>%
select(rt) %>%
ts()
univariate_time_series_test <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$test) %>%
select(rt) %>%
ts()
## Estimation of consituent models
# Naive
naive_model <- naive(univariate_time_series, h = 12)
# Random walk with drift
random_walk_model <- rwf(univariate_time_series, h = 12, drift = TRUE)
# Seasonal Naive, this ends up being the same as naive
seasonal_naive_model <- snaive(univariate_time_series, h = 12)
# Theta Method
theta_model <- thetaf(univariate_time_series, h = 12)
## Auto arima
auto_arima_model <- auto.arima(univariate_time_series)
# Auto ETS
auto_ets_model <- ets(univariate_time_series)
# TBATS
tbats_model <- tbats(univariate_time_series)
# Neural Network time series forecasts
nnetar_model <- nnetar(univariate_time_series)
# Naive model that forecasts 0
# Neat idea, but practically speaking ends up being the sam eas auto arima's 0, 0, 0 model most of the time
# naive0_model <- rep(0, 12)
# mse(as.vector(univariate_time_series_test), naive0_model)
# ARMA 1, 1 with GARCH 1, 1 gaussian errors
ugarch_spec <- ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(1, 1),
include.mean = TRUE,
external.regressors = NULL),
distribution.model = "norm")
ugarch_spec_fit <- ugarchfit(ugarch_spec, data = univariate_time_series, out.sample = 12,
solver = "hybrid",
solver.control = list(tol = 1e-12))
ugarch_forecast <- ugarchforecast(ugarch_spec_fit, n.ahead = 12, n.roll = 11)
## Stochastic volatility model
## Theoretically the most correctly specified model, but very computatioally intensive, and may be infeasible
## Takes ~ 14 seconds to estimate
#stochvol_model <- svlsample(univariate_time_series, draws = 10000, burnin = 1000, designmatrix = "ar1",
#priormu = c(0, 100), priorphi = c(5, 1.5), priorsigma = 1,
#priorrho = c(4, 4), priorbeta = c(0, 10000), thinpara = 1,
#thinlatent = 1, thintime = NULL, keeptime = "all", quiet = TRUE)
## Put errors into a single row
errors <- data.frame(naive = mse(as.vector(univariate_time_series_test), predict(naive_model)$mean),
random_walk = mse(as.vector(univariate_time_series_test), predict(random_walk_model)$mean),
theta = mse(as.vector(univariate_time_series_test), predict(theta_model)$mean),
auto_arima = mse(as.vector(univariate_time_series_test),
forecast(auto_arima_model, h = 12)$mean),
ets = mse(as.vector(univariate_time_series_test), forecast(auto_ets_model, h = 12)$mean),
tbats = mse(as.vector(univariate_time_series_test), forecast(tbats_model, h = 12)$mean),
nnetar = mse(as.vector(univariate_time_series_test), forecast(nnetar_model, h = 12)$mean),
garch_11 = mse(as.vector(univariate_time_series_test), fitted(ugarch_forecast)[1, ]))
#stochvol = mse(as.vector(univariate_time_series_test),
#apply(X = predict(stochvol_model, steps = 12)$y, MARGIN = 2, FUN = mean)))
errors
}
foreach(i = 1:length(unique(pooled_panel$stock)), .combine = "rbind") %dopar% {
## Filter Data first
stock_id <- unique(pooled_panel$stock)
univariate_time_series <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$train | time %in% timeSlices[[1]]$validation) %>%
select(rt) %>%
ts()
univariate_time_series_test <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$test) %>%
select(rt) %>%
ts()
## Estimation of consituent models
# Naive
naive_model <- naive(univariate_time_series, h = 12)
# Random walk with drift
random_walk_model <- rwf(univariate_time_series, h = 12, drift = TRUE)
# Seasonal Naive, this ends up being the same as naive
seasonal_naive_model <- snaive(univariate_time_series, h = 12)
# Theta Method
theta_model <- thetaf(univariate_time_series, h = 12)
## Auto arima
auto_arima_model <- auto.arima(univariate_time_series)
# Auto ETS
auto_ets_model <- ets(univariate_time_series)
# TBATS
tbats_model <- tbats(univariate_time_series)
# Neural Network time series forecasts
nnetar_model <- nnetar(univariate_time_series)
# Naive model that forecasts 0
# Neat idea, but practically speaking ends up being the sam eas auto arima's 0, 0, 0 model most of the time
# naive0_model <- rep(0, 12)
# mse(as.vector(univariate_time_series_test), naive0_model)
# ARMA 1, 1 with GARCH 1, 1 gaussian errors
ugarch_spec <- ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(1, 1),
include.mean = TRUE,
external.regressors = NULL),
distribution.model = "norm")
ugarch_spec_fit <- ugarchfit(ugarch_spec, data = univariate_time_series, out.sample = 12,
solver = "hybrid")
ugarch_forecast <- ugarchforecast(ugarch_spec_fit, n.ahead = 12, n.roll = 11)
## Stochastic volatility model
## Theoretically the most correctly specified model, but very computatioally intensive, and may be infeasible
## Takes ~ 14 seconds to estimate
#stochvol_model <- svlsample(univariate_time_series, draws = 10000, burnin = 1000, designmatrix = "ar1",
#priormu = c(0, 100), priorphi = c(5, 1.5), priorsigma = 1,
#priorrho = c(4, 4), priorbeta = c(0, 10000), thinpara = 1,
#thinlatent = 1, thintime = NULL, keeptime = "all", quiet = TRUE)
## Put errors into a single row
errors <- data.frame(naive = mse(as.vector(univariate_time_series_test), predict(naive_model)$mean),
random_walk = mse(as.vector(univariate_time_series_test), predict(random_walk_model)$mean),
theta = mse(as.vector(univariate_time_series_test), predict(theta_model)$mean),
auto_arima = mse(as.vector(univariate_time_series_test),
forecast(auto_arima_model, h = 12)$mean),
ets = mse(as.vector(univariate_time_series_test), forecast(auto_ets_model, h = 12)$mean),
tbats = mse(as.vector(univariate_time_series_test), forecast(tbats_model, h = 12)$mean),
nnetar = mse(as.vector(univariate_time_series_test), forecast(nnetar_model, h = 12)$mean),
garch_11 = mse(as.vector(univariate_time_series_test), fitted(ugarch_forecast)[1, ]))
#stochvol = mse(as.vector(univariate_time_series_test),
#apply(X = predict(stochvol_model, steps = 12)$y, MARGIN = 2, FUN = mean)))
errors
}
errors <- foreach(i = 1:length(unique(pooled_panel$stock)), .combine = "rbind") %dopar% {
## Filter Data first
stock_id <- unique(pooled_panel$stock)
univariate_time_series <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$train | time %in% timeSlices[[1]]$validation) %>%
select(rt) %>%
ts()
univariate_time_series_test <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$test) %>%
select(rt) %>%
ts()
## Estimation of consituent models
# Naive
naive_model <- naive(univariate_time_series, h = 12)
# Random walk with drift
random_walk_model <- rwf(univariate_time_series, h = 12, drift = TRUE)
# Seasonal Naive, this ends up being the same as naive
seasonal_naive_model <- snaive(univariate_time_series, h = 12)
# Theta Method
theta_model <- thetaf(univariate_time_series, h = 12)
## Auto arima
auto_arima_model <- auto.arima(univariate_time_series)
# Auto ETS
auto_ets_model <- ets(univariate_time_series)
# TBATS
tbats_model <- tbats(univariate_time_series)
# Neural Network time series forecasts
nnetar_model <- nnetar(univariate_time_series)
# Naive model that forecasts 0
# Neat idea, but practically speaking ends up being the sam eas auto arima's 0, 0, 0 model most of the time
# naive0_model <- rep(0, 12)
# mse(as.vector(univariate_time_series_test), naive0_model)
# ARMA 1, 1 with GARCH 1, 1 gaussian errors
ugarch_spec <- ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
submodel = NULL,
external.regressors = NULL,
variance.targeting = FALSE),
mean.model     = list(armaOrder = c(1, 1),
include.mean = TRUE,
external.regressors = NULL),
distribution.model = "norm")
ugarch_spec_fit <- ugarchfit(ugarch_spec, data = univariate_time_series, out.sample = 12,
solver = "hybrid")
ugarch_forecast <- ugarchforecast(ugarch_spec_fit, n.ahead = 12, n.roll = 11)
## Stochastic volatility model
## Theoretically the most correctly specified model, but very computatioally intensive, and may be infeasible
## Takes ~ 14 seconds to estimate
#stochvol_model <- svlsample(univariate_time_series, draws = 10000, burnin = 1000, designmatrix = "ar1",
#priormu = c(0, 100), priorphi = c(5, 1.5), priorsigma = 1,
#priorrho = c(4, 4), priorbeta = c(0, 10000), thinpara = 1,
#thinlatent = 1, thintime = NULL, keeptime = "all", quiet = TRUE)
## Put errors into a single row
errors <- data.frame(naive = mse(as.vector(univariate_time_series_test), predict(naive_model)$mean),
random_walk = mse(as.vector(univariate_time_series_test), predict(random_walk_model)$mean),
theta = mse(as.vector(univariate_time_series_test), predict(theta_model)$mean),
auto_arima = mse(as.vector(univariate_time_series_test),
forecast(auto_arima_model, h = 12)$mean),
ets = mse(as.vector(univariate_time_series_test), forecast(auto_ets_model, h = 12)$mean),
tbats = mse(as.vector(univariate_time_series_test), forecast(tbats_model, h = 12)$mean),
nnetar = mse(as.vector(univariate_time_series_test), forecast(nnetar_model, h = 12)$mean),
garch_11 = mse(as.vector(univariate_time_series_test), fitted(ugarch_forecast)[1, ]))
#stochvol = mse(as.vector(univariate_time_series_test),
#apply(X = predict(stochvol_model, steps = 12)$y, MARGIN = 2, FUN = mean)))
errors
}
which.min(errors)
which.min(errors[1, ])
which.min(errors[2, ])
foreach(1 = i:nrow(errors), .combine = "rbind") %dopar% {
foreach(i = 1:nrow(errors), .combine = "rbind") %dopar% {
which.min(errors[2, ])
}
which.min(errors[1, ])
which.min(errors[2, ])
which.min(errors[3, ])
which.min(errors[4, ])
as.numeric(which.min(errors[2, ]))
foreach(i = 1:nrow(errors), .combine = "rbind") %dopar% {
as.numeric(which.min(errors[2, ]))
}
which.min(errors[i, ])
foreach(i = 1:nrow(errors), .combine = "rbind") %dopar% {
which.min(errors[i, ])
}
foreach(i = 1:nrow(errors), .combine = "rbind") %dopar% {
as.numeric(which.min(errors[i, ]))
}
labels <- foreach(i = 1:nrow(errors), .combine = "rbind") %dopar% {
as.numeric(which.min(errors[i, ]))
}
View(labels)
labels <- foreach(i = 1:nrow(errors), .combine = "rbind") %dopar% {
data.frame(label = which.min(errors[i, ]))
}
View(labels)
train_list <- list(
data = data,
errors = errors,
labels = labels
)
View(train_list)
### Data matrix
# Just use fforma_features function from before, easy
data <- fforma_features(univariate_time_series)
fforma_features <- function(time_series) {
cbind(
# Series length
length = length(time_series),
# nperiods, seasonal_period, trend, seasonality, linearity, curvature, spikiness e_acr1 and e_acf10
tsfeatures(time_series, features = "stl_features"),
# Stability
tsfeatures(time_series, features = "stability"),
# Lumpiness
tsfeatures(time_series, features = "lumpiness"),
# Hurst
tsfeatures(time_series, features = "hurst"),
# Nonlinearity
tsfeatures(time_series, features = "nonlinearity"),
# Holt alpha and beta
tsfeatures(time_series, features = "holt_parameters"),
# HW alpha and beta, only applies for seasonal time series
#tsfeatures(time_series, features = "hw_parameters"),
# Unitroot statistics
tsfeatures(time_series, features = c("unitroot_kpss", "unitroot_pp")),
# ACF features
tsfeatures(time_series, features = "acf_features"),
# PACF features
tsfeatures(time_series, features = "pacf_features"),
# Crossing point
tsfeatures(time_series, features = "crossing_points"),
# flat_spots
tsfeatures(time_series, features = "flat_spots"),
# arch_lm
tsfeatures(time_series, features = "arch_stat"),
# Heterogeneity
tsfeatures(time_series, features = "heterogeneity")
)
}
# Test, works perfectly
fforma_features(univariate_time_series)
### Data matrix
# Just use fforma_features function from before, easy
data <- foreach(i = 1:length(unique(pooled_panel$stock)), .combine = "rbind") %dopar% {
stock_id <- unique(pooled_panel$stock)
univariate_time_series <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$train | time %in% timeSlices[[1]]$validation) %>%
select(rt) %>%
ts()
univariate_time_series_test <- pooled_panel %>%
filter(stock == stock_id[i]) %>%
filter(time %in% timeSlices[[1]]$test) %>%
select(rt) %>%
ts()
fforma_features(univariate_time_series)
}
View(data)
train_list <- list(
data = data,
errors = errors,
labels = labels
)
View(train_list)
knitr::opts_chunk$set(echo = TRUE)
################
##Load Libraries
################
library(speedglm)
library(tidyverse)
library(keras)
library(ggplot2)
library(forecast)
library(rlist)
library(Metrics)
library(tensorflow)
library(quantreg)
library(randomForestSRC)
library(hqreg)
library(caret)
library(tsfeatures)
## Vector arima/garch packages
library(kernlab)
library(xts)
library(tsne)
library(rmgarch)
library(marima)
library(xgboost)
#Parallel Computing
library(foreach)
library(doFuture)
#Registering
registerDoFuture()
plan(multisession)
## Load Simulated Data
pooled_panel <- readRDS("pooled_panel.rds")
## Load empirical data
empirical_panel <- readRDS("final_dataset.rds")
empirical_panel_no_interaction <- readRDS("final_dataset_no_interaction.rds")
pooled_panel_tsne <- tsne(as.matrix(pooled_panel[, -(1:3)]))
install.packages("umap")
library(umap)
pooled_panel_umap <- umap(pooled_panel[, -(1:3)])
install.packages("uwot")
library(uwot)
library(uwot)
?umap
pooled_panel_umap <- umap(pooled_panel[, -(1:3)],
n_threads = 16)
pooled_panel_umap
?uwot
plot(pooled_panel_umap)
pooled_panel_uni_umap <- umap(pooled_panel_uni[, -(1:3)],
n_threads = 12)
simulation_stock_id <- unique(pooled_panel$stock)
pooled_panel_uni <- pooled_panel %>%
filter(stock == "stock_1")
simulation_stock_id <- unique(pooled_panel$stock)
pooled_panel_uni <- pooled_panel %>%
filter(stock == "stock_1")
pooled_panel_uni_umap <- umap(pooled_panel_uni[, -(1:3)],
n_threads = 12)
plot(pooled_panel_uni_umap)
### Empirical Data
empirical_panel_no_interaction_umap <- umap(empirical_panel_no_interaction[, -(1:3)],
n_threads = 12)
?x2set
### Empirical Data
empirical_panel_no_interaction_umap <- umap(empirical_panel_no_interaction[, -(1:3)],
n_threads = 12)
summary(empirical_panel_no_interaction[, -(1:3))
summary(empirical_panel_no_interaction[, -(1:3)])
### Empirical Data
# Problem with this dataset: some columns are constant
col_var <- is.na(apply(empirical_panel_no_interaction, 2, var))
### Empirical Data
# Problem with this dataset: some columns are constant
col_var <- is.na(apply(empirical_panel_no_interaction, 2, var))
empirical_panel_no_interaction <- empirical_panel_no_interaction[, !col_var]
empirical_panel_no_interaction_umap <- umap(empirical_panel_no_interaction[, -(1:3)],
n_threads = 12)
plot(empirical_panel_no_interaction_umap)
## Using the entire panel
# Change tol to higher fractions to automatically choose a lower number of PCs to keep
pooled_panel_pca <- prcomp(pooled_panel[, -(1:3)], center = TRUE, scale. = TRUE, tol = 0.2)
# Plot explained variances
# Not very good at projecting into a lower dimensional space
plot(pooled_panel_pca)
?prcomp
pooled_panel_pca$x
predict(pooled_panel_pca) %>%
ggplot() +
geom_point(aes(x = PC1, y = PC2))
predict(pooled_panel_pca)
predict(pooled_panel_pca) %>%
dataframe() %>%
ggplot() +
geom_point(aes(x = PC1, y = PC2))
predict(pooled_panel_pca) %>%
data.frame() %>%
ggplot() +
geom_point(aes(x = PC1, y = PC2))
