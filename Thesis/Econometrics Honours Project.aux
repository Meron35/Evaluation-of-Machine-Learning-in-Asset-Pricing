\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Topic}{2}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Background Literature and Motivations}{2}{subsection.1.2}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:}  Data skepticism (have you set up the data properly?) Show/highlight non-robustness of ML methods Skepticism of validity of methods that include non-stationary factors (like dividend yield) Check validity via simulation methods Methods to consider: OLS, Elasticnet, RF, NN See how it performs on real data}{2}{section*.3}}
\pgfsyspdfmark {pgfid1}{4736286}{9877777}
\pgfsyspdfmark {pgfid4}{36994278}{9890065}
\pgfsyspdfmark {pgfid5}{38845670}{9666151}
\citation{vuolteenaho_understanding_1999}
\citation{lettau_consumption_2001}
\citation{schwert_anomalies_2003}
\citation{hsu_finding_2014}
\citation{harvey__2016}
\citation{harvey_census_2019}
\citation{kozak_shrinking_2017}
\citation{rapach_forecasting_2013}
\citation{freyberger_dissecting_2017}
\citation{gu_empirical_2018}
\citation{hsu_finding_2014}
\citation{feng_deep_2018}
\citation{gu_empirical_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Main Findings}{3}{subsection.1.3}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} Pending}{3}{section*.4}}
\pgfsyspdfmark {pgfid6}{4736286}{21086450}
\pgfsyspdfmark {pgfid9}{36994278}{21098738}
\pgfsyspdfmark {pgfid10}{38845670}{20874824}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Limitations of Machine Learning}{3}{subsection.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methodology}{4}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Overall Model Design}{4}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Sample Splitting}{4}{subsection.2.2}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} insert a picture of how the windows work from say caret documentation, would be great}{4}{section*.5}}
\pgfsyspdfmark {pgfid11}{5719326}{10642541}
\pgfsyspdfmark {pgfid14}{36994278}{10654829}
\pgfsyspdfmark {pgfid15}{38845670}{10430915}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Loss Function}{4}{subsection.2.3}}
\citation{huber_robust_1992}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of MAE, MSE and Huber Loss when $\xi = 1$}}{5}{figure.1}}
\newlabel{fig:loss_functions}{{1}{5}{Illustration of MAE, MSE and Huber Loss when $\xi = 1$}{figure.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Mean Absolute Error}{5}{subsubsection.2.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Mean Squared Error and Root Mean Squared Error}{5}{subsubsection.2.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Huber Loss}{5}{subsubsection.2.3.3}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} cite something about outliers in financial data}{5}{section*.6}}
\pgfsyspdfmark {pgfid18}{5719326}{4952034}
\pgfsyspdfmark {pgfid21}{36994278}{4964322}
\pgfsyspdfmark {pgfid22}{38845670}{4740408}
\citation{zou_regularization_2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Linear Model}{6}{subsection.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Penalized Linear Model}{6}{subsection.2.5}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} update when algorithm is written}{6}{section*.7}}
\pgfsyspdfmark {pgfid23}{5719326}{14696599}
\pgfsyspdfmark {pgfid26}{36994278}{14708887}
\pgfsyspdfmark {pgfid27}{38845670}{14484973}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Classification and Regression Trees}{6}{subsection.2.6}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} this diagram needs work}{7}{section*.8}}
\pgfsyspdfmark {pgfid28}{5719326}{21820594}
\pgfsyspdfmark {pgfid31}{36994278}{21832882}
\pgfsyspdfmark {pgfid32}{38845670}{21608968}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Random Forests}{7}{subsection.2.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Neural Networks}{7}{subsection.2.8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.1}Introduction}{7}{subsubsection.2.8.1}}
\citation{masters_practical_1993}
\citation{lecun_deep_2015}
\citation{ramachandran_searching_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Neural Network 5 (most complex considered)}}{8}{figure.2}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} would be best to customize neuron text}{8}{section*.9}}
\pgfsyspdfmark {pgfid44}{5719326}{14380307}
\pgfsyspdfmark {pgfid47}{36994278}{14392595}
\pgfsyspdfmark {pgfid48}{38845670}{14168681}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2}Activation Function}{8}{subsubsection.2.8.2}}
\citation{choromanska_loss_2014}
\citation{ioffe_batch_2015}
\citation{hansen_neural_1990}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.3}Computation}{9}{subsubsection.2.8.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.4}Batch Normalization}{9}{subsubsection.2.8.4}}
\citation{gu_empirical_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Simulation Design}{10}{subsection.2.9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.1}Overall Design}{10}{subsubsection.2.9.1}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} justify properly}{10}{section*.10}}
\pgfsyspdfmark {pgfid50}{4736286}{45199934}
\pgfsyspdfmark {pgfid53}{36994278}{45212222}
\pgfsyspdfmark {pgfid54}{38845670}{44988308}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.2}Simulating Characteristics}{10}{subsubsection.2.9.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.3}Simulating Macroeconomic Series}{11}{subsubsection.2.9.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.4}Simulating Return Series}{11}{subsubsection.2.9.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.5}Sample Splitting}{11}{subsubsection.2.9.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10}Model Evaluation}{11}{subsection.2.10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.10.1}R Squared}{11}{subsubsection.2.10.1}}
\citation{diebold_comparing_2002}
\citation{harvey_testing_1997}
\citation{breiman_classification_2017}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.10.2}Diebold-Mariano Test}{12}{subsubsection.2.10.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11}Variable Importance}{12}{subsection.2.11}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} Pending}{12}{section*.11}}
\pgfsyspdfmark {pgfid55}{4736286}{26918297}
\pgfsyspdfmark {pgfid58}{36994278}{26930585}
\pgfsyspdfmark {pgfid59}{38845670}{26706671}
\@writefile{toc}{\contentsline {section}{\numberline {3}Study}{12}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data}{12}{subsection.3.1}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} Pending}{12}{section*.12}}
\pgfsyspdfmark {pgfid60}{4736286}{19065074}
\pgfsyspdfmark {pgfid63}{36994278}{19077362}
\pgfsyspdfmark {pgfid64}{38845670}{18853448}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Model}{12}{subsection.3.2}}
\citation{breiman_random_2001}
\@writefile{toc}{\contentsline {section}{\numberline {4}Appendix}{13}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Algorithms}{13}{subsection.4.1}}
\newlabel{Algorithms}{{4.1}{13}{Algorithms}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Penalized Linear}{13}{subsubsection.4.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Classification and Regression Trees}{13}{subsubsection.4.1.2}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Classification and Regression Tree}}{13}{algocf.1}}
\citation{kingma_adam:_2014}
\bibstyle{jfe}
\bibdata{Bibliography}
\bibcite{breiman_random_2001}{{1}{2001}{{Breiman}}{{}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Random Forest}{14}{subsubsection.4.1.3}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Random Forest}}{14}{algocf.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Neural Networks}{14}{subsubsection.4.1.4}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{green!30}{\leavevmode {\color  {green!30}o}}\ {\bf  RS:} research different types of algorithms. Paper used ADAM}{14}{section*.13}}
\pgfsyspdfmark {pgfid65}{5719326}{30914955}
\pgfsyspdfmark {pgfid68}{36994278}{30927243}
\pgfsyspdfmark {pgfid69}{38845670}{30703329}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Early stopping via validation}}{14}{algocf.3}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Batch Normalization for one activation over one batch}}{14}{algocf.4}}
\bibcite{breiman_classification_2017}{{2}{2017}{{Breiman}}{{}}}
\bibcite{choromanska_loss_2014}{{3}{2014}{{Choromanska et~al.}}{{Choromanska, Henaff, Mathieu, Arous, and LeCun}}}
\bibcite{diebold_comparing_2002}{{4}{2002}{{Diebold and Mariano}}{{}}}
\bibcite{feng_deep_2018}{{5}{2018}{{Feng et~al.}}{{Feng, He, and Polson}}}
\bibcite{freyberger_dissecting_2017}{{6}{2017}{{Freyberger et~al.}}{{Freyberger, Neuhierl, and Weber}}}
\bibcite{gu_empirical_2018}{{7}{2018}{{Gu et~al.}}{{Gu, Kelly, and Xiu}}}
\bibcite{hansen_neural_1990}{{8}{1990}{{Hansen and Salamon}}{{}}}
\bibcite{harvey_census_2019}{{9}{2019}{{Harvey and Liu}}{{}}}
\bibcite{harvey__2016}{{10}{2016}{{Harvey et~al.}}{{Harvey, Liu, and Zhu}}}
\bibcite{harvey_testing_1997}{{11}{1997}{{Harvey et~al.}}{{Harvey, Leybourne, and Newbold}}}
\bibcite{hsu_finding_2014}{{12}{2014}{{Hsu and Kalesnik}}{{}}}
\bibcite{huber_robust_1992}{{13}{1992}{{Huber}}{{}}}
\bibcite{ioffe_batch_2015}{{14}{2015}{{Ioffe and Szegedy}}{{}}}
\bibcite{kingma_adam:_2014}{{15}{2014}{{Kingma and Ba}}{{}}}
\bibcite{kozak_shrinking_2017}{{16}{2017}{{Kozak et~al.}}{{Kozak, Nagel, and Santosh}}}
\bibcite{lecun_deep_2015}{{17}{2015}{{Lecun et~al.}}{{Lecun, Bengio, and Hinton}}}
\bibcite{lettau_consumption_2001}{{18}{2001}{{Lettau and Ludvigson}}{{}}}
\bibcite{masters_practical_1993}{{19}{1993}{{Masters}}{{}}}
\bibcite{ramachandran_searching_2017}{{20}{2017}{{Ramachandran et~al.}}{{Ramachandran, Zoph, and Le}}}
\bibcite{rapach_forecasting_2013}{{21}{2013}{{Rapach and Zhou}}{{}}}
\bibcite{schwert_anomalies_2003}{{22}{2003}{{Schwert}}{{}}}
\bibcite{vuolteenaho_understanding_1999}{{23}{1999}{{Vuolteenaho}}{{}}}
\bibcite{zou_regularization_2005}{{24}{2005}{{Zou and Hastie}}{{}}}
